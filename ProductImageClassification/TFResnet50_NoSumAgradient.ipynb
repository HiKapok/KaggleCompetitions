{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "# Running %env without any arguments\n",
    "# lists all environment variables\n",
    "\n",
    "# The line below sets the environment\n",
    "# variable CUDA_VISIBLE_DEVICES\n",
    "%env CUDA_VISIBLE_DEVICES = 1\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import time\n",
    "import bson                       # this is installed with the pymongo package\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread, imsave, imshow\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import tf_logging\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.training import add_gradients_summaries\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.training import optimizer as tf_optimizer\n",
    "from tensorflow.python.ops import variables as tf_variables\n",
    "import os.path\n",
    "import tensorflow.contrib.slim as slim\n",
    "import inception_preprocessing\n",
    "import logging\n",
    "import resnet1\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/'\n",
    "PRETRAINED_MODEL_PATH = DATASET_PATH + 'Resnet/resnet_v1_50.ckpt'\n",
    "LOG_PATH = DATASET_PATH + 'Resnet/logs/'\n",
    "TRAIN_PATH = DATASET_PATH + 'Split1/Train/'\n",
    "VAL_PATH = DATASET_PATH + 'Split1/Validation/'\n",
    "TEST_PATH = DATASET_PATH + 'Test/'\n",
    "CATEGORY_NAME_PATH = DATASET_PATH + 'category_names.csv'\n",
    "#BATCH_SIZE = 128#256\n",
    "BATCH_SIZE = 128#256\n",
    "\n",
    "# total_batch_size is BATCH_SIZE * ACCUMULATE_STEP\n",
    "ACCUMULATE_STEP = 1\n",
    "\n",
    "IMAGE_WIDTH = 180\n",
    "IMAGE_HEIGHT = 180\n",
    "NUM_CLASS = 5270\n",
    "LEVEL0_CLASS = 49\n",
    "LEVEL1_CLASS = 483\n",
    "# validation examples num: 2319624\n",
    "# train examples num: 10051704\n",
    "# total step: 157057\n",
    "TOTAL_EXAMPLES = 10051704\n",
    "VAL_EXAMPLES = 2319624\n",
    "VAL_CHECK_FREQ = 50\n",
    "NUM_EPOCHES = 8\n",
    "VAL_NUM_EPOCHES = int(NUM_EPOCHES/(VAL_CHECK_FREQ*VAL_EXAMPLES/TOTAL_EXAMPLES)) + 1\n",
    "EPOCHES_OVER = 4\n",
    "\n",
    "INPUT_THREADS = 12\n",
    "\n",
    "#Learning rate information and configuration (Up to you to experiment)\n",
    "# initial_learning_rate = 0.000003#0.00001\n",
    "# learning_rate_decay_factor = 0.94\n",
    "initial_learning_rate = 0.0004#0.0004\n",
    "learning_rate_decay_factor = 0.8\n",
    "num_epochs_before_decay = 1\n",
    "moving_average_decay = 0.9\n",
    "momentum = 0.8\n",
    "#Know the number steps to take before decaying the learning rate and batches per epoch\n",
    "num_steps_per_epoch = TOTAL_EXAMPLES / (BATCH_SIZE * ACCUMULATE_STEP) + 1\n",
    "decay_steps = int(num_epochs_before_decay * num_steps_per_epoch / 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get TF logger\n",
    "log = logging.getLogger('tensorflow')\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# create file handler which logs even debug messages\n",
    "fh = logging.FileHandler(DATASET_PATH + 'tensorflow_resnet_train.log')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "log.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_for_inception(input_image, is_training = True):\n",
    "    return inception_preprocessing.preprocess_image(input_image, 160, 160, is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabelMapping(object):\n",
    "    def __init__(self, catogory_file_path):\n",
    "        super(LabelMapping, self).__init__()\n",
    "        self._category_level_csv = catogory_file_path\n",
    "        self._category_map, self._category_level0_map, self._category_level1_map, self._len_level0, self._len_level1 = self.cvt_csv2tfrecord()\n",
    "        self._mapping_strings = tf.constant( [ str(key) for key in self._category_map.keys() ] )\n",
    "        #print(list(self._category_map.keys())[0])\n",
    "        self._mapping_table = tf.contrib.lookup.index_table_from_tensor(mapping=self._mapping_strings, default_value=0) \n",
    "        \n",
    "        self._level0_table = tf.contrib.lookup.HashTable(tf.contrib.lookup.KeyValueTensorInitializer(list(self._category_level0_map.keys()), list(self._category_level0_map.values()), tf.int64, tf.int64), 0)\n",
    "        self._level1_table = tf.contrib.lookup.HashTable(tf.contrib.lookup.KeyValueTensorInitializer(list(self._category_level1_map.keys()), list(self._category_level1_map.values()), tf.int64, tf.int64), 0)\n",
    "\n",
    "    @property\n",
    "    def category_map(self):\n",
    "        return self._category_map\n",
    "    @property\n",
    "    def level0_table(self):\n",
    "        return self._level0_table\n",
    "    @property\n",
    "    def level1_table(self):\n",
    "        return self._level1_table\n",
    "    @property\n",
    "    def len_level0(self):\n",
    "        return self._len_level0\n",
    "    @property\n",
    "    def len_level1(self):\n",
    "        return self._len_level1\n",
    "    @property\n",
    "    def mapping_table(self):\n",
    "        return self._mapping_table\n",
    "    \n",
    "    def cvt_csv2tfrecord(self):\n",
    "        level0_map, level1_map = self.create_level_map()\n",
    "        count = 0\n",
    "        category_map = dict()\n",
    "        category_level0_map = dict()\n",
    "        category_level1_map = dict()\n",
    "        csv = pd.read_csv(self._category_level_csv).values\n",
    "        for row in csv:  \n",
    "            category_id, level0, level1 = row[0], row[1], row[2]\n",
    "            category_map[category_id] = count\n",
    "            category_level0_map[int(category_id)] = level0_map[level0]\n",
    "            category_level1_map[int(category_id)] = level1_map[level1]\n",
    "            count += 1\n",
    "\n",
    "        return category_map, category_level0_map, category_level1_map, len(level0_map), len(level1_map)\n",
    "\n",
    "    def create_level_map(self):\n",
    "        csv = pd.read_csv(self._category_level_csv).values\n",
    "        level_list = [list(), list()]\n",
    "        for row in csv: \n",
    "            for level in range(1,3):\n",
    "                if row[level] not in level_list[level-1]:\n",
    "                    level_list[level-1].append(row[level])\n",
    "        return dict(zip(level_list[0], range(len(level_list[0])))), dict(zip(level_list[1], range(len(level_list[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class CdiscountDataset(object):\n",
    "#     def __init__(self, data_path, file_begin_match, label_mapping, num_examples, num_classes, buffer_size, batch_size, num_epochs, is_training):\n",
    "#         super(CdiscountDataset, self).__init__()\n",
    "#         self._data_file_list = [ os.path.join(data_path, x) for x in os.listdir(data_path) if lambda x: os.path.isfile(x) and x.startswith(file_begin_match) ]\n",
    "#         self._num_examples = num_examples\n",
    "#         self._num_classes = num_classes\n",
    "#         self._batch_size = batch_size\n",
    "#         self._buffer_size = buffer_size\n",
    "#         self._num_epochs = num_epochs\n",
    "#         self._is_training = is_training\n",
    "#         self._category_map = label_mapping.category_map\n",
    "#         self._level0_table = label_mapping.level0_table\n",
    "#         self._level1_table = label_mapping.level1_table\n",
    "#         self._len_level0 = label_mapping.len_level0\n",
    "#         self._len_level1 = label_mapping.len_level1\n",
    "# #         print(self._len_level0)\n",
    "# #         print(self._len_level1)\n",
    "#         self._mapping_table = label_mapping.mapping_table\n",
    "    \n",
    "#     def _parse_function(self, example_proto):\n",
    "#         features = {'img_raw': tf.FixedLenFeature([], tf.string, default_value=''),\n",
    "#             'product_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n",
    "#             'category_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64))}\n",
    "                \n",
    "#         parsed_features = tf.parse_single_example(example_proto, features)\n",
    "#         image = preprocess_for_inception(tf.image.decode_image(parsed_features[\"img_raw\"]), self._is_training)\n",
    "#         raw_label = parsed_features[\"category_id\"]\n",
    "#         #raw_label = tf.constant(1000018736, dtype=tf.int64)\n",
    "#         #image = tf.image.decode_image(parsed_features[\"img_raw\"])\n",
    "        \n",
    "#         return image, tf.one_hot(self._mapping_table.lookup(tf.as_string(raw_label)), self._num_classes, axis=-1),\\\n",
    "#                 tf.one_hot(self._level0_table.lookup(raw_label), self._len_level0, axis=-1),\\\n",
    "#                 tf.one_hot(self._level1_table.lookup(raw_label), self._len_level1, axis=-1)\n",
    "    \n",
    "#     def get_next(self):\n",
    "#         #next_example, next_label, next_level0_label, next_level1_label \n",
    "#         return self._iterator.get_next()\n",
    "#     def create_dataset(self):\n",
    "#         self._dataset = tf.data.TFRecordDataset(self._data_file_list, compression_type='ZLIB', buffer_size = 409600)\n",
    "#         parse_func = lambda example : self._parse_function(example)\n",
    "#         self._dataset = self._dataset.map(parse_func)\n",
    "#         self._dataset = self._dataset.shuffle(buffer_size=self._buffer_size)\n",
    "#         self._dataset = self._dataset.batch(self._batch_size)\n",
    "#         self._dataset = self._dataset.repeat(self._num_epochs)\n",
    "#         self._iterator = self._dataset.make_initializable_iterator()\n",
    "        \n",
    "#         return self._iterator.initializer\n",
    "    \n",
    "    \n",
    "class CdiscountDataset(object):\n",
    "    def __init__(self, data_path, file_begin_match, label_mapping, num_examples, num_classes, buffer_size, batch_size, num_epochs, is_training):\n",
    "        super(CdiscountDataset, self).__init__()\n",
    "        #self._data_file_list = [ os.path.join(data_path, x) for x in os.listdir(data_path) if lambda x: os.path.isfile(x) and x.startswith(file_begin_match) ]\n",
    "        self._data_file_list = data_path + file_begin_match + '*'\n",
    "        self._num_examples = num_examples\n",
    "        self._num_classes = num_classes\n",
    "        self._batch_size = batch_size\n",
    "        self._buffer_size = buffer_size\n",
    "        self._num_epochs = num_epochs\n",
    "        self._is_training = is_training\n",
    "        self._category_map = label_mapping.category_map\n",
    "        self._level0_table = label_mapping.level0_table\n",
    "        self._level1_table = label_mapping.level1_table\n",
    "        self._len_level0 = label_mapping.len_level0\n",
    "        self._len_level1 = label_mapping.len_level1\n",
    "        self._mapping_table = label_mapping.mapping_table\n",
    "    \n",
    "    \n",
    "    def create_dataset(self):\n",
    "        opts = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.ZLIB)\n",
    "        reader = lambda : tf.TFRecordReader(options=opts)\n",
    "        keys_to_features = {\n",
    "            'img_raw': tf.FixedLenFeature([], tf.string, default_value=''),\n",
    "            'product_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n",
    "            # notice that we don't have this feature in our TFRecord, so always default provided\n",
    "            'format': tf.FixedLenFeature([], tf.string, default_value='jpg'),\n",
    "            'category_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64))\n",
    "        }\n",
    "\n",
    "        items_to_handlers = {\n",
    "            # automated decode image from features in FixedLenFeature\n",
    "            'image': slim.tfexample_decoder.Image(image_key='img_raw', format_key='format'),\n",
    "            'label': slim.tfexample_decoder.Tensor('category_id'),\n",
    "        }\n",
    "\n",
    "        decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\n",
    "        \n",
    "        self._dataset = slim.dataset.Dataset(\n",
    "            data_sources = self._data_file_list,\n",
    "            decoder = decoder,\n",
    "            reader = reader,\n",
    "            # num_readers = 8,\n",
    "            num_samples = self._num_examples,\n",
    "            #num_classes = self._num_classes,\n",
    "            items_to_descriptions = None)\n",
    "        \n",
    "        # notice that DatasetDataProvider can automate shuffle the examples by ParallelReader using its RandomShuffleQueue\n",
    "        self._data_provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "            self._dataset,\n",
    "            num_readers = INPUT_THREADS,\n",
    "            shuffle = True, # default is True\n",
    "            num_epochs = self._num_epochs,\n",
    "            common_queue_capacity = self._buffer_size + 4 * self._batch_size,\n",
    "            common_queue_min = self._buffer_size,\n",
    "            scope = self._is_training and 'train_files' or 'validation_files')\n",
    "        \n",
    "        org_image, org_label = self._data_provider.get(['image', 'label'])\n",
    "\n",
    "        image = preprocess_for_inception(org_image, self._is_training) # final image to train\n",
    " \n",
    "        # no need for shuffle, DatasetDataProvider do this for us\n",
    "        batch_images, batch_labels, batch_labels_level0, batch_labels_level1 = \\\n",
    "                tf.train.batch([image, tf.one_hot(self._mapping_table.lookup(tf.as_string(org_label)), self._num_classes, axis=-1),\\\n",
    "                tf.one_hot(self._level0_table.lookup(org_label), self._len_level0, axis=-1),\\\n",
    "                tf.one_hot(self._level1_table.lookup(org_label), self._len_level1, axis=-1)],\\\n",
    "                self._batch_size,\\\n",
    "                num_threads = INPUT_THREADS,\\\n",
    "                capacity = self._buffer_size + 4 * self._batch_size,\\\n",
    "                allow_smaller_final_batch = self._is_training, name = self._is_training and 'train_batch' or 'validation_batch')\n",
    "        \n",
    "        return batch_images, batch_labels, batch_labels_level0, batch_labels_level1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Parameters\n",
    "# learning_rate = 0.01\n",
    "# total_batch = 25\n",
    "# batch_size = 4\n",
    "# display_step = 1\n",
    "# BATCH_SIZE = 2\n",
    "# # total_batch_size is BATCH_SIZE * ACCUMULATE_STEP\n",
    "# ACCUMULATE_STEP = 2\n",
    "# accumulate_factor = tf.constant([1./ACCUMULATE_STEP])\n",
    "\n",
    "# # tf Graph Input\n",
    "# x = tf.placeholder(tf.float32, [None, 3]) # mnist data image of shape 28*28=784\n",
    "# y = tf.placeholder(tf.float32, [None, 4]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# # Set model weights\n",
    "# W = tf.Variable(tf.zeros([3, 4]))\n",
    "# b = tf.Variable(tf.zeros([4]))\n",
    "\n",
    "# # Construct model\n",
    "# pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "\n",
    "# global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "# # Minimize error using cross entropy\n",
    "# total_loss = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "# # Gradient Descent\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate)#.minimize(cost, global_step=global_step)\n",
    "\n",
    "# variables_to_train = tf_variables.trainable_variables()\n",
    "# ## Creation of a list of variables with the same shape as the trainable ones\n",
    "# # initialized with 0s\n",
    "# accum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in variables_to_train]\n",
    "# zero_ops = [tv.assign(tf.zeros_like(tv)) for tv in accum_vars]\n",
    "\n",
    "# ## Calls the compute_gradients function of the optimizer to obtain... the list of gradients\n",
    "# gvs = optimizer.compute_gradients(total_loss, variables_to_train)\n",
    "\n",
    "# ## Adds to each element from the list you initialized earlier with zeros its gradient (works because accum_vars and gvs are in the same order)\n",
    "# accum_ops = [accum_vars[i].assign_add(gv[0]) for i, gv in enumerate(gvs) if gv is not None]\n",
    "\n",
    "# ## Define the training step (part with variable value update)\n",
    "# train_step = optimizer.apply_gradients([(tf.multiply(accum_vars[i], accumulate_factor), gv[1]) for i, gv in enumerate(gvs) if gv is not None], global_step=global_step)\n",
    "\n",
    "# batch_xs = [np.array([[1,2,3],[1,2,3]]),np.array([[1,2,3],[1,2,3]])]\n",
    "# batch_ys = [np.array([[1,2,3,4],[1,2,3,4]]),np.array([[1,2,3,4],[1,2,3,4]])]\n",
    "# # Initialize the variables (i.e. assign their default value)\n",
    "# init = tf.global_variables_initializer()\n",
    "\n",
    "# # Start training\n",
    "# with tf.Session() as sess:\n",
    "#     # Run the initializer\n",
    "#     sess.run(init)\n",
    "#     # Loop over all batches\n",
    "#     for i in range(total_batch):\n",
    "#         sess.run(zero_ops)\n",
    "#         # Accumulate the gradients 'n_minibatches' times in accum_vars using accum_ops\n",
    "#         for i in range(ACCUMULATE_STEP):\n",
    "#             grad_accumulate, _=sess.run([accum_vars, accum_ops], feed_dict={x: batch_xs[i], y: batch_ys[i]})\n",
    "#             print(grad_accumulate)\n",
    "#         _, cur_step = sess.run([train_step, global_step])\n",
    "#         print(cur_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def my_create_train_op(total_loss, optimizer, summarize_gradients = False):\n",
    "#     global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "#     update_ops = set(ops.get_collection(ops.GraphKeys.UPDATE_OPS))\n",
    "\n",
    "#     # Make sure update_ops are computed before total_loss.\n",
    "#     if update_ops:\n",
    "#         with ops.control_dependencies(update_ops):\n",
    "#             barrier = control_flow_ops.no_op(name='update_barrier')\n",
    "#     total_loss = control_flow_ops.with_dependencies([barrier], total_loss)\n",
    "\n",
    "#     variables_to_train = tf_variables.trainable_variables()\n",
    "\n",
    "#     # Create the gradients. Note that apply_gradients adds the gradient\n",
    "#     # computation to the current graph.\n",
    "#     grads = optimizer.compute_gradients(\n",
    "#       total_loss,\n",
    "#       variables_to_train,\n",
    "#       gate_gradients=tf_optimizer.Optimizer.GATE_OP,\n",
    "#       aggregation_method=None,\n",
    "#       colocate_gradients_with_ops=False)\n",
    "\n",
    "#     # Summarize gradients.\n",
    "#     if summarize_gradients:\n",
    "#         with ops.name_scope('summarize_grads'):\n",
    "#             add_gradients_summaries(grads)\n",
    "\n",
    "#     # Create gradient updates.\n",
    "#     grad_updates = optimizer.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "#     with ops.name_scope('train_op'):\n",
    "#         # Make sure total_loss is valid.\n",
    "#         total_loss = array_ops.check_numerics(total_loss, 'LossTensor is inf or nan')\n",
    "\n",
    "#     # Ensure the train_tensor computes grad_updates.\n",
    "#     train_op = control_flow_ops.with_dependencies([grad_updates], total_loss)\n",
    "\n",
    "#     # Add the operation used for training to the 'train_op' collection\n",
    "#     train_ops = ops.get_collection_ref(ops.GraphKeys.TRAIN_OP)\n",
    "#     if train_op not in train_ops:\n",
    "#         train_ops.append(train_op)\n",
    "\n",
    "#     return train_op\n",
    "def my_create_train_op(total_loss, optimizer, summarize_gradients = False, accumulate_factor=None):\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    update_ops = set(ops.get_collection(ops.GraphKeys.UPDATE_OPS))\n",
    "\n",
    "    # Make sure update_ops are computed before total_loss.\n",
    "    if update_ops:\n",
    "        with ops.control_dependencies(update_ops):\n",
    "            barrier = control_flow_ops.no_op(name='update_barrier')\n",
    "    total_loss = control_flow_ops.with_dependencies([barrier], total_loss)\n",
    "\n",
    "    variables_to_train = tf_variables.trainable_variables()\n",
    "\n",
    "    # initialized with 0s\n",
    "    accum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in variables_to_train]\n",
    "    zero_ops = [tv.assign(tf.zeros_like(tv)) for tv in accum_vars]\n",
    "\n",
    "    # Calls the compute_gradients function of the optimizer to obtain... the list of gradients\n",
    "    grads = optimizer.compute_gradients(\n",
    "      total_loss,\n",
    "      variables_to_train,\n",
    "      gate_gradients=tf_optimizer.Optimizer.GATE_OP,\n",
    "      aggregation_method=None,\n",
    "      colocate_gradients_with_ops=False)\n",
    "\n",
    "    ## Adds to each element from the list you initialized earlier with zeros its gradient (works because accum_vars and grads are in the same order)\n",
    "    if accumulate_factor is not None:   \n",
    "        total_loss = array_ops.check_numerics(total_loss, 'LossTensor is inf or nan')\n",
    "        with tf.control_dependencies([total_loss]):\n",
    "            accum_ops = [accum_vars[i].assign_add(gv[0]) for i, gv in enumerate(grads) if gv[0] is not None]\n",
    "\n",
    "        ## Define the training step (part with variable value update)\n",
    "        accumulate_grads = [(tf.multiply(accum_vars[i], accumulate_factor), gv[1]) for i, gv in enumerate(grads) if gv[0] is not None]\n",
    "    else:\n",
    "        accum_ops = tf.no_op(name = 'accum_pass_by')\n",
    "    \n",
    "    if accumulate_factor is not None: \n",
    "        # Summarize gradients.\n",
    "        if summarize_gradients:\n",
    "            with ops.name_scope('summarize_grads'):\n",
    "                add_gradients_summaries(accumulate_grads)\n",
    "        grad_updates = optimizer.apply_gradients(accumulate_grads, global_step=global_step)\n",
    "    else:\n",
    "        # Summarize gradients.\n",
    "        if summarize_gradients:\n",
    "            with ops.name_scope('summarize_grads'):\n",
    "                add_gradients_summaries(grads)\n",
    "        grad_updates = optimizer.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "    with ops.name_scope('train_op'):\n",
    "        # Ensure the train_tensor computes grad_updates.\n",
    "        train_op = control_flow_ops.with_dependencies([grad_updates], total_loss)\n",
    "\n",
    "    # Add the operation used for training to the 'train_op' collection\n",
    "    train_ops = ops.get_collection_ref(ops.GraphKeys.TRAIN_OP)\n",
    "    if train_op not in train_ops:\n",
    "        train_ops.append(train_op)\n",
    "\n",
    "    return train_op, accum_ops, zero_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def_graph = tf.Graph()\n",
    "with def_graph.as_default() as graph:\n",
    "    def train_step(input_examples, one_hot_labels, level0_labels, level1_labels):   \n",
    "        # inputs has shape [batch, 224, 224, 3]\n",
    "        with slim.arg_scope(resnet1.resnet_arg_scope()):\n",
    "            logits, end_points = resnet1.resnet_v1_50(input_examples, NUM_CLASS, is_training=True)\n",
    "            \n",
    "            variables_to_restore = slim.get_variables_to_restore(exclude = ['resnet_v1_50/logits'])\n",
    "            \n",
    "#             level0_aux_input = def_graph.get_tensor_by_name('resnet_v1_50/block3/unit_6/bottleneck_v1/Relu:0')\n",
    "#             level1_aux_input = def_graph.get_tensor_by_name('resnet_v1_50/block4/unit_3/bottleneck_v1/Relu:0')   \n",
    "            level0_aux_input = def_graph.get_tensor_by_name('resnet_v1_50/block2/unit_4/bottleneck_v1/Relu:0')\n",
    "            level1_aux_input = def_graph.get_tensor_by_name('resnet_v1_50/block3/unit_6/bottleneck_v1/Relu:0')   \n",
    "           \n",
    "            level0_aux_net = math_ops.reduce_mean(level0_aux_input, [1, 2], name='level0_aux_pool', keep_dims=True)\n",
    "            level0_aux_net = layers.conv2d(\n",
    "                  level0_aux_net,\n",
    "                  LEVEL0_CLASS, [1, 1],\n",
    "                  activation_fn=None,\n",
    "                  normalizer_fn=None,\n",
    "                  scope='level0_aux_conv')\n",
    "            level0_aux_logits = tf.squeeze(level0_aux_net)\n",
    "            loss_level0 = tf.losses.softmax_cross_entropy(onehot_labels = level0_labels, logits = level0_aux_logits, weights=0.1)\n",
    "            level1_aux_net = math_ops.reduce_mean(level1_aux_input, [1, 2], name='level1_aux_pool', keep_dims=True)\n",
    "            level1_aux_net = layers.conv2d(\n",
    "                  level1_aux_net,\n",
    "                  LEVEL1_CLASS, [1, 1],\n",
    "                  activation_fn=None,\n",
    "                  normalizer_fn=None,\n",
    "                  scope='level1_aux_conv')\n",
    "            level1_aux_logits = tf.squeeze(level1_aux_net)\n",
    "            loss_level1 = tf.losses.softmax_cross_entropy(onehot_labels = level1_labels, logits = level1_aux_logits, weights=0.3)\n",
    "\n",
    "            #variables_to_restore_from_checkpoint = slim.get_variables_to_restore(exclude = variables_to_exclude)\n",
    "            # Performs the equivalent to tf.nn.sparse_softmax_cross_entropy_with_logits but enhanced, e.x. label smothing\n",
    "            loss = tf.losses.softmax_cross_entropy(onehot_labels = one_hot_labels, logits = tf.squeeze(logits))\n",
    "            total_loss = tf.losses.get_total_loss()    # obtain the regularization losses as well\n",
    "                \n",
    "#             def wrap_with_counter(fn, counter):\n",
    "#                 def wrapped_fn(*args, **kwargs):\n",
    "#                     # control_dependencies forces the assign op to be run even if we don't use the result\n",
    "#                     with tf.control_dependencies([tf.assign_add(counter, 1)]):\n",
    "#                         return fn(*args, **kwargs)\n",
    "#                 return wrapped_fn\n",
    "\n",
    "#             graph_counter = tf.get_variable(\n",
    "#                 dtype=tf.int32, shape=(), name='graph_counter',\n",
    "#                 initializer=tf.zeros_initializer())\n",
    "#             total_loss = wrap_with_counter(tf.losses.get_total_loss, graph_counter)()\n",
    "            # Create the global step for monitoring the learning_rate and training.\n",
    "            # since supervisor will also create one global_step, so we create n advance in order to feed into exponential_decay\n",
    "            global_step = tf.train.get_or_create_global_step(graph = graph)\n",
    "\n",
    "            #Define your exponentially decaying learning rate\n",
    "            lr = tf.train.exponential_decay(\n",
    "                learning_rate = initial_learning_rate,\n",
    "                global_step = global_step,\n",
    "                decay_steps = decay_steps,\n",
    "                decay_rate = learning_rate_decay_factor,\n",
    "                staircase = True)\n",
    "\n",
    "            #Now we can define the optimizer that takes on the learning rate\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate = lr)\n",
    "            #optimizer = tf.train.MomentumOptimizer(learning_rate = lr, momentum=momentum)\n",
    "            \n",
    "            # Gather update_ops from the first clone. These contain, for example,\n",
    "            # the updates for the batch_norm variables created by network_fn.\n",
    "            # update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "            moving_average_variables = slim.get_model_variables()\n",
    "            variable_averages = tf.train.ExponentialMovingAverage(moving_average_decay, global_step)\n",
    "            # Use an alternative set of update ops in addition to the default updates:\n",
    "            tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, variable_averages.apply(moving_average_variables))\n",
    "\n",
    "            #Create the train_op.\n",
    "            accumulate_factor = tf.constant([1./ACCUMULATE_STEP])\n",
    "            #train_op, accum_ops, zero_ops = my_create_train_op(total_loss, optimizer, False, accumulate_factor)\n",
    "            \n",
    "            #Create the train_op.\n",
    "            train_op = slim.learning.create_train_op(total_loss, optimizer, summarize_gradients=False)\n",
    "\n",
    "            #State the metrics that you want to predict. We get a predictions that is not one_hot_encoded.\n",
    "            predictions = tf.argmax(tf.squeeze(end_points['predictions']), 1)\n",
    "            probabilities = end_points['predictions']\n",
    "            accuracy, accuracy_update = tf.contrib.metrics.streaming_accuracy(predictions, tf.argmax(one_hot_labels, 1))\n",
    "            metrics_op = tf.group(accuracy_update)\n",
    "\n",
    "\n",
    "            #Now finally create all the summaries you need to monitor and group them into one summary op.\n",
    "            tf.summary.scalar('losses/Total_Loss', total_loss)\n",
    "            tf.summary.scalar('train/accuracy', accuracy)\n",
    "            tf.summary.scalar('learning_rate', lr)\n",
    "\n",
    "            return train_op, global_step, metrics_op, variables_to_restore, predictions, lr, accuracy, total_loss\n",
    "\n",
    "    def validation_step(input_examples, one_hot_labels):   \n",
    "        with slim.arg_scope(resnet1.resnet_arg_scope()):\n",
    "            logits, end_points = resnet1.resnet_v1_50(input_examples, NUM_CLASS, is_training=False, reuse=True)\n",
    "\n",
    "            #State the metrics that you want to predict. We get a predictions that is not one_hot_encoded.\n",
    "            predictions = tf.argmax(tf.squeeze(end_points['predictions']), 1)\n",
    "            probabilities = end_points['predictions']\n",
    "            accuracy, accuracy_update = tf.contrib.metrics.streaming_accuracy(predictions, tf.argmax(one_hot_labels, 1))\n",
    "            metrics_op = tf.group(accuracy_update)\n",
    "\n",
    "            #Now finally create all the summaries you need to monitor and group them into one summary op.\n",
    "            tf.summary.scalar('validation/accuracy', accuracy)\n",
    "\n",
    "            return metrics_op, accuracy, predictions, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kapok/pyenv35/lib/python3.5/site-packages/tensorflow/contrib/training/python/training/training.py:412: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "INFO:tensorflow:Restoring parameters from /media/rs/0E06CD1706CD0127/Kapok/kaggle/Resnet/resnet_v1_50.ckpt\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Saving checkpoint to path /media/rs/0E06CD1706CD0127/Kapok/kaggle/Resnet/logs/resnet50_v1_model.ckpt\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Validation Speed: 13.872sec/batch\n",
      "INFO:tensorflow:Current Streaming ValAccuracy: 0.000%\n",
      "INFO:tensorflow:Real Label: [1148 4926 4873 3623  267 3352  991 4045 3797 4350 2884 4814 2916 4045 1169\n",
      " 4816  229 4214 2884 3165 3095 4045 4689 3328 4045 2908 4393 3800  289  790\n",
      "  453 4045   58  289  284 4045 4008 3104 4350 4153  480 3797 3501 1068 4250\n",
      " 4117 3692 1377 3234 1208 3025 2900 1310 2938 3547 3593  289  114 1142 3730\n",
      " 4861  762 3631 1372 3692  689 3234 4393 4045  545 2471 1011 1946 3623  160\n",
      "  341 1613 3053  191 3279 3797 4800 2923 4045 3593 4350 3643 4393 4393 4153\n",
      " 2166 4274  267 4393 2938 4429 5126 3582 3050 2589 3663 4970 3623 3692  196\n",
      " 4045 3632 2923 4153 4393 5026 5054 2870 4957 1277 4045 2649 2841   47 1892\n",
      " 4814 3692 4970 1055 4350 3407  358 4045]\n",
      "INFO:tensorflow:Pred Label: [3255 4418 4849  595  595 4822  595  595  595  595  595 4822  595  892  595\n",
      "  595 3255  595  595  595 4418  892  595 4277 5099  595 4822  595  595 4822\n",
      " 4822  595  595 4822  595  595  595  595 3255 2011 4277  595  595  595  892\n",
      "  595  595  595 4822  595  595 3255  595  595  595 4822 4418 3255 4822 3255\n",
      "  741  595 4481 4822 4822  595  595 4822  595  595 4822 4822  595  595  595\n",
      "  595  595  595  595 3255  595 4822  595  595 4277  595  595 4822 4277 4822\n",
      " 3255  595 4481 4822  595 4277 4418  595  595  595 3255  892  595 3255 3255\n",
      "  595  595 3507  595  595  595  595  595 5099  595 4822 4277 4481  595  595\n",
      " 4822  595 4277  595  595  595 4822  595]\n",
      "INFO:tensorflow:Current Speed: 0.847sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 1.476%\n",
      "INFO:tensorflow:Current Loss: 11.538\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 10\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:Current Speed: 0.752sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.015%\n",
      "INFO:tensorflow:Current Loss: 11.421\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 20\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:Current Speed: 0.719sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.236%\n",
      "INFO:tensorflow:Current Loss: 11.321\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 30\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:Current Speed: 0.648sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.324%\n",
      "INFO:tensorflow:Current Loss: 11.267\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 40\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:Validation Speed: 0.180sec/batch\n",
      "INFO:tensorflow:Current Streaming ValAccuracy: 0.000%\n",
      "INFO:tensorflow:Real Label: [ 289 3692 2897 2795 4800 4816 4393 2159  192 4045 5229  461 3328 1502 2842\n",
      " 4393 2592 4045  991   58  302 2897 2816 3784 1383  229  289 3692 4403 4279\n",
      " 4393  192 4350 4393 4393 3643 3279 4153 3929 4747 1428  699 1102 4816 2849\n",
      " 2886   73  790 1112 2611 4335 4459  783 4970  598  457  130 5063 2938 3238\n",
      " 2886 4045 3414 4911 3366  289 4861 4672  289 3692 3638 2063 3186  160 4350\n",
      " 4045 3692 2904 4350 2878  754 1593 4153 5241 3692  991 4861 3277  341 4393\n",
      " 1435  289 1907  210 3569 4992 1956 4350 4993 3623 3463  289 2848 2869 3780\n",
      " 4393 2886 5214 2849 4350 1842 4045  638 3623 2116 2531 2890 2917 4970 1066\n",
      " 4350 4861 4045 3330 2849 4814 2886 4045]\n",
      "INFO:tensorflow:Pred Label: [4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792\n",
      " 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792\n",
      " 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792\n",
      " 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792\n",
      " 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792\n",
      " 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792\n",
      " 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792\n",
      " 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792 4792\n",
      " 4792 4792 4792 4792 4792 4792 4792 4792]\n",
      "INFO:tensorflow:Current Speed: 0.708sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.317%\n",
      "INFO:tensorflow:Current Loss: 11.162\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 59\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:Current Speed: 0.732sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.217%\n",
      "INFO:tensorflow:Current Loss: 11.092\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 69\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:Current Speed: 0.752sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.274%\n",
      "INFO:tensorflow:Current Loss: 11.089\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 79\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:Current Speed: 0.749sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.255%\n",
      "INFO:tensorflow:Current Loss: 11.072\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 89\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:Validation Speed: 0.169sec/batch\n",
      "INFO:tensorflow:Current Streaming ValAccuracy: 0.000%\n",
      "INFO:tensorflow:Real Label: [4350 4816 2791  289 2897 3824 3593 4045 3692 2656 3692  991 4816  341 1420\n",
      "  289 2461  747 4045 4792 2849 3623  384 3501 4045 4839 1132 2884 4904  991\n",
      "  178 3623 3888 4279 4097 4766 5130 3262 4045 4816  662 3991 4350 2647 5210\n",
      " 3623  991 1735  895 3331 2115 4671 1925  267 4350 4393 3869 3773 1591 3929\n",
      " 4153 4393 2925 4279  157 3674 2938 3800 1277 1601 3877 4153 3279 4564 1956\n",
      "  289 1246 4816  845 4403 3167 4816  289 4816 3692  289 1106 2938 4350  377\n",
      " 4393 4350 3582 4837 3152 1282 1706  289 4393  991 4350 2878 4393 4970 2967\n",
      " 3277 4311 4393 4045 3545 2763  377 4147 4393 4350 3429  232 4523 4393 4045\n",
      " 4045 4792 3692 4185 3692  606 4816 3692]\n",
      "INFO:tensorflow:Pred Label: [4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350\n",
      " 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350\n",
      " 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350\n",
      " 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350\n",
      " 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350\n",
      " 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350\n",
      " 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350\n",
      " 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350 4350\n",
      " 4350 4350 4350 4350 4350 4350 4350 4350]\n",
      "INFO:tensorflow:Current Speed: 0.703sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.183%\n",
      "INFO:tensorflow:Current Loss: 11.019\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 108\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:Current Speed: 0.740sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.217%\n",
      "INFO:tensorflow:Current Loss: 11.015\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 118\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:Current Speed: 0.717sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.215%\n",
      "INFO:tensorflow:Current Loss: 10.997\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 128\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:Current Speed: 0.722sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.178%\n",
      "INFO:tensorflow:Current Loss: 11.005\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 138\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:global_step/sec: 1.19166\n",
      "INFO:tensorflow:Validation Speed: 0.180sec/batch\n",
      "INFO:tensorflow:Current Streaming ValAccuracy: 1.823%\n",
      "INFO:tensorflow:Real Label: [3597 3692 4816 4393 3059 3279 3279 4429 3059 4393 4393 3692  232 4305 3692\n",
      " 2842 1636 2230 4393 2147 2649 4800 2854  991  289  210 1386 2942 2819 1306\n",
      " 4123 1902 3692 4393 4516  289 1634 4393 2902 2848 1255 4534 4816 3692 4045\n",
      " 4141 4045 3279 3784 2764  991  804 4835 3800 4429 3692  232 4970  662 3869\n",
      "  289 3730 4160 4946 5089 1644 3768 2421 4160 1899 3262 1607  445 3277  406\n",
      " 3191 4816 3623 2908  289 1331 3569 4350 2884 5264 3328 3800 5210 5114 4816\n",
      " 3188 3279 2917  191  289 4350 2841  991 4970 2791 5015 4179 2842 4045 5082\n",
      "  140 1435 1925 2853  191 3483  662 4832 2232  160  845 4350 4335 1250 3728\n",
      " 4525 4303 1607 2872 4407 2841 2884 4350]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Pred Label: [991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991\n",
      " 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991\n",
      " 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991\n",
      " 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991\n",
      " 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991\n",
      " 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991\n",
      " 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991 991\n",
      " 991 991]\n",
      "INFO:tensorflow:Current Speed: 0.722sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.133%\n",
      "INFO:tensorflow:Current Loss: 10.964\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 157\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:Current Speed: 0.710sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.141%\n",
      "INFO:tensorflow:Current Loss: 10.932\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 167\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:Current Speed: 0.711sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.135%\n",
      "INFO:tensorflow:Current Loss: 10.975\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 177\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:Current Speed: 0.675sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.100%\n",
      "INFO:tensorflow:Current Loss: 10.933\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 187\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:Validation Speed: 0.177sec/batch\n",
      "INFO:tensorflow:Current Streaming ValAccuracy: 1.953%\n",
      "INFO:tensorflow:Real Label: [3463  857 4393 1277  457 4393  204 4045 3050 2904 4800 2938 4153 3692 4393\n",
      " 4045 4429 3059 4350 3692 5001 2849  101 3279 2746 4429 3048 2087 1842  619\n",
      " 3643 4814 3692 2908  991 3816 2116 4023 4342  140 4168 4279  219 2643  289\n",
      " 4393 1099 2938 3623 3692  229 3513 1435 4274 2870 1607 4317 1943 2830 3617\n",
      " 3671 4393 4814  762 3059 3463 1255 3328 4816 4097  174 2900 4236 4350 4045\n",
      " 4045  267 2884  808 2886 2235  289 4045  526 4816 3059 4393 4814 4279 2938\n",
      " 4873 2908 1954 2633 4350 4814 4816 2865 1007 2908 4814 4792  866 4366 2828\n",
      "  289 3692 3692 3433 4970 3279 2889 2886 4393 1282 2800 3545 4815 4699 2230\n",
      " 4045 4153 3623 4816 3407 5089 2938 3279]\n",
      "INFO:tensorflow:Pred Label: [1607 2908 1607 2908 2908 2908 1607 1607 2908 2908 1607 2908 2908 1607 1607\n",
      " 1607 1607 1607 2908 2908 1607 2908 2908 2908 2908 2908 2908 1607 2908 2908\n",
      " 1607 2908 1607 2908 2908 2908 1607 1607 1607 2908 1607 2908 1607 2908 2908\n",
      " 1607 1607 1607 2908 2908 1607 2908 1607 2908 2908 2908 2908 2908 1607 1607\n",
      " 2908 2908 1607 2908 2908 1607 2908 2908 2908 1607 1607 1607 1607 1607 1607\n",
      " 1607 1607 2908 1607 1607 1607 2908 1607 2908 1607 2908 2908 2908 1607 1607\n",
      " 1607 1607 1607 1607 1607 1607 1607 1607 2908 1607 1607 1607 2908 1607 2908\n",
      " 2908 2908 1607 2908 1607 2908 2908 2908 1607 1607 1607 1607 2908 2908 2908\n",
      " 1607 2908 2908 2908 1607 1607 2908 1607]\n",
      "INFO:tensorflow:Current Speed: 0.725sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.218%\n",
      "INFO:tensorflow:Current Loss: 10.959\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 206\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n",
      "INFO:tensorflow:Current Speed: 0.721sec/batch\n",
      "INFO:tensorflow:Current Streaming Accuracy: 2.202%\n",
      "INFO:tensorflow:Current Loss: 10.934\n",
      "INFO:tensorflow:Epoch 1/8, Global Step: 216\n",
      "INFO:tensorflow:Current Learning Rate: 0.00039999998989515007\n"
     ]
    }
   ],
   "source": [
    "with def_graph.as_default() as graph:\n",
    "    label_mapping = LabelMapping(CATEGORY_NAME_PATH)\n",
    "    train_dataset = CdiscountDataset(TRAIN_PATH, 'output_file', label_mapping, TOTAL_EXAMPLES, NUM_CLASS, 8000, BATCH_SIZE, NUM_EPOCHES, True)\n",
    "    val_dataset = CdiscountDataset(VAL_PATH, 'test_output_file', label_mapping, VAL_EXAMPLES, NUM_CLASS, 2000, BATCH_SIZE, VAL_NUM_EPOCHES, False)\n",
    "\n",
    "\n",
    "    #train_iterator_initializer = train_dataset.create_dataset()\n",
    "    #val_iterator_initializer = val_dataset.create_dataset()\n",
    "    #iterator_initalizer = tf.group(train_iterator_initializer, val_iterator_initializer)\n",
    "    \n",
    "    #batch_images, batch_labels, batch_level0_labels, batch_level1_labels = train_dataset.get_next()\n",
    "    #batch_val_images, batch_val_labels, batch_val_level0_labels, batch_val_level1_labels = val_dataset.get_next()\n",
    "    batch_images, batch_labels, batch_level0_labels, batch_level1_labels = train_dataset.create_dataset()\n",
    "    batch_val_images, batch_val_labels, batch_val_level0_labels, batch_val_level1_labels = val_dataset.create_dataset()\n",
    "    \n",
    "#     batch_images = tf.random_uniform([BATCH_SIZE, 180, 180, 3], maxval=256, dtype=tf.float32)\n",
    "#     batch_labels = tf.random_uniform([BATCH_SIZE, NUM_CLASS], maxval=1, dtype=tf.int32)\n",
    "#     batch_level0_labels = tf.random_uniform([BATCH_SIZE, LEVEL0_CLASS], maxval=1, dtype=tf.int32)\n",
    "#     batch_level1_labels = tf.random_uniform([BATCH_SIZE, LEVEL1_CLASS], maxval=1, dtype=tf.int32)\n",
    "    with tf.device('/gpu:0'):\n",
    "        train_op, global_step, metrics_op, variables_to_restore, pred_op, lr, accuracy, total_loss = train_step(batch_images, batch_labels, batch_level0_labels, batch_level1_labels)\n",
    "        val_metrics_op, val_accuracy, val_predictions, val_probabilities = validation_step(batch_val_images, batch_val_labels)\n",
    "        real_val_label = tf.argmax(batch_val_labels, 1)\n",
    "         \n",
    "    summary_op = tf.summary.merge_all()\n",
    "    # Create a saver that restores only the pre-trained variables.\n",
    "    # we have change optim, restore all param use pretrained mode\n",
    "    #pre_train_saver = tf.train.Saver(variables_to_restore)\n",
    "    \n",
    "    variables = slim.get_variables_to_restore()\n",
    "    restore_from_pretrained = tf.contrib.framework.filter_variables(\n",
    "        variables,\n",
    "        include_patterns=None,\n",
    "        exclude_patterns=['Momentum'])\n",
    "\n",
    "    pre_train_saver = tf.train.Saver(variables_to_restore)\n",
    "    # Define an init function that loads the pretrained checkpoint.\n",
    "    # sess is the managed session passed by Supervisor\n",
    "    def load_pretrain(sess):\n",
    "        pre_train_saver.restore(sess, PRETRAINED_MODEL_PATH)\n",
    "\n",
    "    # no need for specify local_variables_initializer and tables_initializer, Supervisor will do this via default local_init_op\n",
    "    # init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer(), tf.tables_initializer())\n",
    "    init_op = tf.group(tf.global_variables_initializer())\n",
    "    #init_op = tf.group(train_iterator_initializer, val_iterator_initializer, tf.global_variables_initializer())\n",
    "    \n",
    "    # Pass the init function to the supervisor.\n",
    "    # - The init function is called _after_ the variables have been initialized by running the init_op.\n",
    "    # - use default tf.Saver() for ordinary save and restore\n",
    "    # - save checkpoint every 1.3 hours(4800)\n",
    "    # - manage summary in current process by ourselves for memory saving\n",
    "    # - no need to specify global_step, supervisor will find this automately\n",
    "    # - initialize order: checkpoint -> local_init_op -> init_op -> init_func\n",
    "    sv = tf.train.Supervisor(logdir=LOG_PATH, init_fn = load_pretrain, init_op = init_op, summary_op = None, save_model_secs=8000, checkpoint_basename='resnet50_v1_model.ckpt')\n",
    "    \n",
    "    final_loss = 0.\n",
    "    final_accuracy = 0.\n",
    "    training_state = True\n",
    "\n",
    "    config = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)\n",
    "    #config.gpu_options.allow_growth = True\n",
    "    with sv.managed_session(config=config) as sess:\n",
    "    #with sv.prepare_or_wait_for_session(config=tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)) as sess:\n",
    "        #sess.run(iterator_initalizer)\n",
    "        # Here sess was either initialized from the pre-trained-checkpoint or\n",
    "        # recovered from a checkpoint saved in a previous run of this code.\n",
    "        for step in range(int(num_steps_per_epoch * NUM_EPOCHES)):         \n",
    "            if sv.should_stop():\n",
    "                tf_logging.info('Supervisor emit finished!')\n",
    "                tf_logging.info('Current Loss: %s', loss)\n",
    "                tf_logging.info('Current Accuracy: %s', accuracy)\n",
    "                tf_logging.info('Saving current model to disk(maybe invalid).')\n",
    "                training_state = False\n",
    "                break\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            if step % 1000 == 0:\n",
    "            #if True:\n",
    "                summ = sess.run(summary_op)\n",
    "                sv.summary_computed(sess, summ)\n",
    "                if step > EPOCHES_OVER * num_steps_per_epoch:\n",
    "                    raise StopIteration(\"over epoches reached.\")\n",
    "\n",
    "            if step % VAL_CHECK_FREQ == 0:\n",
    "                with tf.device('/gpu:0'):\n",
    "                    _, val_acc, val_pred, val_prob, real_label = sess.run([val_metrics_op, val_accuracy, val_predictions, val_probabilities, real_val_label])\n",
    "                time_elapsed = time.time() - start_time\n",
    "                tf_logging.info('Validation Speed: {:5.3f}sec/batch'.format(time_elapsed))\n",
    "                tf_logging.info('Current Streaming ValAccuracy: {:5.3f}%'.format(val_acc*100.))\n",
    "                tf_logging.info('Real Label: {}'.format(real_label))\n",
    "                tf_logging.info('Pred Label: {}'.format(val_pred))\n",
    "\n",
    "            else:\n",
    "                with tf.device('/gpu:0'):\n",
    "                    _, _, cur_loss, cur_acc, total_step, cur_lr = sess.run([train_op, metrics_op, total_loss, accuracy, global_step, lr])\n",
    "\n",
    "                time_elapsed = time.time() - start_time\n",
    "\n",
    "                if step % 10 == 0:\n",
    "                    final_loss = cur_loss\n",
    "                    final_accuracy = cur_acc\n",
    "                    tf_logging.info('Current Speed: {:5.3f}sec/batch'.format(time_elapsed))\n",
    "                    tf_logging.info('Current Streaming Accuracy: {:5.3f}%'.format(cur_acc*100.))\n",
    "                    tf_logging.info('Current Loss: {:5.3f}'.format(cur_loss))\n",
    "                    tf_logging.info('Epoch %s/%s, Global Step: %s', int(total_step / num_steps_per_epoch + 1), NUM_EPOCHES, total_step)\n",
    "                    tf_logging.info('Current Learning Rate: {}'.format(cur_lr))\n",
    "                \n",
    "                    \n",
    "        if training_state:\n",
    "            #We log the final training loss and accuracy\n",
    "            tf_logging.info('Final Loss: %s', final_loss)\n",
    "            tf_logging.info('Final Accuracy: %s', final_accuracy)\n",
    "            # Once all the training has been done, save the log files and checkpoint model\n",
    "            tf_logging.info('Finished training! Model saved.')\n",
    "        sv.saver.save(sess, sv.save_path, global_step = sv.global_step)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with def_graph.as_default() as graph:\n",
    "#     label_mapping = LabelMapping(CATEGORY_NAME_PATH)\n",
    "#     train_dataset = CdiscountDataset(TRAIN_PATH, 'output_file', label_mapping, TOTAL_EXAMPLES, NUM_CLASS, 8000, BATCH_SIZE, NUM_EPOCHES, True)\n",
    "#     val_dataset = CdiscountDataset(VAL_PATH, 'test_output_file', label_mapping, VAL_EXAMPLES, NUM_CLASS, 2000, BATCH_SIZE, VAL_NUM_EPOCHES, False)\n",
    "\n",
    "\n",
    "#     #train_iterator_initializer = train_dataset.create_dataset()\n",
    "#     #val_iterator_initializer = val_dataset.create_dataset()\n",
    "#     #iterator_initalizer = tf.group(train_iterator_initializer, val_iterator_initializer)\n",
    "    \n",
    "#     #batch_images, batch_labels, batch_level0_labels, batch_level1_labels = train_dataset.get_next()\n",
    "#     #batch_val_images, batch_val_labels, batch_val_level0_labels, batch_val_level1_labels = val_dataset.get_next()\n",
    "#     batch_images, batch_labels, batch_level0_labels, batch_level1_labels = train_dataset.create_dataset()\n",
    "#     batch_val_images, batch_val_labels, batch_val_level0_labels, batch_val_level1_labels = val_dataset.create_dataset()\n",
    "    \n",
    "# #     batch_images = tf.random_uniform([BATCH_SIZE, 180, 180, 3], maxval=256, dtype=tf.float32)\n",
    "# #     batch_labels = tf.random_uniform([BATCH_SIZE, NUM_CLASS], maxval=1, dtype=tf.int32)\n",
    "# #     batch_level0_labels = tf.random_uniform([BATCH_SIZE, LEVEL0_CLASS], maxval=1, dtype=tf.int32)\n",
    "# #     batch_level1_labels = tf.random_uniform([BATCH_SIZE, LEVEL1_CLASS], maxval=1, dtype=tf.int32)\n",
    "#     with tf.device('/gpu:0'):\n",
    "#         train_op, accum_op, zero_op, global_step, metrics_op, variables_to_restore, pred_op, lr, accuracy, total_loss = train_step(batch_images, batch_labels, batch_level0_labels, batch_level1_labels)\n",
    "#         val_metrics_op, val_accuracy, val_predictions, val_probabilities = validation_step(batch_val_images, batch_val_labels)\n",
    "#         real_val_label = tf.argmax(batch_val_labels, 1)\n",
    "         \n",
    "#     summary_op = tf.summary.merge_all()\n",
    "#     # Create a saver that restores only the pre-trained variables.\n",
    "#     # we have change optim, restore all param use pretrained mode\n",
    "#     #pre_train_saver = tf.train.Saver(variables_to_restore)\n",
    "    \n",
    "#     variables = slim.get_variables_to_restore()\n",
    "#     restore_from_pretrained = tf.contrib.framework.filter_variables(\n",
    "#         variables,\n",
    "#         include_patterns=None,\n",
    "#         exclude_patterns=['Momentum'])\n",
    "\n",
    "#     pre_train_saver = tf.train.Saver(variables_to_restore)\n",
    "#     # Define an init function that loads the pretrained checkpoint.\n",
    "#     # sess is the managed session passed by Supervisor\n",
    "#     def load_pretrain(sess):\n",
    "#         pre_train_saver.restore(sess, PRETRAINED_MODEL_PATH)\n",
    "\n",
    "#     # no need for specify local_variables_initializer and tables_initializer, Supervisor will do this via default local_init_op\n",
    "#     # init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer(), tf.tables_initializer())\n",
    "#     init_op = tf.group(tf.global_variables_initializer())\n",
    "#     #init_op = tf.group(train_iterator_initializer, val_iterator_initializer, tf.global_variables_initializer())\n",
    "    \n",
    "#     # Pass the init function to the supervisor.\n",
    "#     # - The init function is called _after_ the variables have been initialized by running the init_op.\n",
    "#     # - use default tf.Saver() for ordinary save and restore\n",
    "#     # - save checkpoint every 1.3 hours(4800)\n",
    "#     # - manage summary in current process by ourselves for memory saving\n",
    "#     # - no need to specify global_step, supervisor will find this automately\n",
    "#     # - initialize order: checkpoint -> local_init_op -> init_op -> init_func\n",
    "#     sv = tf.train.Supervisor(logdir=LOG_PATH, init_fn = load_pretrain, init_op = init_op, summary_op = None, save_model_secs=8000, checkpoint_basename='resnet50_v1_model.ckpt')\n",
    "    \n",
    "#     final_loss = 0.\n",
    "#     final_accuracy = 0.\n",
    "#     training_state = True\n",
    "\n",
    "#     config = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)\n",
    "#     #config.gpu_options.allow_growth = True\n",
    "#     with sv.managed_session(config=config) as sess:\n",
    "#     #with sv.prepare_or_wait_for_session(config=tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)) as sess:\n",
    "#         #sess.run(iterator_initalizer)\n",
    "#         # Here sess was either initialized from the pre-trained-checkpoint or\n",
    "#         # recovered from a checkpoint saved in a previous run of this code.\n",
    "#         for step in range(int(num_steps_per_epoch * NUM_EPOCHES)):         \n",
    "#             if sv.should_stop():\n",
    "#                 tf_logging.info('Supervisor emit finished!')\n",
    "#                 tf_logging.info('Current Loss: %s', loss)\n",
    "#                 tf_logging.info('Current Accuracy: %s', accuracy)\n",
    "#                 tf_logging.info('Saving current model to disk(maybe invalid).')\n",
    "#                 training_state = False\n",
    "#                 break\n",
    "\n",
    "#             start_time = time.time()\n",
    "\n",
    "#             # accumulate gradient to get bigger batch_size\n",
    "#             with tf.device('/gpu:0'):\n",
    "#                 sess.run(zero_op)\n",
    "#                 for _ in range(ACCUMULATE_STEP):\n",
    "#                     _,ff=sess.run([accum_op, total_loss])\n",
    "#                     print(ff)\n",
    "\n",
    "#             if step % 1000 == 0:\n",
    "#                 with tf.device('/gpu:0'):\n",
    "#                     _, _, _, summ = sess.run([train_op, global_step, metrics_op, summary_op])\n",
    "#                 sv.summary_computed(sess, summ)\n",
    "#                 if step > EPOCHES_OVER * num_steps_per_epoch:\n",
    "#                     raise StopIteration(\"over epoches reached.\")\n",
    "#             else:\n",
    "#                 if step % VAL_CHECK_FREQ == 0:\n",
    "#                     with tf.device('/gpu:0'):\n",
    "#                         _, val_acc, val_pred, val_prob, real_label = sess.run([val_metrics_op, val_accuracy, val_predictions, val_probabilities, real_val_label])\n",
    "#                     time_elapsed = time.time() - start_time\n",
    "#                     tf_logging.info('Validation Speed: {:5.3f}sec/batch'.format(time_elapsed))\n",
    "#                     tf_logging.info('Current Streaming ValAccuracy: {:5.3f}%'.format(val_acc*100.))\n",
    "#                     tf_logging.info('Real Label: {}'.format(real_label))\n",
    "#                     tf_logging.info('Pred Label: {}'.format(val_pred))\n",
    "                        \n",
    "#                 else:\n",
    "#                     with tf.device('/gpu:0'):\n",
    "#                         _, total_step, _, cur_loss, cur_acc, cur_lr = sess.run([train_op, global_step, metrics_op, total_loss, accuracy, lr])\n",
    "#                     time_elapsed = time.time() - start_time\n",
    "#                     print(cur_loss)\n",
    "#                     if step % 10 == 0:\n",
    "#                         final_loss = cur_loss\n",
    "#                         final_accuracy = cur_acc\n",
    "#                         tf_logging.info('Current Speed: {:5.3f}sec/batch'.format(time_elapsed))\n",
    "#                         tf_logging.info('Current Streaming Accuracy: {:5.3f}%'.format(cur_acc*100.))\n",
    "#                         tf_logging.info('Current Loss: {:5.3f}'.format(cur_loss))\n",
    "#                         tf_logging.info('Epoch %s/%s, Global Step: %s', int(total_step / num_steps_per_epoch + 1), NUM_EPOCHES, total_step)\n",
    "#                         tf_logging.info('Current Learning Rate: {}'.format(cur_lr))\n",
    "                \n",
    "                    \n",
    "#         if training_state:\n",
    "#             #We log the final training loss and accuracy\n",
    "#             tf_logging.info('Final Loss: %s', final_loss)\n",
    "#             tf_logging.info('Final Accuracy: %s', final_accuracy)\n",
    "#             # Once all the training has been done, save the log files and checkpoint model\n",
    "#             tf_logging.info('Finished training! Model saved.')\n",
    "#         sv.saver.save(sess, sv.save_path, global_step = sv.global_step)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
