{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "# Running %env without any arguments\n",
    "# lists all environment variables\n",
    "\n",
    "# The line below sets the environment\n",
    "# variable CUDA_VISIBLE_DEVICES\n",
    "%env CUDA_VISIBLE_DEVICES = 0\n",
    "\n",
    "import io\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread, imsave\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import tf_logging\n",
    "import os.path\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.slim.python.slim.nets import inception\n",
    "from tensorflow.contrib.framework.python.ops.variables import get_or_create_global_step\n",
    "import inception_preprocessing\n",
    "import logging\n",
    "from scipy.sparse import *\n",
    "import tables as tb\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/'\n",
    "LOG_PATH = DATASET_PATH + 'logs/'\n",
    "TEST_PATH = DATASET_PATH + 'Test/'\n",
    "OUTPUT_PATH = DATASET_PATH + 'logs_focalloss/output_{}.csv'\n",
    "CATEGORY_NAME_PATH = DATASET_PATH + 'category_names.csv'\n",
    "INCEPTION_MODEL_PATH = DATASET_PATH + 'logs_focalloss/inception_v3_model.ckpt-882954'\n",
    "PROB_SAVE_FILE = DATASET_PATH + 'logs_focalloss/probs_{}.h5'\n",
    "ID_SAVE_FILE = DATASET_PATH + 'logs_focalloss/ids.csv'\n",
    "\n",
    "moving_average_decay = 0.96\n",
    "\n",
    "NUM_OF_TOPK = 20\n",
    "BATCH_SIZE = 64\n",
    "NUM_TO_AUG = 4\n",
    "IMAGE_WIDTH = 180\n",
    "IMAGE_HEIGHT = 180\n",
    "NUM_CLASS = 5270\n",
    "TOTAL_EXAMPLES = 3095080\n",
    "INPUT_THREADS = 1\n",
    "NUM_STEPS = int(TOTAL_EXAMPLES / BATCH_SIZE) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get TF logger\n",
    "log = logging.getLogger('tensorflow')\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# create file handler which logs even debug messages\n",
    "fh = logging.FileHandler(DATASET_PATH + 'tensorflow_inception_160_test.log')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "log.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MiniDataSet(object):\n",
    "    def __init__(self, file_path_pattern, num_examples, num_classes, is_training = True, min_after_dequeue=2000, batch_size = BATCH_SIZE, num_reader = INPUT_THREADS):\n",
    "        super(MiniDataSet, self).__init__()\n",
    "        self._num_examples = num_examples\n",
    "        self._num_classes = num_classes\n",
    "        self._file_path_pattern = file_path_pattern\n",
    "        self._num_reader = num_reader\n",
    "        self._batch_size = batch_size\n",
    "        self._min_after_dequeue = min_after_dequeue\n",
    "        self._is_training = is_training\n",
    "        \n",
    "    def create_dataset(self):\n",
    "        opts = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.ZLIB)\n",
    "        reader = lambda : tf.TFRecordReader(options=opts)\n",
    "        keys_to_features = {\n",
    "            'product_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n",
    "            'img_raw': tf.FixedLenFeature([], tf.string, default_value=''),\n",
    "            # notice that we don't have this feature in our TFRecord, so always default provided\n",
    "            'format': tf.FixedLenFeature([], tf.string, default_value='jpg')\n",
    "        }\n",
    "\n",
    "        items_to_handlers = {\n",
    "            # automated decode image from features in FixedLenFeature\n",
    "            'image': slim.tfexample_decoder.Image(image_key='img_raw', format_key='format'),\n",
    "            'product': slim.tfexample_decoder.Tensor('product_id'),\n",
    "        }\n",
    "\n",
    "        decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\n",
    "\n",
    "        self._dataset = slim.dataset.Dataset(\n",
    "            data_sources = self._file_path_pattern,\n",
    "            decoder = decoder,\n",
    "            reader = reader,\n",
    "            # num_readers = 8,\n",
    "            num_samples = self._num_examples,\n",
    "            #num_classes = self._num_classes,\n",
    "            items_to_descriptions = None)\n",
    "        \n",
    "        # notice that DatasetDataProvider can automate shuffle the examples by ParallelReader using its RandomShuffleQueue\n",
    "        self._data_provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "            self._dataset,\n",
    "            num_readers = self._num_reader,\n",
    "            shuffle = False, # default is True\n",
    "            num_epochs = 1,\n",
    "            common_queue_capacity = self._min_after_dequeue + 3 * self._batch_size,\n",
    "            common_queue_min = self._min_after_dequeue,\n",
    "            scope = 'test_files')\n",
    "        \n",
    "        return self._data_provider.get(['image', 'product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def_graph = tf.Graph()\n",
    "with def_graph.as_default() as graph:\n",
    "    def test_step(input_examples):   \n",
    "        with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "            # here logits is the pre-softmax activations\n",
    "            logits, end_points = inception.inception_v3(\n",
    "                input_examples,\n",
    "                num_classes = NUM_CLASS,\n",
    "                is_training=False)\n",
    "            variable_averages = tf.train.ExponentialMovingAverage(moving_average_decay)\n",
    "            variables_to_restore = variable_averages.variables_to_restore()\n",
    "            #variables_to_restore = slim.get_variables_to_restore()\n",
    "\n",
    "            #State the metrics that you want to predict. We get a predictions that is not one_hot_encoded.\n",
    "            predictions = tf.argmax(end_points['Predictions'], 1)\n",
    "            #probabilities = end_points['Predictions']\n",
    "            probabilities = logits\n",
    "\n",
    "            return predictions, probabilities, variables_to_restore\n",
    "    def preprocess_for_inception(input_image):\n",
    "        # inception_v3.default_image_size = 299\n",
    "        return inception_preprocessing.preprocess_image(input_image, 160, 160, True)\n",
    "    def init_dataset(file_path_pattern):\n",
    "        dataset = MiniDataSet(file_path_pattern, TOTAL_EXAMPLES, NUM_CLASS)\n",
    "        org_image, product_id = dataset.create_dataset()\n",
    "        image_to_aug = tf.tile(tf.expand_dims(org_image, 0), tf.constant([NUM_TO_AUG, 1, 1, 1]))\n",
    "        product_id_to_aug = tf.tile(tf.expand_dims(product_id, 0), tf.constant([NUM_TO_AUG]))\n",
    "\n",
    "        image_list = tf.unstack(image_to_aug)\n",
    "        \n",
    "        image_preprocessed_list = [preprocess_for_inception(image) for image in image_list]\n",
    "\n",
    "        batch_images, batch_id = tf.train.batch([tf.stack(image_preprocessed_list), product_id_to_aug], BATCH_SIZE,\\\n",
    "                                            num_threads = INPUT_THREADS,\\\n",
    "                                            capacity = 2000 + 3 * BATCH_SIZE,\\\n",
    "                                            allow_smaller_final_batch = True, name = 'test_batch')\n",
    "        \n",
    "        return batch_images, batch_id\n",
    "    def cvt_csv2tfrecord():\n",
    "        count = 0\n",
    "        category_map = dict()\n",
    "        csv = pd.read_csv(CATEGORY_NAME_PATH).values\n",
    "        for row in csv:  \n",
    "            category_id, _ = row[0], row[1:]\n",
    "            category_map[category_id] = count\n",
    "            count += 1\n",
    "        return category_map\n",
    "    def slices_to_dims(slice_indices):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        slice_indices: An [N, k] Tensor mapping to column indices.\n",
    "        Returns:\n",
    "        An index Tensor with shape [N * k, 2], corresponding to indices suitable for\n",
    "        passing to SparseTensor.\n",
    "        \"\"\"\n",
    "        slice_indices = tf.cast(slice_indices, tf.int64)\n",
    "        num_rows = tf.shape(slice_indices, out_type=tf.int64)[0]\n",
    "        row_range = tf.range(num_rows)\n",
    "        # row_range expanded from [num_rows] into [num_rows, 1]\n",
    "        # every item in k_th row of slice_indices are multiplied by num_rows, then added by k with broadcast\n",
    "        item_numbers = slice_indices * num_rows + tf.expand_dims(row_range, axis=1)\n",
    "        # flaten so that each row represent each element\n",
    "        item_numbers_flat = tf.reshape(item_numbers, [-1])\n",
    "        # convert back by zip op\n",
    "        return item_numbers_flat % num_rows, item_numbers_flat // num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-01 09:46:30\n",
      "INFO:tensorflow:Restoring parameters from /media/rs/0E06CD1706CD0127/Kapok/kaggle/logs_focalloss/inception_v3_model.ckpt-882954\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:Step: 0 of 48361.\n",
      "INFO:tensorflow:Validation Speed: 2.770sec/batch\n",
      "INFO:tensorflow:Roughly 37.215 hours to go.\n",
      "INFO:tensorflow:Step: 200 of 48361.\n",
      "INFO:tensorflow:Validation Speed: 0.852sec/batch\n",
      "INFO:tensorflow:Roughly 11.399 hours to go.\n",
      "INFO:tensorflow:Step: 400 of 48361.\n",
      "INFO:tensorflow:Validation Speed: 0.856sec/batch\n",
      "INFO:tensorflow:Roughly 11.402 hours to go.\n",
      "INFO:tensorflow:Step: 600 of 48361.\n",
      "INFO:tensorflow:Validation Speed: 0.806sec/batch\n",
      "INFO:tensorflow:Roughly 10.696 hours to go.\n",
      "INFO:tensorflow:Step: 800 of 48361.\n",
      "INFO:tensorflow:Validation Speed: 0.773sec/batch\n",
      "INFO:tensorflow:Roughly 10.209 hours to go.\n",
      "INFO:tensorflow:Step: 1000 of 48361.\n",
      "INFO:tensorflow:Validation Speed: 0.797sec/batch\n",
      "INFO:tensorflow:Roughly 10.480 hours to go.\n",
      "INFO:tensorflow:Step: 1200 of 48361.\n",
      "INFO:tensorflow:Validation Speed: 0.792sec/batch\n",
      "INFO:tensorflow:Roughly 10.379 hours to go.\n",
      "INFO:tensorflow:Step: 1400 of 48361.\n",
      "INFO:tensorflow:Validation Speed: 0.770sec/batch\n",
      "INFO:tensorflow:Roughly 10.045 hours to go.\n",
      "INFO:tensorflow:Step: 1600 of 48361.\n",
      "INFO:tensorflow:Validation Speed: 0.781sec/batch\n",
      "INFO:tensorflow:Roughly 10.141 hours to go.\n",
      "INFO:tensorflow:Step: 1800 of 48361.\n",
      "INFO:tensorflow:Validation Speed: 0.801sec/batch\n",
      "INFO:tensorflow:Roughly 10.362 hours to go.\n",
      "INFO:tensorflow:Step: 2000 of 48361.\n",
      "INFO:tensorflow:Validation Speed: 0.767sec/batch\n",
      "INFO:tensorflow:Roughly  9.876 hours to go.\n",
      "INFO:tensorflow:Step: 2200 of 48361.\n",
      "INFO:tensorflow:Validation Speed: 0.778sec/batch\n",
      "INFO:tensorflow:Roughly  9.981 hours to go.\n",
      "INFO:tensorflow:Step: 2400 of 48361.\n",
      "INFO:tensorflow:Validation Speed: 0.797sec/batch\n",
      "INFO:tensorflow:Roughly 10.180 hours to go.\n",
      "INFO:tensorflow:Step: 2600 of 48361.\n",
      "INFO:tensorflow:Validation Speed: 0.768sec/batch\n",
      "INFO:tensorflow:Roughly  9.768 hours to go.\n",
      "INFO:tensorflow:Step: 2800 of 48361.\n",
      "INFO:tensorflow:Validation Speed: 0.808sec/batch\n",
      "INFO:tensorflow:Roughly 10.220 hours to go.\n",
      "INFO:tensorflow:Step: 3000 of 48361.\n",
      "INFO:tensorflow:Validation Speed: 0.769sec/batch\n",
      "INFO:tensorflow:Roughly  9.694 hours to go.\n"
     ]
    }
   ],
   "source": [
    "with def_graph.as_default() as graph:\n",
    "    mapping_strings = tf.constant( [ str(key) for key in cvt_csv2tfrecord().keys() ] )\n",
    "    mapping_table = tf.contrib.lookup.index_table_from_tensor(mapping=mapping_strings, default_value=0)\n",
    "    \n",
    "    inv_table = tf.contrib.lookup.index_to_string_table_from_tensor(mapping_strings, default_value=\"0000000000\")\n",
    "\n",
    "    batch_images_aug, batch_id_aug = init_dataset(TEST_PATH + \"output_file*.tfrecords\")#test_output_file6.tfrecords\n",
    "    \n",
    "    #batch_images, batch_id = init_dataset(TEST_PATH+'test_output_file6*')\n",
    "    batch_images = tf.reshape(batch_images_aug, [-1, 160, 160, 3])\n",
    "    batch_id = tf.reshape(batch_id_aug, [-1])\n",
    "    \n",
    "    # use placeholder instead\n",
    "    #last_prob = tf.constant(0, shape=[0,NUM_CLASS], dtype=tf.float32)\n",
    "    #last_id = tf.constant(0, shape=[0], dtype=tf.int64)  \n",
    "    last_prob = tf.placeholder(tf.float32)\n",
    "    last_id = tf.placeholder(tf.int64)\n",
    "    with tf.device('/gpu:0'):\n",
    "        test_predictions, test_probabilities, variables_to_restore = test_step(batch_images)\n",
    "        test_predictions_values = tf.string_to_number(inv_table.lookup(test_predictions), out_type=tf.int64) \n",
    "        \n",
    "        top_values, top_indices = tf.nn.top_k(test_probabilities, k = NUM_OF_TOPK, sorted=True)\n",
    "        (row_indice, col_indice), value_array = slices_to_dims(top_indices), tf.reshape(top_values, [-1])\n",
    "        cur_prob_shape = tf.shape(test_probabilities)\n",
    "        # concat betweent batches\n",
    "        _, idx, count = tf.unique_with_counts(batch_id)\n",
    "        #print(tf.dynamic_partition(batch_id, tf.not_equal(idx, tf.shape(count)[0] - 1).eval(), 2)[1].eval())  \n",
    "        cur_id_tail, _cur_id_head = tf.dynamic_partition(batch_id, tf.cast(tf.not_equal(idx, tf.shape(count)[0] - 1), tf.int32), 2)\n",
    "        with tf.control_dependencies([cur_id_tail, _cur_id_head]):\n",
    "            cur_id_head = tf.concat([last_id, _cur_id_head], axis = 0)\n",
    "        #cur_id_head = tf.concat([last_id, tf.concat(tf.split(batch_id, count)[0:-1], axis = 0)], axis = 0)\n",
    "        #cur_id_tail = tf.split(batch_id, count)[-1]\n",
    "        \n",
    "        cur_prob_tail, _cur_prob_head = tf.dynamic_partition(test_probabilities, tf.cast(tf.not_equal(idx, tf.shape(count)[0] - 1), tf.int32), 2)\n",
    "        with tf.control_dependencies([last_prob, _cur_prob_head]):\n",
    "            cur_prob_head = tf.concat([last_prob, _cur_prob_head], axis = 0)\n",
    "        #cur_prob_head = tf.concat([last_prob, tf.concat(tf.split(test_probabilities, count[0:-1]), axis = 0)], axis = 0)\n",
    "        #cur_prob_tail = tf.split(test_probabilities, count)[-1]\n",
    "        with tf.control_dependencies([cur_id_head, cur_prob_head]):\n",
    "            raw_id, idx, _ = tf.unique_with_counts(cur_id_head)\n",
    "            mean_prob = tf.segment_mean(cur_prob_head, idx)\n",
    "            mean_label = tf.string_to_number(inv_table.lookup(tf.argmax(mean_prob, 1)), out_type=tf.int64) \n",
    "        with tf.control_dependencies([mean_prob, mean_label]):\n",
    "            #last_id = cur_id_tail\n",
    "            #last_prob = cur_prob_tail\n",
    "            # last partition may have nothing to concat\n",
    "            raw_id_tail, idx_tail, _ = tf.unique_with_counts(cur_id_tail)\n",
    "            mean_prob_tail = tf.segment_mean(cur_prob_tail, idx_tail)\n",
    "            tail_label = tf.string_to_number(inv_table.lookup(tf.argmax(mean_prob_tail, 1)), out_type=tf.int64) \n",
    "    restore_saver = tf.train.Saver(variables_to_restore)\n",
    "    def load_pretrain(sess):\n",
    "        restore_saver.restore(sess, INCEPTION_MODEL_PATH)\n",
    "\n",
    "    # no need for specify local_variables_initializer and tables_initializer, Supervisor will do this via default local_init_op\n",
    "    init_op = tf.group(tf.global_variables_initializer())\n",
    "    # Pass the init function to the supervisor.\n",
    "    # - The init function is called _after_ the variables have been initialized by running the init_op.\n",
    "    # - use default tf.Saver() for ordinary save and restore\n",
    "    # - save checkpoint every 1.3 hours\n",
    "    # - manage summary in current process by ourselves for memory saving\n",
    "    # - no need to specify global_step, supervisor will find this automately\n",
    "    # - initialize order: checkpoint -> local_init_op -> init_op -> init_func\n",
    "    sv = tf.train.Supervisor(logdir=LOG_PATH, init_fn = load_pretrain, init_op = init_op, summary_op = None, save_model_secs=0)\n",
    "    \n",
    "    step = 0\n",
    "    lats_pred = []\n",
    "    last_batch_id = []\n",
    "    last_feed_id = np.empty([0])\n",
    "    last_feed_prob = np.empty([0, NUM_CLASS])\n",
    "    save_file_name = OUTPUT_PATH.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    prob_save_file_name = PROB_SAVE_FILE.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    hdf5_file = tb.open_file(prob_save_file_name, 'w')\n",
    "    total_prob_store = hdf5_file.create_earray(hdf5_file.root, 'prob', tb.Float32Atom(), shape=(0,), filters=tb.Filters(complevel=5, complib='zlib'))\n",
    "    total_row_indice = hdf5_file.create_earray(hdf5_file.root, 'row', tb.Int64Atom(), shape=(0,), filters=tb.Filters(complevel=5, complib='zlib'))\n",
    "    total_col_indice = hdf5_file.create_earray(hdf5_file.root, 'col', tb.Int64Atom(), shape=(0,), filters=tb.Filters(complevel=5, complib='zlib'))\n",
    "    print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    #last_row_to_save = 0\n",
    "    with sv.managed_session(config=tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)) as sess:\n",
    "    #with sv.prepare_or_wait_for_session(config=tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)) as sess:\n",
    "\n",
    "        # Here sess was either initialized from the pre-trained-checkpoint or\n",
    "        # recovered from a checkpoint saved in a previous run of this code.\n",
    "        while True:       \n",
    "            if sv.should_stop():\n",
    "                tf_logging.info('Supervisor emit finished!')\n",
    "                break\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            with tf.device('/gpu:0'):\n",
    "                #test_pred, test_prob, test_batch_id = sess.run([test_predictions_values, test_probabilities, batch_id])\n",
    "                cur_batch_id, last_feed_id, last_feed_prob, test_pred, test_prob, test_batch_id, lats_pred, last_batch_id, sparse_row, sparse_col, sparse_value, sparse_shape = sess.run([batch_id, cur_id_tail, cur_prob_tail, mean_label, mean_prob, raw_id, tail_label, raw_id_tail, row_indice, col_indice, value_array, cur_prob_shape], feed_dict = {last_prob: last_feed_prob, last_id: last_feed_id})\n",
    "            #print(csr_matrix((sparse_value, (sparse_row, sparse_col)), shape=sparse_shape).toarray())\n",
    "            #total_prob_store[last_row_to_save:last_row_to_save + sparse_shape[0],:] = csr_matrix((sparse_value, (sparse_row, sparse_col)), shape=sparse_shape).toarray()\n",
    "            total_prob_store.append(sparse_value)\n",
    "            total_row_indice.append(sparse_row)\n",
    "            total_col_indice.append(sparse_col)\n",
    "            #last_row_to_save += sparse_shape[0]\n",
    "            time_elapsed = time.time() - start_time\n",
    "            if step % 200 == 0:\n",
    "            #if True:\n",
    "                tf_logging.info('Step: {} of {}.'.format(step, NUM_STEPS))\n",
    "                tf_logging.info('Validation Speed: {:5.3f}sec/batch'.format(time_elapsed))\n",
    "                tf_logging.info('Roughly {:6.3f} hours to go.'.format(  time_elapsed*( (NUM_STEPS-step) > 0 and (NUM_STEPS-step)/3600. or 0.001 )  ))\n",
    "                #tf_logging.info('Test Label: {}'.format(test_pred))\n",
    "                #tf_logging.info('Test Prob: {}'.format(test_prob))\n",
    "                #tf_logging.info('Test Ids: {}'.format(test_batch_id))\n",
    "            #print(len(test_prob[0]))\n",
    "            df = pd.DataFrame({'_id' : test_batch_id, 'category_id' : test_pred})\n",
    "            #df = pd.DataFrame([test_batch_id, test_pred], columns=[\"_id\", 'category_id'])\n",
    "\n",
    "            if not os.path.isfile(save_file_name):\n",
    "                df.to_csv(save_file_name, mode='a', index=False, sep=',')\n",
    "            else:\n",
    "                df.to_csv(save_file_name, mode='a', index=False, sep=',', header=False)\n",
    "#             if not os.path.isfile(ID_SAVE_FILE):\n",
    "#                 pd.DataFrame({'_id' : cur_batch_id}).to_csv(ID_SAVE_FILE, mode='a', index=False, sep=',')\n",
    "#             else:\n",
    "#                 pd.DataFrame({'_id' : cur_batch_id}).to_csv(ID_SAVE_FILE, mode='a', index=False, sep=',', header=False)\n",
    "            step += 1\n",
    "\n",
    "#             tf_logging.info('BB ID: {}'.format(bb_id))\n",
    "#             tf_logging.info('Test Label: {}'.format(test_pred))\n",
    "#             #tf_logging.info('Test Prob: {}'.format(test_prob))\n",
    "#             tf_logging.info('Test Ids: {}'.format(test_batch_id))\n",
    "#             tf_logging.info('Last Label: {}'.format(lats_pred))\n",
    "#             #tf_logging.info('Test Prob: {}'.format(test_prob))\n",
    "#             tf_logging.info('Last Ids: {}'.format(last_batch_id))\n",
    "#             if step > 3:\n",
    "#                 break\n",
    "            \n",
    "    df = pd.DataFrame({'_id' : last_batch_id, 'category_id' : lats_pred})\n",
    "    df.to_csv(save_file_name, mode='a', index=False, sep=',', header=False)\n",
    "    hdf5_file.close()\n",
    "    tf_logging.info('Finished evaluation! ')\n",
    "    print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(save_file_name)\n",
    "print(test_data.tail())\n",
    "# 1768182 \n",
    "#(1768182, 3095080)\n",
    "#Test11111 - (700, 1195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# h5 = tb.open_file(DATASET_PATH + 'logs/probs_2017-10-19 21:30:55.h5', 'r')\n",
    "# print(h5.root.prob.shape)\n",
    "# print(h5.root.row.shape)\n",
    "# print(h5.root.col.shape)\n",
    "# print(csr_matrix((h5.root.prob[:], (h5.root.row[:], h5.root.col[:])), shape=(TOTAL_EXAMPLES,NUM_CLASS)).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
