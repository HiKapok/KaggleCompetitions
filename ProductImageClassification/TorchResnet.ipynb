{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running %env without any arguments\n",
    "# lists all environment variables\n",
    "\n",
    "# The line below sets the environment\n",
    "# variable CUDA_VISIBLE_DEVICES\n",
    "%env CUDA_VISIBLE_DEVICES = 0\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread, imsave\n",
    "import tensorflow as tf\n",
    "import os.path\n",
    "import logging\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/'\n",
    "PRETRAINED_MODEL_PATH = DATASET_PATH + 'models/inception_v3.ckpt'\n",
    "LOG_PATH = DATASET_PATH + 'logs/'\n",
    "TRAIN_PATH = DATASET_PATH + 'Split/Train/'\n",
    "VAL_PATH = DATASET_PATH + 'Split/Validation/'\n",
    "TEST_PATH = DATASET_PATH + 'Test/'\n",
    "CATEGORY_NAME_PATH = DATASET_PATH + 'category_names.csv'\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_WIDTH = 180\n",
    "IMAGE_HEIGHT = 180\n",
    "NUM_CLASS = 5270\n",
    "# validation examples num: 2319624\n",
    "# train examples num: 10051704\n",
    "# total step: 157057\n",
    "TOTAL_EXAMPLES = 10051704\n",
    "# validation num = 2319624\n",
    "NUM_EPOCHES = 5\n",
    "INPUT_THREADS = 6\n",
    "\n",
    "#Learning rate information and configuration (Up to you to experiment)\n",
    "initial_learning_rate = 0.000003#0.00001\n",
    "learning_rate_decay_factor = 0.94\n",
    "num_epochs_before_decay = 1\n",
    "#Know the number steps to take before decaying the learning rate and batches per epoch\n",
    "num_steps_per_epoch = TOTAL_EXAMPLES / BATCH_SIZE\n",
    "decay_steps = int(num_epochs_before_decay * num_steps_per_epoch / 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_logging(logger_name, logger_file_name):\n",
    "    log = logging.getLogger(logger_name)\n",
    "    log.setLevel(logging.DEBUG)\n",
    "\n",
    "    # create formatter and add it to the handlers\n",
    "    print_formatter = logging.Formatter('%(message)s')\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(name)s_%(levelname)s: %(message)s')\n",
    "\n",
    "    # create file handler which logs even debug messages\n",
    "    fh = logging.FileHandler(logger_file_name, mode='w')\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    fh.setFormatter(file_formatter)\n",
    "    log.addHandler(fh)\n",
    "    # both output to console and file\n",
    "    consoleHandler = logging.StreamHandler()\n",
    "    consoleHandler.setFormatter(print_formatter)\n",
    "    log.addHandler(consoleHandler)\n",
    "    \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = set_logging('TORCH', DATASET_PATH + 'resnet_train.log')\n",
    "log.info('here is an info message.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BATCH_SIZE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-282a3cbcb075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMiniDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_level_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_after_dequeue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_EPOCHES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINPUT_THREADS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMiniDataSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-282a3cbcb075>\u001b[0m in \u001b[0;36mMiniDataSet\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMiniDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_level_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_after_dequeue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_EPOCHES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINPUT_THREADS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMiniDataSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BATCH_SIZE' is not defined"
     ]
    }
   ],
   "source": [
    "class MiniDataSet(object):\n",
    "    def __init__(self, file_path_pattern, category_level_csv, num_examples, num_classes, is_training = True, min_after_dequeue=1000, batch_size = BATCH_SIZE, num_epochs = NUM_EPOCHES, num_reader = INPUT_THREADS):\n",
    "        super(MiniDataSet, self).__init__()\n",
    "        self._num_examples = num_examples\n",
    "        self._num_classes = num_classes\n",
    "        self._file_path_pattern = file_path_pattern\n",
    "        self._category_level_csv = category_level_csv\n",
    "        self._num_reader = num_reader\n",
    "        self._batch_size = batch_size\n",
    "        self._num_epochs = num_epochs\n",
    "        self._min_after_dequeue = min_after_dequeue\n",
    "        self._is_training = is_training\n",
    "        \n",
    "    def get_category_description_from_csv(self, level = 0):\n",
    "        category_map = dict()\n",
    "        csv = pd.read_csv(self._category_level_csv).values\n",
    "        for row in csv:  \n",
    "            category_id, levels = row[0], row[1:]\n",
    "            category_map[category_id] = levels[level]\n",
    "        return category_map\n",
    "    \n",
    "    def num_examples():\n",
    "        return self._num_examples\n",
    "    def num_classes():\n",
    "        return self._num_classes\n",
    "\n",
    "    def create_dataset(self):\n",
    "        opts = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.ZLIB)\n",
    "        reader = lambda : tf.TFRecordReader(options=opts)\n",
    "        keys_to_features = {\n",
    "            'img_raw': tf.FixedLenFeature([], tf.string, default_value=''),\n",
    "            'product_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n",
    "            # notice that we don't have this feature in our TFRecord, so always default provided\n",
    "            'format': tf.FixedLenFeature([], tf.string, default_value='jpg'),\n",
    "            'category_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64))\n",
    "        }\n",
    "\n",
    "        items_to_handlers = {\n",
    "            # automated decode image from features in FixedLenFeature\n",
    "            'image': slim.tfexample_decoder.Image(image_key='img_raw', format_key='format'),\n",
    "            'label': slim.tfexample_decoder.Tensor('category_id'),\n",
    "        }\n",
    "\n",
    "        decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\n",
    "\n",
    "        labels_to_name_dict = self.get_category_description_from_csv()\n",
    "\n",
    "        self._dataset = slim.dataset.Dataset(\n",
    "            data_sources = self._file_path_pattern,\n",
    "            decoder = decoder,\n",
    "            reader = reader,\n",
    "            # num_readers = 8,\n",
    "            num_samples = self._num_examples,\n",
    "            #num_classes = self._num_classes,\n",
    "            #labels_to_name = labels_to_name_dict,\n",
    "            items_to_descriptions = None)\n",
    "        \n",
    "        # notice that DatasetDataProvider can automate shuffle the examples by ParallelReader using its RandomShuffleQueue\n",
    "        self._data_provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "            self._dataset,\n",
    "            num_readers = self._num_reader,\n",
    "            shuffle = True, # default is True\n",
    "            num_epochs = self._num_epochs,\n",
    "            common_queue_capacity = self._min_after_dequeue + 3 * self._batch_size,\n",
    "            common_queue_min = self._min_after_dequeue,\n",
    "            scope = self._is_training and 'train_files' or 'validation_files')\n",
    "        \n",
    "        return self._data_provider.get(['image', 'label'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fa44ab634d95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCdiscountDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class CdiscountDataset(Dataset):\n",
    "    def __init__(self, tf_dataset, root_dir, transform=None):\n",
    "        self._def_graph = tf.Graph()\n",
    "        session_config = tf.tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "        session_config.gpu_options.per_process_gpu_memory_fraction = 0.\n",
    "        session_config.gpu_options.visible_device_list= ''\n",
    "        self._session = tf.Session(config=session_config)    \n",
    "        self._image, self._label = tf_dataset.create_dataset()\n",
    "        self._tfdataset = tf_dataset\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._tfdataset.num_examples()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.landmarks_frame.ix[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.ix[idx, 1:].as_matrix().astype('float')\n",
    "        landmarks = landmarks.reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_for_inception(input_image, is_training = True):\n",
    "    # inception_v3.default_image_size = 299\n",
    "    return inception_preprocessing.preprocess_image(input_image, 299, 299, is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cvt_csv2tfrecord():\n",
    "    count = 0\n",
    "    category_map = dict()\n",
    "    csv = pd.read_csv(CATEGORY_NAME_PATH).values\n",
    "    for row in csv:  \n",
    "        category_id, _ = row[0], row[1:]\n",
    "        category_map[category_id] = count\n",
    "        count += 1\n",
    "    return category_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_process(org_label, map_table, num_classes):\n",
    "    return tf.one_hot(map_table.lookup(tf.as_string(org_label)), num_classes, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def_graph = tf.Graph()\n",
    "with def_graph.as_default() as graph:\n",
    "    def train_step(input_examples, one_hot_labels):   \n",
    "        with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "            # here logits is the pre-softmax activations\n",
    "            logits, end_points = inception.inception_v3(\n",
    "                input_examples,\n",
    "                num_classes = NUM_CLASS,\n",
    "                is_training = True)\n",
    "            # we retrain for diferrent num classes\n",
    "            # and don't define any Variables before get_variables_to_restore\n",
    "            variables_to_restore = slim.get_variables_to_restore(exclude = ['InceptionV3/Logits', 'InceptionV3/AuxLogits'])\n",
    "            # Performs the equivalent to tf.nn.sparse_softmax_cross_entropy_with_logits but enhanced, e.x. label smothing\n",
    "            loss = tf.losses.softmax_cross_entropy(onehot_labels = one_hot_labels, logits = logits)\n",
    "            total_loss = tf.losses.get_total_loss()    # obtain the regularization losses as well\n",
    "\n",
    "            # Create the global step for monitoring the learning_rate and training.\n",
    "            # since supervisor will also create one global_step, so we create n advance in order to feed into exponential_decay\n",
    "            global_step = get_or_create_global_step(graph = graph)\n",
    "\n",
    "            #Define your exponentially decaying learning rate\n",
    "            lr = tf.train.exponential_decay(\n",
    "                learning_rate = initial_learning_rate,\n",
    "                global_step = global_step,\n",
    "                decay_steps = decay_steps,\n",
    "                decay_rate = learning_rate_decay_factor,\n",
    "                staircase = True)\n",
    "\n",
    "            #Now we can define the optimizer that takes on the learning rate\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate = lr)\n",
    "\n",
    "            #Create the train_op.\n",
    "            train_op = slim.learning.create_train_op(total_loss, optimizer, summarize_gradients=False)\n",
    "\n",
    "            #State the metrics that you want to predict. We get a predictions that is not one_hot_encoded.\n",
    "            predictions = tf.argmax(end_points['Predictions'], 1)\n",
    "            probabilities = end_points['Predictions']\n",
    "            accuracy, accuracy_update = tf.contrib.metrics.streaming_accuracy(predictions, tf.argmax(one_hot_labels, 1))\n",
    "            metrics_op = tf.group(accuracy_update)\n",
    "\n",
    "\n",
    "            #Now finally create all the summaries you need to monitor and group them into one summary op.\n",
    "            tf.summary.scalar('losses/Total_Loss', total_loss)\n",
    "            tf.summary.scalar('accuracy', accuracy)\n",
    "            tf.summary.scalar('learning_rate', lr)\n",
    "\n",
    "            return train_op, global_step, metrics_op, variables_to_restore, predictions, lr, accuracy, total_loss\n",
    "\n",
    "    def validation_step(input_examples, one_hot_labels):   \n",
    "        with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "            # here logits is the pre-softmax activations\n",
    "            logits, end_points = inception.inception_v3(\n",
    "                input_examples,\n",
    "                num_classes = NUM_CLASS,\n",
    "                is_training=False, reuse=True)\n",
    "\n",
    "            #State the metrics that you want to predict. We get a predictions that is not one_hot_encoded.\n",
    "            predictions = tf.argmax(end_points['Predictions'], 1)\n",
    "            probabilities = end_points['Predictions']\n",
    "            accuracy, accuracy_update = tf.contrib.metrics.streaming_accuracy(predictions, tf.argmax(one_hot_labels, 1))\n",
    "            metrics_op = tf.group(accuracy_update)\n",
    "\n",
    "            #Now finally create all the summaries you need to monitor and group them into one summary op.\n",
    "            tf.summary.scalar('validation/accuracy', accuracy)\n",
    "\n",
    "            return metrics_op, accuracy, predictions, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with def_graph.as_default() as graph:\n",
    "    def init_dataset(file_path_pattern, mapping_table, is_training = True):\n",
    "        dataset = MiniDataSet(file_path_pattern, CATEGORY_NAME_PATH, TOTAL_EXAMPLES, NUM_CLASS, is_training = is_training)\n",
    "        org_image, org_label = dataset.create_dataset()\n",
    "        image = preprocess_for_inception(org_image, is_training) # final image to train\n",
    "\n",
    "        label = one_hot_process(org_label, mapping_table, NUM_CLASS) # final label for training\n",
    "        # no need for shuffle, DatasetDataProvider do this for us\n",
    "        batch_images, batch_labels = tf.train.batch([image, label], BATCH_SIZE,\\\n",
    "                                            num_threads = INPUT_THREADS,\\\n",
    "                                            capacity = 1000 + 3 * BATCH_SIZE,\\\n",
    "                                            allow_smaller_final_batch = is_training, name = is_training and 'train_batch' or 'validation_batch')\n",
    "        \n",
    "        return batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with def_graph.as_default() as graph:\n",
    "    mapping_strings = tf.constant( [ str(key) for key in cvt_csv2tfrecord().keys() ] )\n",
    "    mapping_table = tf.contrib.lookup.index_table_from_tensor(mapping=mapping_strings, default_value=0)\n",
    "    batch_images, batch_labels = init_dataset(TRAIN_PATH + \"output_file*.tfrecords\", mapping_table)\n",
    "    batch_val_images, batch_val_labels = init_dataset(VAL_PATH + \"test_output_file*.tfrecords\", mapping_table, False)\n",
    "    with tf.device('/gpu:0'):\n",
    "        train_op, global_step, metrics_op, variables_to_restore, pred_op, lr, accuracy, total_loss = train_step(batch_images, batch_labels)\n",
    "        val_metrics_op, val_accuracy, val_predictions, val_probabilities = validation_step(batch_val_images, batch_val_labels)\n",
    "        real_val_label = tf.argmax(batch_val_labels, 1)\n",
    "    \n",
    "     # Summarize all gradients\n",
    "#     for var in tf.trainable_variables():\n",
    "#         print(var.name[:-2])\n",
    "#         if 'InceptionV3/Conv2d_1a_3x3/weights' == var.name[:-2]:\n",
    "#             tf.summary.tensor_summary(var.name[:-2], var) \n",
    "                    \n",
    "    summary_op = tf.summary.merge_all()\n",
    "    # Create a saver that restores only the pre-trained variables.\n",
    "    pre_train_saver = tf.train.Saver(variables_to_restore)\n",
    "    # Define an init function that loads the pretrained checkpoint.\n",
    "    # sess is the managed session passed by Supervisor\n",
    "    def load_pretrain(sess):\n",
    "        pre_train_saver.restore(sess, PRETRAINED_MODEL_PATH)\n",
    "\n",
    "    # no need for specify local_variables_initializer and tables_initializer, Supervisor will do this via default local_init_op\n",
    "    # init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer(), tf.tables_initializer())\n",
    "    init_op = tf.group(tf.global_variables_initializer())\n",
    "    # Pass the init function to the supervisor.\n",
    "    # - The init function is called _after_ the variables have been initialized by running the init_op.\n",
    "    # - use default tf.Saver() for ordinary save and restore\n",
    "    # - save checkpoint every 1.3 hours(4800)\n",
    "    # - manage summary in current process by ourselves for memory saving\n",
    "    # - no need to specify global_step, supervisor will find this automately\n",
    "    # - initialize order: checkpoint -> local_init_op -> init_op -> init_func\n",
    "    sv = tf.train.Supervisor(logdir=LOG_PATH, init_fn = load_pretrain, init_op = init_op, summary_op = None, save_model_secs=24000, checkpoint_basename='inception_v3_model.ckpt')\n",
    "    \n",
    "    final_loss = 0.\n",
    "    final_accuracy = 0.\n",
    "    training_state = True\n",
    "    with sv.managed_session(config=tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)) as sess:\n",
    "    #with sv.prepare_or_wait_for_session(config=tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)) as sess:\n",
    "\n",
    "        # Here sess was either initialized from the pre-trained-checkpoint or\n",
    "        # recovered from a checkpoint saved in a previous run of this code.\n",
    "        for step in range(int(num_steps_per_epoch * NUM_EPOCHES)):       \n",
    "            if sv.should_stop():\n",
    "                tf_logging.info('Supervisor emit finished!')\n",
    "                tf_logging.info('Current Loss: %s', loss)\n",
    "                tf_logging.info('Current Accuracy: %s', accuracy)\n",
    "                tf_logging.info('Saving current model to disk(maybe invalid).')\n",
    "                training_state = False\n",
    "                break\n",
    "\n",
    "            start_time = time.time()\n",
    "            if step % 1000 == 0:\n",
    "                with tf.device('/gpu:0'):\n",
    "                    _, _, _, summ = sess.run([train_op, global_step, metrics_op, summary_op])\n",
    "                sv.summary_computed(sess, summ)\n",
    "            else:\n",
    "                if step % 50 == 0:\n",
    "                    with tf.device('/gpu:0'):\n",
    "                        _, val_acc, val_pred, val_prob, real_label = sess.run([val_metrics_op, val_accuracy, val_predictions, val_probabilities, real_val_label])\n",
    "                    time_elapsed = time.time() - start_time\n",
    "                    tf_logging.info('Validation Speed: {:5.3f}sec/batch'.format(time_elapsed))\n",
    "                    tf_logging.info('Current Streaming ValAccuracy: {:5.3f}%'.format(val_acc*100.))\n",
    "                    tf_logging.info('Real Label: {}'.format(real_label))\n",
    "                    tf_logging.info('Pred Label: {}'.format(val_pred))\n",
    "                        \n",
    "                else:\n",
    "                    with tf.device('/gpu:0'):\n",
    "                        _, total_step, _, cur_loss, cur_acc, cur_lr = sess.run([train_op, global_step, metrics_op, total_loss, accuracy, lr])\n",
    "                    time_elapsed = time.time() - start_time\n",
    "                    if step % 10 == 0:\n",
    "                        final_loss = cur_loss\n",
    "                        final_accuracy = cur_acc\n",
    "                        tf_logging.info('Current Speed: {:5.3f}sec/batch'.format(time_elapsed))\n",
    "                        tf_logging.info('Current Streaming Accuracy: {:5.3f}%'.format(cur_acc*100.))\n",
    "                        tf_logging.info('Current Loss: {:5.3f}'.format(cur_loss))\n",
    "                        tf_logging.info('Epoch %s/%s, Global Step: %s', int(total_step / num_steps_per_epoch + 1), NUM_EPOCHES, total_step)\n",
    "                        tf_logging.info('Current Learning Rate: {}'.format(cur_lr))\n",
    "                \n",
    "                    \n",
    "        if training_state:\n",
    "            #We log the final training loss and accuracy\n",
    "            tf_logging.info('Final Loss: %s', final_loss)\n",
    "            tf_logging.info('Final Accuracy: %s', final_accuracy)\n",
    "            # Once all the training has been done, save the log files and checkpoint model\n",
    "            tf_logging.info('Finished training! Model saved.')\n",
    "        sv.saver.save(sess, sv.save_path, global_step = sv.global_step)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
