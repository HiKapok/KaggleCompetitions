{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=\n"
     ]
    }
   ],
   "source": [
    "# Running %env without any arguments\n",
    "# lists all environment variables\n",
    "\n",
    "# The line below sets the environment\n",
    "# variable CUDA_VISIBLE_DEVICES\n",
    "%env CUDA_VISIBLE_DEVICES = \n",
    "\n",
    "import io\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread, imsave\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import tf_logging\n",
    "import os.path\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.slim.python.slim.nets import inception\n",
    "from tensorflow.contrib.framework.python.ops.variables import get_or_create_global_step\n",
    "import inception_preprocessing\n",
    "import logging\n",
    "from scipy.sparse import *\n",
    "import tables as tb\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/'\n",
    "PROB_FILE_PATH = DATASET_PATH + 'keep/'\n",
    "ENSEMBLE_LIST = ['0.61245', '0.62080', '0.62191', '0.62625', '0.62490']\n",
    "CATEGORY_NAME_PATH = DATASET_PATH + 'category_names.csv'\n",
    "ID_FILE_PATH = PROB_FILE_PATH + 'ids.csv'\n",
    "OUTPUT_PATH = PROB_FILE_PATH + 'output_ensemble_{}.csv'\n",
    "NUM_CLASS = 5270\n",
    "NUM_TOPK = 20\n",
    "#TOTAL_EXAMPLES = 1524\n",
    "TOTAL_EXAMPLES = 3095080\n",
    "BATCH_SIZE = 256\n",
    "NUM_STEPS = int(TOTAL_EXAMPLES / BATCH_SIZE) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALL_MODEL_TO_ENSEMBLE = sum([[os.path.join(PROB_FILE_PATH, ENSEMBLE_LIST[index], filename) for filename in os.listdir(os.path.join(PROB_FILE_PATH, ENSEMBLE_LIST[index])) if filename.endswith(\".h5\")]  for index in range(len(ENSEMBLE_LIST))], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get TF logger\n",
    "log = logging.getLogger('tensorflow')\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# create file handler which logs even debug messages\n",
    "fh = logging.FileHandler(DATASET_PATH + 'product_test_ensemble.log')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "log.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cvt_csv2tfrecord():\n",
    "    count = 0\n",
    "    category_map = dict()\n",
    "    csv = pd.read_csv(CATEGORY_NAME_PATH).values\n",
    "    for row in csv:  \n",
    "        category_id, _ = row[0], row[1:]\n",
    "        category_map[category_id] = count\n",
    "        count += 1\n",
    "    return category_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def_graph = tf.Graph()\n",
    "with def_graph.as_default() as graph:\n",
    "    mapping_strings = tf.constant( [ str(key) for key in cvt_csv2tfrecord().keys() ] )\n",
    "    mapping_table = tf.contrib.lookup.index_table_from_tensor(mapping=mapping_strings, default_value=0)\n",
    "    \n",
    "    inv_table = tf.contrib.lookup.index_to_string_table_from_tensor(mapping_strings, default_value=\"0000000000\")\n",
    "\n",
    "    last_prob = tf.placeholder(tf.float32)\n",
    "    last_id = tf.placeholder(tf.int64)\n",
    "    test_probabilities = tf.placeholder(tf.float32, shape=(None, NUM_CLASS))\n",
    "    batch_id = tf.placeholder(tf.int64, shape=(None, 1))\n",
    "    with tf.device('/cpu:0'):\n",
    "        # concat betweent batches\n",
    "        batch_id_1d = tf.reshape(batch_id, [-1])\n",
    "        _, idx, count = tf.unique_with_counts(batch_id_1d)\n",
    "        \n",
    "        cur_id_tail, _cur_id_head = tf.dynamic_partition(batch_id_1d, tf.cast(tf.not_equal(idx, tf.shape(count)[0] - 1), tf.int32), 2)\n",
    "        with tf.control_dependencies([cur_id_tail, _cur_id_head]):\n",
    "            cur_id_head = tf.concat([last_id, _cur_id_head], axis = 0)\n",
    "      \n",
    "        cur_prob_tail, _cur_prob_head = tf.dynamic_partition(test_probabilities, tf.cast(tf.not_equal(idx, tf.shape(count)[0] - 1), tf.int32), 2)\n",
    "        with tf.control_dependencies([last_prob, _cur_prob_head]):\n",
    "            cur_prob_head = tf.concat([last_prob, _cur_prob_head], axis = 0)\n",
    "       \n",
    "        with tf.control_dependencies([cur_id_head, cur_prob_head]):\n",
    "            raw_id, idx, _ = tf.unique_with_counts(cur_id_head)\n",
    "            mean_prob = tf.segment_mean(cur_prob_head, idx)\n",
    "            mean_label = tf.string_to_number(inv_table.lookup(tf.argmax(mean_prob, 1)), out_type=tf.int64) \n",
    "        with tf.control_dependencies([mean_prob, mean_label]):\n",
    "            # last partition may have nothing to concat\n",
    "            raw_id_tail, idx_tail, _ = tf.unique_with_counts(cur_id_tail)\n",
    "            mean_prob_tail = tf.segment_mean(cur_prob_tail, idx_tail)\n",
    "            tail_label = tf.string_to_number(inv_table.lookup(tf.argmax(mean_prob_tail, 1)), out_type=tf.int64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:2017-10-28 11:03:32\n",
      "INFO:tensorflow:CurStep:1/12091 Speed: 0.057sec/batch.\n",
      "INFO:tensorflow:CurStep:501/12091 Speed: 0.047sec/batch.\n",
      "INFO:tensorflow:CurStep:1001/12091 Speed: 0.044sec/batch.\n",
      "INFO:tensorflow:CurStep:1501/12091 Speed: 0.048sec/batch.\n",
      "INFO:tensorflow:CurStep:2001/12091 Speed: 0.059sec/batch.\n",
      "INFO:tensorflow:CurStep:2501/12091 Speed: 0.046sec/batch.\n",
      "INFO:tensorflow:CurStep:3001/12091 Speed: 0.050sec/batch.\n",
      "INFO:tensorflow:CurStep:3501/12091 Speed: 0.050sec/batch.\n",
      "INFO:tensorflow:CurStep:4001/12091 Speed: 0.046sec/batch.\n",
      "INFO:tensorflow:CurStep:4501/12091 Speed: 0.043sec/batch.\n",
      "INFO:tensorflow:CurStep:5001/12091 Speed: 0.042sec/batch.\n",
      "INFO:tensorflow:CurStep:5501/12091 Speed: 0.051sec/batch.\n",
      "INFO:tensorflow:CurStep:6001/12091 Speed: 0.049sec/batch.\n",
      "INFO:tensorflow:CurStep:6501/12091 Speed: 0.061sec/batch.\n",
      "INFO:tensorflow:CurStep:7001/12091 Speed: 0.045sec/batch.\n",
      "INFO:tensorflow:CurStep:7501/12091 Speed: 0.047sec/batch.\n",
      "INFO:tensorflow:CurStep:8001/12091 Speed: 0.046sec/batch.\n",
      "INFO:tensorflow:CurStep:8501/12091 Speed: 0.046sec/batch.\n",
      "INFO:tensorflow:CurStep:9001/12091 Speed: 0.050sec/batch.\n",
      "INFO:tensorflow:CurStep:9501/12091 Speed: 0.045sec/batch.\n",
      "INFO:tensorflow:CurStep:10001/12091 Speed: 0.050sec/batch.\n",
      "INFO:tensorflow:CurStep:10501/12091 Speed: 0.053sec/batch.\n",
      "INFO:tensorflow:CurStep:11001/12091 Speed: 0.042sec/batch.\n",
      "INFO:tensorflow:CurStep:11501/12091 Speed: 0.044sec/batch.\n",
      "INFO:tensorflow:CurStep:12001/12091 Speed: 0.048sec/batch.\n",
      "INFO:tensorflow:Ensemble finished! \n",
      "INFO:tensorflow:2017-10-28 11:12:55\n"
     ]
    }
   ],
   "source": [
    "with def_graph.as_default() as graph:\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.tables_initializer(), tf.local_variables_initializer())\n",
    "    \n",
    "    tf_logging.info(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    save_file_name = OUTPUT_PATH.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        \n",
    "        cur_step = 0\n",
    "        last_feed_id = np.empty([0])\n",
    "        last_feed_prob = np.empty([0, NUM_CLASS])\n",
    "        h5_file_list = [tb.open_file(model, 'r') for model in ALL_MODEL_TO_ENSEMBLE]\n",
    "        #h5_file_list = []\n",
    "        id_list = pd.read_csv(ID_FILE_PATH)\n",
    "        for _step in range(NUM_STEPS):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            cur_batch_size = _step + 1 == NUM_STEPS and TOTAL_EXAMPLES - cur_step//NUM_TOPK or BATCH_SIZE\n",
    "            next_step = cur_step + cur_batch_size*NUM_TOPK\n",
    "\n",
    "            probs = np.zeros((cur_batch_size, NUM_CLASS), dtype=np.float) \n",
    "            labels = np.zeros(cur_batch_size, dtype=np.int)\n",
    "            for h5 in h5_file_list:\n",
    "                dense_matrix = csr_matrix((h5.root.prob[cur_step:next_step], (h5.root.row[cur_step:next_step], h5.root.col[cur_step:next_step])), shape=(cur_batch_size,NUM_CLASS)).toarray()\n",
    "                probs = np.add(probs, dense_matrix)\n",
    "            probs = np.divide(probs, 1.*len(h5_file_list))\n",
    "            labels = id_list[cur_step//NUM_TOPK:next_step//NUM_TOPK]\n",
    "            cur_step += cur_batch_size*NUM_TOPK\n",
    "\n",
    "            with tf.device('/cpu:0'):\n",
    "                last_feed_id, last_feed_prob, _mean_label, _mean_id, _tail_label, _tail_id = sess.run([cur_id_tail, cur_prob_tail, mean_label, raw_id, tail_label, raw_id_tail], feed_dict = {last_prob: last_feed_prob, last_id: last_feed_id, test_probabilities: probs, batch_id: labels })\n",
    "\n",
    "            df = pd.DataFrame({'_id' : _mean_id, 'category_id' : _mean_label})\n",
    "#             print({'_id' : _mean_id, 'category_id' : _mean_label})\n",
    "            if not os.path.isfile(save_file_name):\n",
    "                df.to_csv(save_file_name, mode='a', index=False, sep=',')\n",
    "            else:\n",
    "                df.to_csv(save_file_name, mode='a', index=False, sep=',', header=False)\n",
    "                \n",
    "            time_elapsed = time.time() - start_time\n",
    "            if _step % 500 == 0:\n",
    "                tf_logging.info('CurStep:{}/{} Speed: {:5.3f}sec/batch.'.format(cur_step//NUM_TOPK//BATCH_SIZE, NUM_STEPS, time_elapsed))\n",
    "            \n",
    "        for file in h5_file_list:\n",
    "            file.close()\n",
    "        df = pd.DataFrame({'_id' : _tail_id, 'category_id' : _tail_label})\n",
    "        df.to_csv(save_file_name, mode='a', index=False, sep=',', header=False)\n",
    "        tf_logging.info('Ensemble finished! ')\n",
    "        tf_logging.info(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# h5 = tb.open_file(ALL_MODEL_TO_ENSEMBLE[0], 'r')\n",
    "# print(h5.root.prob.shape)\n",
    "# print(h5.root.row.shape)\n",
    "# print(h5.root.col.shape)\n",
    "# print(h5.root.prob)\n",
    "# dense_matrix = csr_matrix((h5.root.prob[:100], (h5.root.row[:100], h5.root.col[:100])), shape=(20,NUM_CLASS)).toarray()\n",
    "\n",
    "# print(sorted(dense_matrix[2], reverse=True)[:5])\n",
    "# print(sorted(dense_matrix[3], reverse=True)[:5])\n",
    "# print(sorted(dense_matrix[4], reverse=True)[:5])\n",
    "# print(sorted(dense_matrix[5], reverse=True)[:5])\n",
    "#print(np.max(csr_matrix((h5.root.prob[:100], (h5.root.row[:100], h5.root.col[:100])), shape=(20,NUM_CLASS)).toarray()))\n",
    "#print(csr_matrix((h5.root.prob[:10], (h5.root.row[:10], h5.root.col[:10])), shape=(TOTAL_EXAMPLES,NUM_CLASS)).toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
