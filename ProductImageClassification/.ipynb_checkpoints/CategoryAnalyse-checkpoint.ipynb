{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/'\n",
    "CATEGORY_NAME_PATH = DATASET_PATH + 'category_names.csv'\n",
    "CATEGORY_TF_PATH = DATASET_PATH + 'category_names.tfrecords'\n",
    "CATEGORY_REMAP_PATH = DATASET_PATH + 'category_names_onehot.tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvt_csv2tfrecord(csv_name, tf_name):\n",
    "    count = 0\n",
    "    csv = pd.read_csv(csv_name).values\n",
    "    opts = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.ZLIB)\n",
    "    with tf.python_io.TFRecordWriter(tf_name, options=opts) as writer:\n",
    "        for row in csv:  \n",
    "            category_id, levels = row[0], row[1:]\n",
    "            #print(type(category_id), levels)  \n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                            'category_id': _int64_feature(category_id),\n",
    "                            'index': _int64_feature(count),\n",
    "                            'level1': _bytes_feature(levels[0].encode()),\n",
    "                            'level2': _bytes_feature(levels[1].encode()),\n",
    "                            'level3': _bytes_feature(levels[2].encode()),\n",
    "                        }))\n",
    "            writer.write(example.SerializeToString())\n",
    "            count += 1\n",
    "    print('total count: {}'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count: 5270\n"
     ]
    }
   ],
   "source": [
    "cvt_csv2tfrecord(CATEGORY_NAME_PATH, CATEGORY_TF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_examples(files):\n",
    "    filename_queue = tf.train.string_input_producer(files, num_epochs=1, shuffle=True) \n",
    "    opts = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.ZLIB)\n",
    "    reader = tf.TFRecordReader(options = opts)\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    input_features = tf.parse_single_example(\n",
    "          serialized_example,\n",
    "          features={\n",
    "                'category_id': tf.FixedLenFeature([], tf.int64),\n",
    "                'index': tf.FixedLenFeature([], tf.int64),\n",
    "                'level1': tf.FixedLenFeature([], tf.string),\n",
    "                'level2': tf.FixedLenFeature([], tf.string),\n",
    "                'level3': tf.FixedLenFeature([], tf.string),\n",
    "          })\n",
    "    # only part of the dictionary are needed\n",
    "    #return { 'category_id' : input_features['category_id'] }\n",
    "    return input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
