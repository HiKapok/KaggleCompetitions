{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "# Running %env without any arguments\n",
    "# lists all environment variables\n",
    "\n",
    "# The line below sets the environment\n",
    "# variable CUDA_VISIBLE_DEVICES\n",
    "%env CUDA_VISIBLE_DEVICES = 0\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import io\n",
    "import time\n",
    "import bson                       # this is installed with the pymongo package\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread, imsave, imshow\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import tf_logging\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.training import add_gradients_summaries\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.training import optimizer as tf_optimizer\n",
    "from tensorflow.python.ops import variables as tf_variables\n",
    "import os.path\n",
    "import tensorflow.contrib.slim as slim\n",
    "import inception_preprocessing\n",
    "from tensorflow.contrib.slim.python.slim.nets import inception\n",
    "import logging\n",
    "import resnet2\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/'\n",
    "RESNET_MODEL_PATH = DATASET_PATH + 'Resnet/logs101-new/resnet101_v2_model.ckpt-216292'\n",
    "INCEPTION_MODEL_PATH = DATASET_PATH + 'logs_aux/inception_v3_model.ckpt-47255'\n",
    "LOG_PATH = DATASET_PATH + 'Resnet/temp/'\n",
    "TRAIN_PATH = DATASET_PATH + 'Split1/Train/'\n",
    "RESNET_OUTPUT_TRAIN_PATH = '/media/rs/FC6CDC6F6CDC25E4/ResnetHardTrain/'\n",
    "INCEPTION_OUTPUT_TRAIN_PATH = '/media/rs/FC6CDC6F6CDC25E4/InceptionHardTrain/'\n",
    "CATEGORY_NAME_PATH = DATASET_PATH + 'category_names.csv'\n",
    "BATCH_SIZE = 256#256\n",
    "\n",
    "IMAGE_WIDTH = 180\n",
    "IMAGE_HEIGHT = 180\n",
    "NUM_CLASS = 5270\n",
    "LEVEL0_CLASS = 49\n",
    "LEVEL1_CLASS = 483\n",
    "\n",
    "TOTAL_EXAMPLES = 10051704\n",
    "NUM_STEPS = int(TOTAL_EXAMPLES / BATCH_SIZE) + 1\n",
    "INPUT_THREADS = 12\n",
    "\n",
    "moving_average_decay = 0.96\n",
    "hard_example_thres = 3.\n",
    "out_file_num = 600\n",
    "\n",
    "MODEL_TO_RUN = 'resnet'\n",
    "\n",
    "if os.path.exists(RESNET_OUTPUT_TRAIN_PATH) is not True: os.makedirs(RESNET_OUTPUT_TRAIN_PATH)\n",
    "if os.path.exists(INCEPTION_OUTPUT_TRAIN_PATH) is not True: os.makedirs(INCEPTION_OUTPUT_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get TF logger\n",
    "log = logging.getLogger('tensorflow')\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# create file handler which logs even debug messages\n",
    "fh = logging.FileHandler(DATASET_PATH + 'tensorflow_resnet_hard_example.log')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "log.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_for_inception(input_image, is_training = False):\n",
    "    return inception_preprocessing.preprocess_image(input_image, 160, 160, is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabelMapping(object):\n",
    "    def __init__(self, catogory_file_path):\n",
    "        super(LabelMapping, self).__init__()\n",
    "        self._category_level_csv = catogory_file_path\n",
    "        self._category_map, self._category_level0_map, self._category_level1_map, self._len_level0, self._len_level1 = self.cvt_csv2tfrecord()\n",
    "        self._mapping_strings = tf.constant( [ str(key) for key in self._category_map.keys() ] )\n",
    "\n",
    "        self._mapping_table = tf.contrib.lookup.index_table_from_tensor(mapping=self._mapping_strings, default_value=0) \n",
    "        \n",
    "        self._level0_table = tf.contrib.lookup.HashTable(tf.contrib.lookup.KeyValueTensorInitializer(list(self._category_level0_map.keys()), list(self._category_level0_map.values()), tf.int64, tf.int64), 0)\n",
    "        self._level1_table = tf.contrib.lookup.HashTable(tf.contrib.lookup.KeyValueTensorInitializer(list(self._category_level1_map.keys()), list(self._category_level1_map.values()), tf.int64, tf.int64), 0)\n",
    "\n",
    "    @property\n",
    "    def category_map(self):\n",
    "        return self._category_map\n",
    "    @property\n",
    "    def level0_table(self):\n",
    "        return self._level0_table\n",
    "    @property\n",
    "    def level1_table(self):\n",
    "        return self._level1_table\n",
    "    @property\n",
    "    def len_level0(self):\n",
    "        return self._len_level0\n",
    "    @property\n",
    "    def len_level1(self):\n",
    "        return self._len_level1\n",
    "    @property\n",
    "    def mapping_table(self):\n",
    "        return self._mapping_table\n",
    "    \n",
    "    def cvt_csv2tfrecord(self):\n",
    "        level0_map, level1_map = self.create_level_map()\n",
    "        count = 0\n",
    "        category_map = dict()\n",
    "        category_level0_map = dict()\n",
    "        category_level1_map = dict()\n",
    "        csv = pd.read_csv(self._category_level_csv).values\n",
    "        for row in csv:  \n",
    "            category_id, level0, level1 = row[0], row[1], row[2]\n",
    "            category_map[category_id] = count\n",
    "            category_level0_map[int(category_id)] = level0_map[level0]\n",
    "            category_level1_map[int(category_id)] = level1_map[level1]\n",
    "            count += 1\n",
    "\n",
    "        return category_map, category_level0_map, category_level1_map, len(level0_map), len(level1_map)\n",
    "\n",
    "    def create_level_map(self):\n",
    "        csv = pd.read_csv(self._category_level_csv).values\n",
    "        level_list = [list(), list()]\n",
    "        for row in csv: \n",
    "            for level in range(1,3):\n",
    "                if row[level] not in level_list[level-1]:\n",
    "                    level_list[level-1].append(row[level])\n",
    "        return dict(zip(level_list[0], range(len(level_list[0])))), dict(zip(level_list[1], range(len(level_list[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CdiscountDataset(object):\n",
    "    def __init__(self, data_path, file_begin_match, label_mapping, num_examples, num_classes, buffer_size, batch_size, num_epochs, is_training):\n",
    "        super(CdiscountDataset, self).__init__()\n",
    "        #self._data_file_list = [ os.path.join(data_path, x) for x in os.listdir(data_path) if lambda x: os.path.isfile(x) and x.startswith(file_begin_match) ]\n",
    "        self._data_file_list = data_path + file_begin_match + '*'\n",
    "        self._num_examples = num_examples\n",
    "        self._num_classes = num_classes\n",
    "        self._batch_size = batch_size\n",
    "        self._buffer_size = buffer_size\n",
    "        self._num_epochs = num_epochs\n",
    "        self._is_training = is_training\n",
    "        self._category_map = label_mapping.category_map\n",
    "        self._level0_table = label_mapping.level0_table\n",
    "        self._level1_table = label_mapping.level1_table\n",
    "        self._len_level0 = label_mapping.len_level0\n",
    "        self._len_level1 = label_mapping.len_level1\n",
    "        self._mapping_table = label_mapping.mapping_table\n",
    "    \n",
    "    def create_dataset(self):\n",
    "        opts = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.ZLIB)\n",
    "        reader = lambda : tf.TFRecordReader(options=opts)\n",
    "        keys_to_features = {\n",
    "            'img_raw': tf.FixedLenFeature([], tf.string, default_value=''),\n",
    "            'product_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n",
    "            # notice that we don't have this feature in our TFRecord, so always default provided\n",
    "            'format': tf.FixedLenFeature([], tf.string, default_value='jpg'),\n",
    "            'category_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64))\n",
    "        }\n",
    "\n",
    "        items_to_handlers = {\n",
    "            # automated decode image from features in FixedLenFeature\n",
    "            'image': slim.tfexample_decoder.Image(image_key='img_raw', format_key='format'),\n",
    "            'raw_image': slim.tfexample_decoder.Tensor('img_raw'),\n",
    "            'label': slim.tfexample_decoder.Tensor('category_id'),\n",
    "            'product_id': slim.tfexample_decoder.Tensor('product_id')\n",
    "        }\n",
    "\n",
    "        decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\n",
    "        \n",
    "        self._dataset = slim.dataset.Dataset(\n",
    "            data_sources = self._data_file_list,\n",
    "            decoder = decoder,\n",
    "            reader = reader,\n",
    "            # num_readers = 8,\n",
    "            num_samples = self._num_examples,\n",
    "            #num_classes = self._num_classes,\n",
    "            items_to_descriptions = None)\n",
    "        \n",
    "        # notice that DatasetDataProvider can automate shuffle the examples by ParallelReader using its RandomShuffleQueue\n",
    "        self._data_provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "            self._dataset,\n",
    "            num_readers = INPUT_THREADS,\n",
    "            shuffle = True, # default is True\n",
    "            num_epochs = self._num_epochs,\n",
    "            common_queue_capacity = self._buffer_size + 4 * self._batch_size,\n",
    "            common_queue_min = self._buffer_size,\n",
    "            scope = 'test_files')\n",
    "        \n",
    "        raw_org_image, org_image, org_label, product_id = self._data_provider.get(['raw_image', 'image', 'label', 'product_id'])\n",
    "\n",
    "        image = preprocess_for_inception(org_image, self._is_training) # final image to train\n",
    " \n",
    "        batch_org_images, batch_images, batch_labels, batch_category_id, batch_product_id = \\\n",
    "                tf.train.batch([raw_org_image, image, self._mapping_table.lookup(tf.as_string(org_label)), org_label, product_id],\\\n",
    "                self._batch_size,\\\n",
    "                num_threads = INPUT_THREADS,\\\n",
    "                capacity = self._buffer_size + 4 * self._batch_size,\\\n",
    "                allow_smaller_final_batch = self._is_training, name = 'test_batch')\n",
    "        \n",
    "        return batch_org_images, batch_images, batch_labels, batch_category_id, batch_product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def_graph = tf.Graph()\n",
    "with def_graph.as_default() as graph:\n",
    "    def resnet_v2_101_test_step(input_examples): \n",
    "        with slim.arg_scope(resnet2.resnet_arg_scope()):\n",
    "            logits, end_points = resnet2.resnet_v2_101(input_examples, NUM_CLASS, is_training=False)\n",
    "        \n",
    "            variable_averages = tf.train.ExponentialMovingAverage(moving_average_decay)\n",
    "            variables_to_restore = variable_averages.variables_to_restore()\n",
    "            #variables_to_restore = slim.get_variables_to_restore()\n",
    "            \n",
    "            #State the metrics that you want to predict. We get a predictions that is not one_hot_encoded.\n",
    "            predictions = tf.argmax(tf.squeeze(end_points['predictions']), 1)\n",
    "            probabilities = tf.squeeze(end_points['predictions'])\n",
    "\n",
    "            return predictions, probabilities, variables_to_restore\n",
    "    def inception_aux_test_step(input_examples): \n",
    "        with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "            # here logits is the pre-softmax activations\n",
    "            logits, end_points = inception.inception_v3(\n",
    "                input_examples,\n",
    "                num_classes = NUM_CLASS,\n",
    "                is_training=False)\n",
    "            variable_averages = tf.train.ExponentialMovingAverage(moving_average_decay)\n",
    "            variables_to_restore = variable_averages.variables_to_restore()\n",
    "            #variables_to_restore = slim.get_variables_to_restore()\n",
    "\n",
    "            #State the metrics that you want to predict. We get a predictions that is not one_hot_encoded.\n",
    "            predictions = tf.argmax(end_points['Predictions'], 1)\n",
    "            probabilities = end_points['Predictions']\n",
    "\n",
    "            return predictions, probabilities, variables_to_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /media/rs/0E06CD1706CD0127/Kapok/kaggle/Resnet/logs101-new/resnet101_v2_model.ckpt-216292\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:Current Speed: 3.448sec/batch\n",
      "INFO:tensorflow:Step 0/39265\n",
      "INFO:tensorflow:Roughly select ratio  31.25%.\n",
      "INFO:tensorflow:Roughly 37.608 hours to go.\n",
      "INFO:tensorflow:Current Speed: 0.633sec/batch\n",
      "INFO:tensorflow:Step 1000/39265\n",
      "INFO:tensorflow:Roughly select ratio  34.38%.\n",
      "INFO:tensorflow:Roughly  6.730 hours to go.\n"
     ]
    }
   ],
   "source": [
    "with def_graph.as_default() as graph:\n",
    "    label_mapping = LabelMapping(CATEGORY_NAME_PATH)\n",
    "    train_dataset = CdiscountDataset(TRAIN_PATH, 'output_file', label_mapping, TOTAL_EXAMPLES, NUM_CLASS, 8000, BATCH_SIZE, 1, False)\n",
    "    \n",
    "    batch_org_images, batch_images, batch_labels, batch_category_ids, batch_product_ids = train_dataset.create_dataset()\n",
    "    \n",
    "    hard_train_examples = dict()\n",
    "    with tf.device('/gpu:0'):\n",
    "        if(MODEL_TO_RUN == 'resnet'):\n",
    "            test_predictions, test_probabilities, variables_to_restore = resnet_v2_101_test_step(batch_images)\n",
    "        if(MODEL_TO_RUN == 'inception'):\n",
    "            test_predictions, test_probabilities, variables_to_restore = inception_aux_test_step(batch_images)\n",
    "        # after stack\n",
    "        # [ [0, real0],\n",
    "        #   [1, real1]\n",
    "        #   ....\n",
    "        # ]\n",
    "        # after tf.gather_nd\n",
    "        # indices = [[0, 0], [1, 1]]\n",
    "        # params = [['a', 'b'], ['c', 'd']]\n",
    "        # output = ['a', 'd']\n",
    "        real_label_pos_value = tf.gather_nd( test_probabilities, tf.stack((tf.range(test_probabilities.get_shape()[0],\n",
    "                                            dtype=batch_labels.dtype), batch_labels), axis=1) )\n",
    "        \n",
    "        batch_max_prob = tf.reduce_max(test_probabilities, axis = 1)\n",
    "        \n",
    "        false_true_ratio = tf.div(batch_max_prob, real_label_pos_value)\n",
    "        ratio_thres = tf.add(tf.zeros_like(false_true_ratio), tf.constant(hard_example_thres, dtype=tf.float32))\n",
    "        partition_mask = tf.cast(tf.greater(false_true_ratio, ratio_thres), tf.int32)\n",
    "        \n",
    "        _, hard_train_examples['img_raw'] = tf.dynamic_partition(batch_org_images, partition_mask, 2)\n",
    "        _, hard_train_examples['category_id'] = tf.dynamic_partition(batch_category_ids, partition_mask, 2)\n",
    "        _, hard_train_examples['product_id'] = tf.dynamic_partition(batch_product_ids, partition_mask, 2)\n",
    "        \n",
    "        cur_hard_count = tf.count_nonzero(partition_mask)\n",
    "   \n",
    "    if(MODEL_TO_RUN == 'inception'):\n",
    "        tfrecords_filename = [INCEPTION_OUTPUT_TRAIN_PATH + 'output_file{:d}.tfrecords'.format(index + 1) for index in range(out_file_num)]\n",
    "    if(MODEL_TO_RUN == 'resnet'):\n",
    "        tfrecords_filename = [RESNET_OUTPUT_TRAIN_PATH + 'output_file{:d}.tfrecords'.format(index + 1) for index in range(out_file_num)]\n",
    "    \n",
    "    opts = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.ZLIB)\n",
    "\n",
    "    try:\n",
    "        writer_list = [tf.python_io.TFRecordWriter(file_name, options = opts) for file_name in tfrecords_filename]\n",
    "    except Exception as e:\n",
    "        print('writer_list create failed!')\n",
    "\n",
    "    pre_train_saver = tf.train.Saver(variables_to_restore)\n",
    "    # Define an init function that loads the pretrained checkpoint.\n",
    "    # sess is the managed session passed by Supervisor\n",
    "    def load_pretrain(sess, path):\n",
    "        pre_train_saver.restore(sess, path)\n",
    "        #pre_train_saver.restore(sess, RESNET_MODEL_PATH)\n",
    "    if(MODEL_TO_RUN == 'inception'):\n",
    "        load_pretrain_func = lambda sess : load_pretrain(sess, INCEPTION_MODEL_PATH)\n",
    "    if(MODEL_TO_RUN == 'resnet'):\n",
    "        load_pretrain_func = lambda sess : load_pretrain(sess, RESNET_MODEL_PATH)\n",
    "    # no need for specify local_variables_initializer and tables_initializer, Supervisor will do this via default local_init_op\n",
    "    # init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer(), tf.tables_initializer())\n",
    "    init_op = tf.group(tf.global_variables_initializer())\n",
    "    #init_op = tf.group(train_iterator_initializer, val_iterator_initializer, tf.global_variables_initializer())\n",
    "    \n",
    "    # Pass the init function to the supervisor.\n",
    "    # - The init function is called _after_ the variables have been initialized by running the init_op.\n",
    "    # - use default tf.Saver() for ordinary save and restore\n",
    "    # - save checkpoint every 1.3 hours(4800)\n",
    "    # - manage summary in current process by ourselves for memory saving\n",
    "    # - no need to specify global_step, supervisor will find this automately\n",
    "    # - initialize order: checkpoint -> local_init_op -> init_op -> init_func\n",
    "    sv = tf.train.Supervisor(logdir=LOG_PATH, init_fn = load_pretrain_func, init_op = init_op, summary_op = None, save_model_secs=0)\n",
    "\n",
    "    total_hard_examples = 0\n",
    "    config = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)\n",
    "    #config.gpu_options.allow_growth = True\n",
    "    with sv.managed_session(config=config) as sess:\n",
    "    #with sv.prepare_or_wait_for_session(config=tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)) as sess:\n",
    "        #sess.run(iterator_initalizer)\n",
    "        # Here sess was either initialized from the pre-trained-checkpoint or\n",
    "        # recovered from a checkpoint saved in a previous run of this code.\n",
    "        for step in range(NUM_STEPS):        \n",
    "            if sv.should_stop():\n",
    "                tf_logging.info('Supervisor emit finished!')\n",
    "                break\n",
    "\n",
    "            start_time = time.time()\n",
    "            cur_train_writer = writer_list[step % out_file_num]\n",
    "            \n",
    "            with tf.device('/gpu:0'):\n",
    "                hard_count, cur_ratio, cur_mask, train_list_img, train_list_catogory_id, train_list_product_id = sess.run([cur_hard_count, false_true_ratio, partition_mask, hard_train_examples['img_raw'], hard_train_examples['category_id'], hard_train_examples['product_id']])\n",
    "            \n",
    "            for index in range(hard_count):\n",
    "                example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                    'img_raw': _bytes_feature(train_list_img[index]),\n",
    "                    'product_id': _int64_feature(train_list_product_id[index]),\n",
    "                    'category_id': _int64_feature(train_list_catogory_id[index])\n",
    "                }))\n",
    "                cur_train_writer.write(example.SerializeToString())\n",
    "\n",
    "            total_hard_examples += hard_count    \n",
    "            time_elapsed = time.time() - start_time\n",
    "#             print(hard_count)\n",
    "#             print(cur_ratio)\n",
    "#             print(cur_mask)\n",
    "#             print(train_list_product_id)\n",
    "#             print(train_list_catogory_id)\n",
    "#             print(train_list_img)\n",
    "#             if step % 50000 == 1:\n",
    "#                  break\n",
    "            if step % 1000 == 0:\n",
    "                tf_logging.info('Current Speed: {:5.3f}sec/batch'.format(time_elapsed))    \n",
    "                tf_logging.info('Step {}/{}'.format(step, NUM_STEPS))\n",
    "                tf_logging.info('Roughly select ratio {:6.2f}%.'.format(hard_count*100./BATCH_SIZE))\n",
    "                tf_logging.info('Roughly {:6.3f} hours to go.'.format(  time_elapsed*( (NUM_STEPS-step) > 0 and (NUM_STEPS-step)/3600. or 0.001 )  ))\n",
    "    if writer_list:\n",
    "        for f in writer_list:\n",
    "            f.close()\n",
    "    tf_logging.info('Total Examples: {}'.format(total_hard_examples))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
