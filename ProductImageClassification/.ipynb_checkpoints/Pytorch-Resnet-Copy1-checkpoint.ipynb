{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "# The line below sets the environment\n",
    "# variable CUDA_VISIBLE_DEVICES\n",
    "get_ipython().magic('env CUDA_VISIBLE_DEVICES = ')\n",
    "#%env CUDA_VISIBLE_DEVICES = 0\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread, imsave, imshow, imresize\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.)\n",
    "tf_sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options))\n",
    "# now tensorflow will assume there not exist gpu\n",
    "# use this tf_session following, and close in the end\n",
    "#tf_sess.close()\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import time\n",
    "import io\n",
    "from datetime import datetime\n",
    "import gc # garbage collector\n",
    "import logging\n",
    "get_ipython().magic('env CUDA_VISIBLE_DEVICES = 0')\n",
    "from tensorboard_logger import configure, log_value\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch_resnet\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "get_ipython().magic('matplotlib inline')\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "get_ipython().magic('load_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/'\n",
    "PRETRAINED_MODEL_PATH = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytorch/cdiscount/models/resnet152-b121ed2d.pth'\n",
    "LOG_DIR = DATASET_PATH + 'pytorch/cdiscount/logs_resnet'\n",
    "LR_FILE_PATH = DATASET_PATH + 'pytorch/cdiscount/logs_resnet/lr_setting/resnet_lr_setting'\n",
    "TRAIN_PATH = DATASET_PATH + 'Split/Train/'\n",
    "#TRAIN_PATH = '/media/rs/FC6CDC6F6CDC25E4/resample_dataset2/'\n",
    "VAL_PATH = DATASET_PATH + 'Split/Validation/'\n",
    "TEST_PATH = DATASET_PATH + 'Test/'\n",
    "CATEGORY_NAME_PATH = DATASET_PATH + 'category_names.csv'\n",
    "CATEGORY_WEIGHT_PATH = DATASET_PATH + 'catogory_with_weight.csv'\n",
    "\n",
    "# following is non-resampled, and only 10mil\n",
    "LEVEL1_WEIGHT = [1.817, 1.528, 1.056, 2.174, 1.622, 2.531, 2.663, 1.103, 1.935, 1.937, 2.898, 1.279, 2.923, 1.095, 2.086, 3.0, 2.218, 3.0, 3.0, 2.123, 3.0, 1.038, 3.0, 3.0, 3.0, 3.0, 1.817, 1.448, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.955, 3.0, 1.946, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0]\n",
    "\n",
    "BATCH_SIZE = 128#256\n",
    "\n",
    "IMAGE_WIDTH = 180\n",
    "IMAGE_HEIGHT = 180\n",
    "NUM_CLASS = 5270\n",
    "LEVEL1_CLASS = 49\n",
    "LEVEL2_CLASS = 483\n",
    "# validation examples num: 2319624\n",
    "# train examples num: 10051704\n",
    "# total step: 157057\n",
    "TOTAL_EXAMPLES = 12301740\n",
    "VAL_EXAMPLES = 69588\n",
    "\n",
    "NUM_EPOCHES = 12\n",
    "EPOCHES_OVER = 8\n",
    "\n",
    "INPUT_THREADS = 8\n",
    "\n",
    "save_time_interval = 720\n",
    "log_step_interval = 10\n",
    "\n",
    "initial_learning_rate = 0.01#0.0004\n",
    "stop_learning_rate = 0.0000001\n",
    "momentum = 0.9\n",
    "num_steps_per_train_epoch = int(TOTAL_EXAMPLES / (BATCH_SIZE)) + 1\n",
    "num_steps_per_val_epoch = int(VAL_EXAMPLES / (BATCH_SIZE)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_logging(logger_name, logger_file_name):\n",
    "    log = logging.getLogger(logger_name)\n",
    "    log.setLevel(logging.DEBUG)\n",
    "\n",
    "    # create formatter and add it to the handlers\n",
    "    print_formatter = logging.Formatter('%(message)s')\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(name)s_%(levelname)s: %(message)s')\n",
    "\n",
    "    # create file handler which logs even debug messages\n",
    "    fh = logging.FileHandler(logger_file_name, mode='w')\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    fh.setFormatter(file_formatter)\n",
    "    log.addHandler(fh)\n",
    "    # both output to console and file\n",
    "    consoleHandler = logging.StreamHandler()\n",
    "    consoleHandler.setFormatter(print_formatter)\n",
    "    log.addHandler(consoleHandler)\n",
    "    \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "here is an info message.\n"
     ]
    }
   ],
   "source": [
    "log = set_logging('CDiscount', DATASET_PATH + 'pytorch/cdiscount/resnet_pytorch.log')\n",
    "log.info('here is an info message.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Saver(object):\n",
    "    def __init__(self, log_dir, ckeckpoint_name, max_to_keep=5):\n",
    "        super(Saver, self).__init__()\n",
    "        self._log_dir = log_dir\n",
    "        self._max_to_keep = max_to_keep\n",
    "        self._ckeckpoint_container_file = os.path.join(self._log_dir, 'checkpoint')\n",
    "        self._ckeckpoint_name = os.path.join(self._log_dir, ckeckpoint_name)\n",
    "        self._best_ckeckpoint_name = os.path.join(self._log_dir, 'best_checkpoint')\n",
    "        os.makedirs(self._log_dir, exist_ok=True)\n",
    "        os.makedirs(self._best_ckeckpoint_name, exist_ok=True)\n",
    "        self._best_ckeckpoint_name = os.path.join(self._best_ckeckpoint_name, ckeckpoint_name)\n",
    "    def save_checkpoint(self, model_state_dict, other_state_dict, tag, is_best=False):\n",
    "        checkpoint_list = list()\n",
    "        if os.path.exists(self._ckeckpoint_container_file):\n",
    "            with open(self._ckeckpoint_container_file, 'r') as checkpoint_file:\n",
    "                for index, line in enumerate(checkpoint_file):\n",
    "                    if index == 0: continue\n",
    "                    if line.strip() != '':\n",
    "                        checkpoint_list.append(line.strip())\n",
    "        if not is_best: \n",
    "            model_save_name = (self._ckeckpoint_name + '_pytorch_state_{}_{}.pth').format(tag, datetime.now().strftime('%Y-%m-%d_%H_%M_%S'))\n",
    "        else:\n",
    "            model_save_name = (self._best_ckeckpoint_name + '_pytorch_state_{}_{}.pth').format(tag, datetime.now().strftime('%Y-%m-%d_%H_%M_%S'))\n",
    "        checkpoint_list.append(model_save_name)\n",
    "\n",
    "        torch.save(model_state_dict, model_save_name)\n",
    "        torch.save(other_state_dict, model_save_name.replace('state','others'))\n",
    "\n",
    "        log.info('model saved: {}.'.format(model_save_name))\n",
    "\n",
    "        # remove checkpoint older than 5\n",
    "        if len(checkpoint_list) > self._max_to_keep:\n",
    "            checkpoint_list_to_delete = checkpoint_list[:-self._max_to_keep]\n",
    "            checkpoint_list = checkpoint_list[-self._max_to_keep:]\n",
    "            for model_file in checkpoint_list_to_delete:\n",
    "                if os.path.isfile(model_file): os.remove(model_file)\n",
    "                model_file = model_file.replace('state','others')\n",
    "                if os.path.isfile(model_file):  os.remove(model_file)\n",
    "        with open(self._ckeckpoint_container_file, 'w') as outfile:\n",
    "            outfile.write(model_save_name+'\\n')\n",
    "            for line in checkpoint_list:\n",
    "                outfile.write(line+'\\n')\n",
    "\n",
    "    def restore_from_checkpoint(self, model, step=None):\n",
    "        checkpoint_filename = None\n",
    "        if os.path.exists(self._ckeckpoint_container_file):\n",
    "            with open(self._ckeckpoint_container_file, 'r') as checkpoint_file:\n",
    "                for _, line in enumerate(checkpoint_file):\n",
    "                    line = line.strip()\n",
    "                    if line != '':\n",
    "                        # get the first one\n",
    "                        if step is None:\n",
    "                            checkpoint_filename = line\n",
    "                            break\n",
    "                        # get the specified one\n",
    "                        elif str(step) in line:\n",
    "                            checkpoint_filename = line\n",
    "                            break\n",
    "        if (not os.path.isdir(self._log_dir)) or (checkpoint_filename is None):\n",
    "            return None\n",
    "\n",
    "        model.load_state_dict(torch.load(checkpoint_filename, map_location=lambda storage, loc: storage))    \n",
    "\n",
    "        log.info('model resotred from: {}.'.format(checkpoint_filename))\n",
    "\n",
    "        return torch.load(checkpoint_filename.replace('state','others'))  \n",
    "\n",
    "class TimeRecorder(object):\n",
    "    def __init__(self):\n",
    "        super(TimeRecorder, self).__init__()\n",
    "        self._tick_map = dict()\n",
    "        self._recorder = dict()\n",
    "        self._use_time = dict()\n",
    "        self._last_interval = dict()\n",
    "    # register at the very begining\n",
    "    # when not use time, call reset_event with your initial value at each start\n",
    "    def register_event(self, name, tick, use_time=True):\n",
    "        self._tick_map[name] = tick\n",
    "        self._last_interval[name] = 0\n",
    "        self._recorder[name] = 0\n",
    "        if use_time:\n",
    "            self._recorder[name] = time.time() \n",
    "        self._use_time[name] = use_time\n",
    "    def reset_event(self, name, criterion=None):\n",
    "        if self._use_time[name]: self._recorder[name] = time.time()\n",
    "        elif criterion is not None: self._recorder[name] = criterion\n",
    "        self._last_interval[name] = 0\n",
    "    def cancel_event(self, name):\n",
    "        self._tick_map.pop(name, None)\n",
    "        self._last_interval.pop(name, None)\n",
    "        self._recorder.pop(name, None)\n",
    "        self._use_time.pop(name, None)\n",
    "    # you can call this to get how log elapsed after you get True from check_for_me\n",
    "    def how_long_before(self, name):\n",
    "        return self._last_interval[name]\n",
    "    def check_for_me(self, name, criterion=None):\n",
    "        if self._use_time[name]:\n",
    "            if time.time() - self._recorder[name] > self._tick_map[name]:\n",
    "                self._last_interval[name] = time.time() - self._recorder[name]\n",
    "                self._recorder[name] = time.time()\n",
    "                return True\n",
    "        elif criterion is not None:\n",
    "            if criterion - self._recorder[name] > self._tick_map[name]:\n",
    "                self._last_interval[name] = criterion - self._recorder[name]\n",
    "                self._recorder[name] = criterion\n",
    "                return True\n",
    "        return False\n",
    "def load_pretrain_file(net, pretrain_file, skip=[]):\n",
    "    pretrain_state_dict = torch.load(pretrain_file)\n",
    "    state_dict = net.state_dict()\n",
    "    keys = list(state_dict.keys())\n",
    "    for key in keys:\n",
    "        if any(s in key for s in skip):\n",
    "            continue\n",
    "        pretrain_key = key\n",
    "        #if 'layer0.0.conv.' in key: pretrain_key=key.replace('layer0.0.conv.',  'conv1.' )\n",
    "        state_dict[key] = pretrain_state_dict[pretrain_key]\n",
    "        \n",
    "    net.load_state_dict(state_dict)\n",
    "    return net\n",
    "\n",
    "class CriterionSmooth(object):\n",
    "    def __init__(self):\n",
    "        super(CriterionSmooth, self).__init__()\n",
    "        self._history = dict()\n",
    "        self._factor = dict()\n",
    "        self._just_add = dict()\n",
    "    def register_smooth(self, name, factor=0.6):\n",
    "        self._history[name] = 0.\n",
    "        self._just_add[name] = False\n",
    "        if factor < 0: self._just_add[name] = True\n",
    "        if factor > 1.: factor=1.\n",
    "        self._factor[name] = 1. - factor\n",
    "    def push_new_value(self, name, value):\n",
    "        if self._just_add[name]: self._history[name] = self._history[name] + value\n",
    "        else: self._history[name] = self._history[name] * (1.-self._factor[name]) + value*self._factor[name]\n",
    "        return value\n",
    "    def smooth_value(self, name):\n",
    "        return self._history[name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_lr_scheduler(optimizer, epoch, init_lr=0.01, lr_decay_epoch=1):\n",
    "    lr = init_lr * (0.27**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if lr < 0.000002: lr = 0.000002\n",
    "        \n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        log.info('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer\n",
    "def read_learning_rate(cur_step, num_steps_per_epoch):\n",
    "    def inner_lr_parser(interval_start, interval_end, lr, dict_in, default_lr, use_epoch_percent, num_steps_per_epoch):\n",
    "        lr = default_lr * lr\n",
    "        if use_epoch_percent:\n",
    "            interval_start = num_steps_per_epoch * interval_start\n",
    "            interval_end = num_steps_per_epoch * interval_end\n",
    "        interval_start = int(interval_start)\n",
    "        interval_end = int(interval_end)\n",
    "        if (interval_start < interval_end) and (lr > 0):\n",
    "            dict_in[(interval_start, interval_end)] = lr\n",
    "            \n",
    "    lr_map = dict()\n",
    "    default_lr = initial_learning_rate\n",
    "    stop_lr = stop_learning_rate\n",
    "    line_index = -1\n",
    "    use_epoch_percent = True\n",
    "    if os.path.exists(LR_FILE_PATH):\n",
    "        with open(LR_FILE_PATH, 'r') as lr_setting_file:\n",
    "            for _, line in enumerate(lr_setting_file):\n",
    "                line = line.strip()\n",
    "                if (line != '') and (not line.startswith('#')):\n",
    "                    line_index += 1\n",
    "                    if line_index == 0:\n",
    "                        default_lr = float(line.split(':')[-1].strip())\n",
    "                        continue\n",
    "                    if line_index == 1:\n",
    "                        stop_lr = float(line.split(':')[-1].strip())\n",
    "                        continue\n",
    "                    if line_index == 2:\n",
    "                        use_epoch_percent = ('EPOCHES_PERCENT' in (line.split(':')[-1].strip()))\n",
    "                        continue\n",
    "                    # this is a list desciption\n",
    "                    if line.startswith('['):\n",
    "                        line = [float(s.strip()) for s in line[1:-1].strip().split()]\n",
    "                        step_interval = (line[1] - line[0])/line[-1]\n",
    "                        lr_interval = (line[3] - line[2])/line[-1]\n",
    "                        begin = line[0]\n",
    "                        lr_begin = line[2]\n",
    "                        for index in range(int(line[-1])):\n",
    "                            inner_lr_parser(begin, begin+step_interval, lr_begin, lr_map, default_lr, use_epoch_percent, num_steps_per_epoch)\n",
    "                            begin += step_interval\n",
    "                            lr_begin += lr_interval\n",
    "                    else:\n",
    "                        interval_start, interval_end, lr = [float(s) for s in line.strip().split()]\n",
    "                        inner_lr_parser(interval_start, interval_end, lr, lr_map, default_lr, use_epoch_percent, num_steps_per_epoch)\n",
    "    lr_ret = default_lr\n",
    "#     print(use_epoch_percent)\n",
    "    for (start, end), lr in lr_map.items():\n",
    "        if (cur_step >= start) and (cur_step <= end):\n",
    "            if (lr < lr_ret):\n",
    "                lr_ret = lr\n",
    "    if lr_ret < stop_lr: lr_ret = stop_lr      \n",
    "    return lr_ret\n",
    "# _ = read_learning_rate(1, num_steps_per_epoch)\n",
    "# lr = []\n",
    "# num_epoches_to_show = 10\n",
    "# num_point = 100\n",
    "# for i in [i*num_epoches_to_show*num_steps_per_epoch/num_point for i in range(num_point)]:\n",
    "#     lr.append(read_learning_rate(i, num_steps_per_epoch))\n",
    "# plt.plot(lr)\n",
    "# plt.ylabel('learning rate')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabelMapping(object):\n",
    "    def __init__(self, catogory_file_path):\n",
    "        super(LabelMapping, self).__init__()\n",
    "        self._category_level_csv = catogory_file_path\n",
    "        self._category_map, self._category_level1_map, self._category_level2_map, self._len_level1, self._len_level2 = self.cvt_csv2tfrecord()\n",
    "        \n",
    "        assert (LEVEL1_CLASS == self._len_level1) and (LEVEL2_CLASS == self._len_level2), 'Other two levels are not mapped correctly.'\n",
    "        self._catogory_weight_map = self.cvt_catogory_weight()\n",
    "        self._mapping_strings = tf.constant( [ str(key) for key in self._category_map.keys() ] )\n",
    "        #print(list(self._category_map.keys())[0])\n",
    "        self._mapping_table = tf.contrib.lookup.index_table_from_tensor(mapping=self._mapping_strings, default_value=0) \n",
    "        \n",
    "        self._level1_table = tf.contrib.lookup.HashTable(tf.contrib.lookup.KeyValueTensorInitializer(list(self._category_level1_map.keys()), list(self._category_level1_map.values()), tf.int64, tf.int64), 0)\n",
    "        self._level2_table = tf.contrib.lookup.HashTable(tf.contrib.lookup.KeyValueTensorInitializer(list(self._category_level2_map.keys()), list(self._category_level2_map.values()), tf.int64, tf.int64), 0)\n",
    "        self._weight_table = tf.contrib.lookup.HashTable(tf.contrib.lookup.KeyValueTensorInitializer(list(self._catogory_weight_map.keys()), list(self._catogory_weight_map.values()), tf.int64, tf.float32), 0)\n",
    "\n",
    "    @property\n",
    "    def category_map(self):\n",
    "        return self._category_map\n",
    "    @property\n",
    "    def level1_table(self):\n",
    "        return self._level1_table\n",
    "    @property\n",
    "    def level2_table(self):\n",
    "        return self._level2_table\n",
    "    @property\n",
    "    def len_level1(self):\n",
    "        return self._len_level1\n",
    "    @property\n",
    "    def len_level2(self):\n",
    "        return self._len_level2\n",
    "    @property\n",
    "    def mapping_table(self):\n",
    "        return self._mapping_table\n",
    "    @property\n",
    "    def weight_table(self):\n",
    "        return self._weight_table\n",
    "    \n",
    "    def cvt_catogory_weight(self):\n",
    "        category_weight_map = dict()\n",
    "        csv = pd.read_csv(CATEGORY_WEIGHT_PATH).values\n",
    "        for row in csv:  \n",
    "            category_id, weight = row[0], row[2]\n",
    "#             if weight > 1.5:\n",
    "#                 weight = 1.5\n",
    "            category_weight_map[int(category_id)] = 1.\n",
    "\n",
    "        return category_weight_map\n",
    "\n",
    "    def cvt_csv2tfrecord(self):\n",
    "        level1_map, level2_map = self.create_level_map()\n",
    "        count = 0\n",
    "        category_map = dict()\n",
    "        category_level1_map = dict()\n",
    "        category_level2_map = dict()\n",
    "        csv = pd.read_csv(self._category_level_csv).values\n",
    "        for row in csv:  \n",
    "            category_id, level1, level2 = row[0], row[1], row[2]\n",
    "            category_map[category_id] = count\n",
    "            category_level1_map[int(category_id)] = level1_map[level1]\n",
    "            category_level2_map[int(category_id)] = level2_map[level2]\n",
    "            count += 1\n",
    "\n",
    "        return category_map, category_level1_map, category_level2_map, len(level1_map), len(level2_map)\n",
    "\n",
    "    def create_level_map(self):\n",
    "        csv = pd.read_csv(self._category_level_csv).values\n",
    "        level_list = [list(), list()]\n",
    "        for row in csv: \n",
    "            for level in range(1,3):\n",
    "                if row[level] not in level_list[level-1]:\n",
    "                    level_list[level-1].append(row[level])\n",
    "        return dict(zip(level_list[0], range(len(level_list[0])))), dict(zip(level_list[1], range(len(level_list[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CdiscountDataset(Dataset):\n",
    "    def __init__(self, sess, data_path, file_begin_match, label_mapping, num_examples, num_classes, buffer_size, batch_size, is_training):\n",
    "        super(CdiscountDataset, self).__init__()\n",
    "        self._data_file_list = [ os.path.join(data_path, x) for x in os.listdir(data_path) if lambda x: os.path.isfile(x) and file_begin_match in x ]\n",
    "        self._num_examples = num_examples\n",
    "        self._tf_sess = sess\n",
    "        self._num_classes = num_classes\n",
    "        self._batch_size = batch_size\n",
    "        self._buffer_size = buffer_size\n",
    "        self._is_training = is_training\n",
    "        self._category_map = label_mapping.category_map\n",
    "        self._level1_table = label_mapping.level1_table\n",
    "        self._level2_table = label_mapping.level2_table\n",
    "        self._len_level1 = label_mapping.len_level1\n",
    "        self._len_level2 = label_mapping.len_level2\n",
    "        self._mapping_table = label_mapping.mapping_table\n",
    "    def __len__(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print('read',idx)\n",
    "        try:\n",
    "            next_example, next_label, next_level0_label, next_level1_label = self._tf_sess.run(self.get_next())\n",
    "            #print(next_example, next_label, next_level0_label, next_level1_label)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        return (torch.from_numpy(next_example), torch.from_numpy(next_label), torch.from_numpy(next_level0_label), torch.from_numpy(next_level1_label))\n",
    "    @staticmethod\n",
    "    def image_normalized(image):\n",
    "        mean = [0.485, 0.456, 0.406 ]\n",
    "        std  = [0.229, 0.224, 0.225 ]\n",
    "\n",
    "        image = image.transpose((2,0,1))\n",
    "        image = image.astype(float)/255.\n",
    "        \n",
    "        image[0] = (image[0] - mean[0]) / std[0]\n",
    "        image[1] = (image[1] - mean[1]) / std[1]\n",
    "        image[2] = (image[2] - mean[2]) / std[2]\n",
    "\n",
    "        return image.astype(np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_center_crop(image, size=(160,160)):\n",
    "\n",
    "        height, width = image.shape[0:2]\n",
    "        w,h = size\n",
    "\n",
    "        x0 = (width  -w)//2\n",
    "        y0 = (height -h)//2\n",
    "        x1 = x0 + w\n",
    "        y1 = y0 + h\n",
    "        image = image[y0:y1, x0:x1]\n",
    "\n",
    "        return image\n",
    "    @staticmethod\n",
    "    def random_horizontal_flip(image, u=0.5):\n",
    "        if random.random() < u:\n",
    "            image = np.flip(image,1)  #np.fliplr(img) ##left-right\n",
    "        return image\n",
    "    @staticmethod\n",
    "    def random_crop(image, size=(160,160), u=0.5):\n",
    "\n",
    "        height,width=image.shape[0:2]\n",
    "        w,h = size\n",
    "\n",
    "        if random.random() < u:\n",
    "            x0 = np.random.choice(width - w)\n",
    "            y0 = np.random.choice(height - h)\n",
    "        else:\n",
    "            x0 = (width  -w)//2\n",
    "            y0 = (height -h)//2\n",
    "\n",
    "        x1 = x0 + w\n",
    "        y1 = y0 + h\n",
    "        image = image[y0:y1, x0:x1]\n",
    "\n",
    "        return image\n",
    "    @staticmethod\n",
    "    def random_resize(image, scale_x_limits=[0.9, 1.1], scale_y_limits=[0.9, 1.1], u=0.5):\n",
    "        if random.random() < u:\n",
    "            height,width=image.shape[0:2]\n",
    "\n",
    "            scale_x  = random.uniform(scale_x_limits[0],scale_x_limits[1])\n",
    "            if scale_y_limits is not None:\n",
    "                scale_y  = random.uniform(scale_y_limits[0],scale_y_limits[1])\n",
    "            else:\n",
    "                scale_y = scale_x\n",
    "\n",
    "            w = int(scale_x*width )\n",
    "            h = int(scale_y*height)\n",
    "\n",
    "            image = imresize(image,(h,w))\n",
    "        return image\n",
    "\n",
    "    @staticmethod\n",
    "    def _preprocess_by_pytorch_train(image):\n",
    "        image = CdiscountDataset.random_resize(image, scale_x_limits=[0.9,1.1], scale_y_limits=[0.9,1.1], u=0.5)\n",
    "        # flip  random ---------\n",
    "        image = CdiscountDataset.random_crop(image, size=(160,160), u=0.5) \n",
    "        image = CdiscountDataset.random_horizontal_flip(image, u=0.5)\n",
    "        return image.astype(np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def _preprocess_by_pytorch_test(image):\n",
    "        image  = CdiscountDataset.fix_center_crop(image, size=(160,160))  \n",
    "        return image.astype(np.float32)\n",
    "    @staticmethod\n",
    "    def _preprocess_normalize(image):\n",
    "        return CdiscountDataset.image_normalized(image)\n",
    "    \n",
    "    def _parse_function(self, example_proto):\n",
    "        features = {'img_raw': tf.FixedLenFeature([], tf.string, default_value=''),\n",
    "            'product_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n",
    "            'category_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64))}\n",
    "                \n",
    "        parsed_features = tf.parse_single_example(example_proto, features)\n",
    "        image = tf.image.decode_image(parsed_features[\"img_raw\"])\n",
    "        raw_label = parsed_features[\"category_id\"]\n",
    "        if self._is_training:\n",
    "            image = tf.py_func(CdiscountDataset._preprocess_by_pytorch_train, [image], tf.float32, stateful=False)\n",
    "            tf.summary.image('final_train_image', tf.expand_dims(image, 0))\n",
    "        else:\n",
    "            image = tf.py_func(CdiscountDataset._preprocess_by_pytorch_test, [image], tf.float32, stateful=False)\n",
    "            tf.summary.image('final_test_image', tf.expand_dims(image, 0))\n",
    "        image = tf.py_func(CdiscountDataset._preprocess_normalize, [image], tf.float32, stateful=False)\n",
    "        \n",
    "        return image, tf.one_hot(self._mapping_table.lookup(tf.as_string(raw_label)), self._num_classes, axis=-1, dtype=tf.int64),\\\n",
    "                tf.one_hot(self._level1_table.lookup(raw_label), self._len_level1, axis=-1, dtype=tf.int64),\\\n",
    "                tf.one_hot(self._level2_table.lookup(raw_label), self._len_level2, axis=-1, dtype=tf.int64)\n",
    "#         return image, self._mapping_table.lookup(tf.as_string(raw_label)),\\\n",
    "#                 self._level1_table.lookup(raw_label),\\\n",
    "#                 self._level2_table.lookup(raw_label)\n",
    "    \n",
    "    def get_next(self):\n",
    "        #next_example, next_label, next_level0_label, next_level1_label \n",
    "        return self._next_iter\n",
    "    def create_dataset(self):\n",
    "        self._dataset = tf.data.TFRecordDataset(self._data_file_list, compression_type='ZLIB', buffer_size = 409600)\n",
    "        parse_func = lambda example : self._parse_function(example)\n",
    "        self._dataset = self._dataset.map(parse_func, num_parallel_calls=INPUT_THREADS)\n",
    "        self._dataset = self._dataset.prefetch(self._batch_size * 3)\n",
    "        self._dataset = self._dataset.shuffle(buffer_size=self._buffer_size)\n",
    "        # don't batch here, hand this to pytorch dataloader\n",
    "        #self._dataset = self._dataset.batch(self._batch_size)\n",
    "        # we don't want to repeat until finish training, instead we stop each one epoch finished\n",
    "        #self._dataset = self._dataset.repeat(self._num_epochs)\n",
    "        self._iterator = self._dataset.make_initializable_iterator()\n",
    "        self._next_iter = self._iterator.get_next()\n",
    "#             Compute for 100 epochs.\n",
    "#             for _ in range(100):\n",
    "#               sess.run(iterator.initializer)\n",
    "#               while True:\n",
    "#                 try:\n",
    "#                   sess.run(next_element)\n",
    "#                 except tf.errors.OutOfRangeError:\n",
    "#                   break\n",
    "#         map(\n",
    "#             map_func,\n",
    "#             num_threads=None,\n",
    "#             output_buffer_size=None,\n",
    "#             num_parallel_calls=None\n",
    "#         )\n",
    "#         Maps map_func across this datset. (deprecated arguments)\n",
    "\n",
    "#         SOME ARGUMENTS ARE DEPRECATED. They will be removed in a future version. Instructions for updating: Replace num_threads=T with num_parallel_calls=T. Replace output_buffer_size=N with ds.prefetch(N) on the returned dataset.\n",
    "\n",
    "#         Args:\n",
    "\n",
    "#         map_func: A function mapping a nested structure of tensors (having shapes and types defined by self.output_shapes and self.output_types) to another nested structure of tensors.\n",
    "#         num_threads: (Optional.) Deprecated, use num_parallel_calls instead.\n",
    "#         output_buffer_size: (Optional.) A tf.int64 scalar tf.Tensor, representing the maximum number of processed elements that will be buffered.\n",
    "#         num_parallel_calls: (Optional.) A tf.int32 scalar tf.Tensor, representing the number elements to process in parallel. If not specified, elements will be processed sequentially.\n",
    "        return self._iterator.initializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 of 12 start...\n",
      "start from 1 of epoch 0.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c4766872d7b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mtf_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mnext_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_level0_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_level1_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mglobal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kapok/pyenv35/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.2/lib/python3.5/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.2/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.2/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.2/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch_saver = Saver(LOG_DIR, 'Resnet', 5)\n",
    "\n",
    "smoother = CriterionSmooth()\n",
    "smoother.register_smooth('train_correct', -1.)\n",
    "smoother.register_smooth('train_total', -1.)\n",
    "smoother.register_smooth('val_correct', -1.)\n",
    "smoother.register_smooth('val_total', -1.)\n",
    "\n",
    "timer_holder = TimeRecorder()\n",
    "timer_holder.register_event('save_time', save_time_interval)\n",
    "timer_holder.register_event('log_time', log_step_interval, False)\n",
    "timer_holder.register_event('eval_log_time', log_step_interval, False)\n",
    "\n",
    "cdiscount_net = torch_resnet.resnet152(pretrained=False, num_classes=NUM_CLASS)\n",
    "#print(cdiscount_net)\n",
    "if torch.cuda.is_available():\n",
    "    cdiscount_net = cdiscount_net.cuda()\n",
    "\n",
    "#criterion = nn.NLLLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(cdiscount_net.parameters(), lr=initial_learning_rate, momentum=momentum, weight_decay=0.0002)\n",
    "\n",
    "if True:\n",
    "    cdiscount_net = load_pretrain_file(cdiscount_net, PRETRAINED_MODEL_PATH, ['fc'])\n",
    "    others_state = None\n",
    "else:\n",
    "    others_state = torch_saver.restore_from_checkpoint(cdiscount_net, step=None)\n",
    "start_iter = 1\n",
    "start_epoch = 0\n",
    "global_step = 0\n",
    "if others_state is not None:\n",
    "    start_iter  = others_state['iter']\n",
    "    start_epoch = others_state['epoch']\n",
    "    global_step  = others_state['global_step']\n",
    "    optimizer.load_state_dict(others_state['optimizer'])\n",
    "\n",
    "label_mapping = LabelMapping(CATEGORY_NAME_PATH)\n",
    "train_set = CdiscountDataset(tf_sess, TRAIN_PATH, 'output_file', label_mapping, TOTAL_EXAMPLES, NUM_CLASS, 10000, BATCH_SIZE, True)\n",
    "val_set = CdiscountDataset(tf_sess, VAL_PATH, 'output_file', label_mapping, VAL_EXAMPLES, NUM_CLASS, 12000, BATCH_SIZE, False)\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "train_initializer = train_set.create_dataset()\n",
    "val_initializer = val_set.create_dataset()\n",
    "    \n",
    "tf_sess.run(tf.group(tf.global_variables_initializer(), tf.local_variables_initializer(), tf.tables_initializer()))\n",
    "#tf_sess.run(train_initializer)\n",
    "#print(tf_sess.run(train_set.get_next()))\n",
    "#tf_sess.run(train_set[0])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=False, num_workers = 4, drop_last=False)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers = 4, drop_last=False)\n",
    "\n",
    "# initialize tensorboard_logger\n",
    "summaries_dir = LOG_DIR + \"/tensorboard_logger_{}\".format(datetime.now().strftime('%Y-%m-%d_%H_%M_%S'))\n",
    "configure(summaries_dir, flush_secs=120)\n",
    "summary_writer = tf.summary.FileWriter(summaries_dir, tf_sess.graph)\n",
    "\n",
    "#target_onehot = torch.FloatTensor(batch_size, 4)\n",
    "timer_holder.reset_event('log_time', global_step)\n",
    "for epoch in range(NUM_EPOCHES):\n",
    "    if epoch < start_epoch: continue\n",
    "    log.info('epoch {} of {} start...'.format(epoch, NUM_EPOCHES))\n",
    "    log.info('start from {} of epoch {}.'.format(start_iter, epoch))\n",
    "    cdiscount_net.train()\n",
    "    tf_sess.run(train_initializer)\n",
    "\n",
    "    for index, data in enumerate(train_loader, start_iter):\n",
    "        next_example, next_label, next_level0_label, next_level1_label = data\n",
    "        global_step += 1\n",
    "            \n",
    "        if torch.cuda.is_available():\n",
    "            example_in = Variable(next_example).cuda()\n",
    "            label_in = Variable(next_label).cuda()\n",
    "            level0_label_in = Variable(next_level0_label).cuda()\n",
    "            level1_label_in = Variable(next_level1_label).cuda()\n",
    "        else:\n",
    "            example_in = Variable(next_example)\n",
    "            label_in = Variable(next_label)\n",
    "            level0_label_in = Variable(next_level0_label)\n",
    "            level1_label_in = Variable(next_level1_label)\n",
    "           \n",
    "        _, label_in = torch.topk(label_in, 1)\n",
    "        \n",
    "        target_logits = cdiscount_net(example_in)\n",
    "        target_softmax = nn.Softmax()(target_logits)\n",
    "        loss = criterion(target_logits, label_in)\n",
    "        _, batch_top1 = torch.topk(target_softmax, 1)\n",
    "        batch_top1 = batch_top1.type(torch.LongTensor)\n",
    "        if torch.cuda.is_available():\n",
    "            batch_top1 = batch_top1.cuda()\n",
    "            \n",
    "        num_correct = smoother.push_new_value('train_correct', (label_in == batch_top1.view(1, -1)).sum().data[0])\n",
    "        smoother.push_new_value('train_total', batch_size)\n",
    "#         target_log_softmax = cdiscount_net(msno_in, artist_in)\n",
    "#         loss = criterion(target_log_softmax, label_in)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_acc  = num_correct/batch_size\n",
    "        batch_loss = loss.data[0]\n",
    "        \n",
    "        smooth_train_acc = smoother.smooth_value('train_correct')/smoother.smooth_value('train_total')\n",
    "    \n",
    "        if timer_holder.check_for_me('log_time', global_step):\n",
    "            cur_readed_lr = read_learning_rate(global_step, num_steps_per_train_epoch)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = cur_readed_lr\n",
    "            time_passed = timer_holder.how_long_before('log_time')\n",
    "            log_value('train/batch_loss', batch_loss, global_step)\n",
    "            log_value('train/sec_per_step', time_passed/log_step_interval, global_step)\n",
    "            log_value('train/learning_rate', optimizer.param_groups[0]['lr'], global_step)\n",
    "            log_value('train/batch_acc', batch_acc, global_step)\n",
    "            log_value('train/smooth_train_acc', smooth_train_acc, global_step)\n",
    "            # to stdout\n",
    "            log.info('####### train logging #######')\n",
    "            log.info('\\ttrain/current_step: {}, cur_epoch: {}/{}'.format(global_step, epoch, num_steps_per_train_epoch))\n",
    "            log.info('\\ttrain/current_lr: {}'.format(optimizer.param_groups[0]['lr']))\n",
    "            log.info('\\ttrain/sec_per_step: {:.3f}'.format(time_passed/log_step_interval))\n",
    "            log.info('\\ttrain/batch_loss: {:.3f}'.format(batch_loss))\n",
    "            log.info('\\ttrain/batch_acc: {:.3f}'.format(batch_acc*100))\n",
    "            log.info('\\ttrain/smooth_train_acc: {:.3f}'.format(smooth_train_acc*100))\n",
    "            summary = tf_sess.run(merged_summary)\n",
    "            summary_writer.add_summary(summary, global_step)\n",
    "\n",
    "        if timer_holder.check_for_me('save_time'):\n",
    "            torch_saver.save_checkpoint(cdiscount_net.state_dict(), {'optimizer': optimizer.state_dict(),\n",
    "                                                    'iter': index, 'epoch': epoch, 'global_step': global_step }, global_step, is_best=False)\n",
    "            break\n",
    "    \n",
    "    # reset start_iter\n",
    "    start_iter = 1\n",
    "    log.info('epoch {} finished.'.format(epoch)) \n",
    "    # save model after each epoch\n",
    "    torch_saver.save_checkpoint(cdiscount_net.state_dict(), {'optimizer': optimizer.state_dict(),\n",
    "                                                    'iter': 0, 'epoch': epoch, 'global_step': global_step }, global_step, is_best=False)\n",
    "    timer_holder.reset_event('save_time')\n",
    "    \n",
    "    \n",
    "    # check on validation every epoches            \n",
    "    cdiscount_net.eval()\n",
    "    tf_sess.run(val_initializer)\n",
    "    timer_holder.reset_event('eval_log_time', 1)\n",
    "    #if False:\n",
    "    for index, data in enumerate(val_loader, 1):\n",
    "        next_example, next_label, next_level0_label, next_level1_label = data\n",
    "            \n",
    "        if torch.cuda.is_available():\n",
    "            example_in = Variable(next_example).cuda()\n",
    "            label_in = Variable(next_label).cuda()\n",
    "            level0_label_in = Variable(next_level0_label).cuda()\n",
    "            level1_label_in = Variable(next_level1_label).cuda()\n",
    "        else:\n",
    "            example_in = Variable(next_example)\n",
    "            label_in = Variable(next_label)\n",
    "            level0_label_in = Variable(next_level0_label)\n",
    "            level1_label_in = Variable(next_level1_label)\n",
    "            \n",
    "        _, label_in = torch.topk(label_in, 1)\n",
    "           \n",
    "        _, batch_top1 = torch.topk(nn.Softmax()(cdiscount_net(example_in)), 1)\n",
    "        batch_top1 = batch_top1.type(torch.LongTensor)\n",
    "        if torch.cuda.is_available():\n",
    "            batch_top1 = batch_top1.cuda()\n",
    "        num_correct = smoother.push_new_value('val_correct', (label_in == batch_top1.view(1, -1)).sum().data[0])\n",
    "        smoother.push_new_value('val_total', batch_size)        \n",
    "        \n",
    "        batch_acc  = num_correct/batch_size\n",
    "\n",
    "        smooth_validation_acc = smoother.smooth_value('val_correct')/smoother.smooth_value('val_total')\n",
    "\n",
    "        if timer_holder.check_for_me('eval_log_time', index):\n",
    "            time_passed = timer_holder.how_long_before('eval_log_time')\n",
    "            log_value('validation/batch_acc', batch_acc, global_step+index)\n",
    "            log_value('validation/smooth_validation_acc', smooth_validation_acc, global_step+index)\n",
    "            log.info('####### validation logging #######')\n",
    "            log.info('\\tvalidation/current_step: {}/{}'.format(index, num_steps_per_val_epoch))\n",
    "            log.info('\\tvalidation/sec_per_step: {:.3f}'.format(time_passed/log_step_interval))\n",
    "            log.info('\\tvalidation/batch_acc: {:.3f}'.format(batch_acc*100))\n",
    "            log.info('\\tvalidation/smooth_validation_acc: {:.3f}'.format(smooth_validation_acc*100))\n",
    "tf_sess.close()\n",
    "log.info('Done: {}'.format(datetime.now().strftime('%Y-%m-%d_%H_%M_%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
