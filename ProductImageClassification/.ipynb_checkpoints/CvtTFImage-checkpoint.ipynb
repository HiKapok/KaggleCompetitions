{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import io\n",
    "import bson \n",
    "import tensorflow as tf\n",
    "import os.path\n",
    "from scipy.misc import imread   # or, whatever image library you prefer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/'\n",
    "TRAIN_OUTPUT_PATH = '/media/rs/0E06CD1706CD0127/Train_Seq/'\n",
    "TEST_OUTPUT_PATH = DATASET_PATH + 'Test11111/'\n",
    "if os.path.exists(TRAIN_OUTPUT_PATH) is not True: os.mkdir(TRAIN_OUTPUT_PATH)\n",
    "if os.path.exists(TEST_OUTPUT_PATH) is not True: os.mkdir(TEST_OUTPUT_PATH)\n",
    "train_bson_file = DATASET_PATH + 'train.bson'\n",
    "#test_bson_file = DATASET_PATH + 'train_example.bson'\n",
    "test_bson_file = DATASET_PATH + 'test.bson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cvt_bson_tfrecord(path, bson_file):\n",
    "    tfrecords_filename = [path + 'output_file1.tfrecords', path + 'output_file2.tfrecords', path + 'output_file3.tfrecords', path + 'output_file4.tfrecords']\n",
    "    opts = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.ZLIB)\n",
    "\n",
    "    z = 0 \n",
    "    data = bson.decode_file_iter(open(bson_file, 'rb'))\n",
    "    with tf.python_io.TFRecordWriter(tfrecords_filename[0], options=opts) as writer1, tf.python_io.TFRecordWriter(tfrecords_filename[1], options=opts) as writer2, tf.python_io.TFRecordWriter(tfrecords_filename[2], options=opts) as writer3, tf.python_io.TFRecordWriter(tfrecords_filename[3], options=opts) as writer4:\n",
    "        writer_list = [writer1, writer2, writer3, writer4]\n",
    "        for c, d in enumerate(data):       \n",
    "            n_img = len(d['imgs'])\n",
    "            cur_writer = writer_list[z%4]\n",
    "            for index in range(n_img):\n",
    "                img_raw = d['imgs'][index]['picture']\n",
    "                img = imread(io.BytesIO(img_raw))\n",
    "                height = img.shape[0]\n",
    "                width = img.shape[1]\n",
    "                product_id = d['_id']\n",
    "                category_id = d['category_id'] \n",
    "                example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                    'height': _int64_feature(height),\n",
    "                    'width': _int64_feature(width),\n",
    "                    'category_id': _int64_feature(category_id),\n",
    "                    'product_id': _int64_feature(product_id),\n",
    "                    'img_raw':_bytes_feature(img_raw)\n",
    "                }))\n",
    "                cur_writer.write(example.SerializeToString())\n",
    "            z = z + 1\n",
    "            if z % 10000 == 0:\n",
    "                print('current record: ', z)\n",
    "        print('finished. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cvt_bson_tfrecord_test_only(path, bson_file):\n",
    "    tfrecords_filename = [path + 'output_file1.tfrecords', path + 'output_file2.tfrecords', path + 'output_file3.tfrecords', path + 'output_file4.tfrecords']\n",
    "    opts = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.ZLIB)\n",
    "\n",
    "    z = 0 \n",
    "    num_examples = 0\n",
    "    data = bson.decode_file_iter(open(bson_file, 'rb'))\n",
    "    with tf.python_io.TFRecordWriter(tfrecords_filename[0], options=opts) as writer1,\\\n",
    "        tf.python_io.TFRecordWriter(tfrecords_filename[1], options=opts) as writer2, \\\n",
    "        tf.python_io.TFRecordWriter(tfrecords_filename[2], options=opts) as writer3, \\\n",
    "        tf.python_io.TFRecordWriter(tfrecords_filename[3], options=opts) as writer4:\n",
    "        writer_list = [writer1, writer2, writer3, writer4]\n",
    "        for c, d in enumerate(data):       \n",
    "            n_img = len(d['imgs'])\n",
    "            #z = z + 1\n",
    "            #num_examples = num_examples + n_img\n",
    "            #continue\n",
    "            cur_writer = writer_list[z%4]\n",
    "            for index in range(n_img):\n",
    "                img_raw = d['imgs'][index]['picture']\n",
    "                img = imread(io.BytesIO(img_raw))\n",
    "                height = img.shape[0]\n",
    "                width = img.shape[1]\n",
    "                product_id = d['_id']\n",
    "                example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                    'height': _int64_feature(height),\n",
    "                    'width': _int64_feature(width),\n",
    "                    'product_id': _int64_feature(product_id),\n",
    "                    'img_raw':_bytes_feature(img_raw)\n",
    "                }))\n",
    "                cur_writer.write(example.SerializeToString())\n",
    "            z = z + 1\n",
    "            if z % 10000 == 0:\n",
    "                print('current record: ', z)\n",
    "                #break\n",
    "        print('finished. ')\n",
    "    return z, num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cvt_bson_tfrecord_seq(path, bson_file):\n",
    "    tfrecords_filename = path + 'output_file.tfrecords'\n",
    "    opts = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.ZLIB)\n",
    "\n",
    "    z = 0 \n",
    "    num_examples = 0\n",
    "    data = bson.decode_file_iter(open(bson_file, 'rb'))\n",
    "    with tf.python_io.TFRecordWriter(tfrecords_filename, options=opts) as cur_writer:\n",
    "        for c, d in enumerate(data):     \n",
    "            if np.random.random_sample() < 0.4:\n",
    "                continue\n",
    "            n_img = len(d['imgs'])\n",
    "            for index in range(n_img):\n",
    "                img_raw = d['imgs'][index]['picture']\n",
    "                img = imread(io.BytesIO(img_raw))\n",
    "                height = img.shape[0]\n",
    "                width = img.shape[1]\n",
    "                product_id = d['_id']\n",
    "                category_id = d['category_id'] \n",
    "                example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                    'height': _int64_feature(height),\n",
    "                    'width': _int64_feature(width),\n",
    "                    'category_id': _int64_feature(category_id),\n",
    "                    'product_id': _int64_feature(product_id),\n",
    "                    'img_raw':_bytes_feature(img_raw)\n",
    "                }))\n",
    "                cur_writer.write(example.SerializeToString())\n",
    "                num_examples += 1\n",
    "            z = z + 1\n",
    "            if z % 10000 == 0:\n",
    "                print('current record: ', z)\n",
    "        print('finished. ')\n",
    "    return num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/rs/0E06CD1706CD0127/Kapok/kaggle/train.bson'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-75c5be0c88ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#cvt_bson_tfrecord(TRAIN_OUTPUT_PATH, train_bson_file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvt_bson_tfrecord_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_OUTPUT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_bson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#print(cvt_bson_tfrecord_test_only(TEST_OUTPUT_PATH, test_bson_file))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f6720e21e198>\u001b[0m in \u001b[0;36mcvt_bson_tfrecord_seq\u001b[0;34m(path, bson_file)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnum_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_file_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfrecords_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcur_writer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/rs/0E06CD1706CD0127/Kapok/kaggle/train.bson'"
     ]
    }
   ],
   "source": [
    "# # Create the graph, etc.\n",
    "# # initialize local variables, like local counter epochs\n",
    "# init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "# # Create a session for running operations in the Graph.\n",
    "# sess = tf.Session()\n",
    "# # Initialize the variables (like the epoch counter).\n",
    "# sess.run(init_op)\n",
    "\n",
    "cvt_bson_tfrecord(TRAIN_OUTPUT_PATH, train_bson_file)\n",
    "#print(cvt_bson_tfrecord_seq(TRAIN_OUTPUT_PATH, train_bson_file))\n",
    "#print(cvt_bson_tfrecord_test_only(TEST_OUTPUT_PATH, test_bson_file))\n",
    "\n",
    "#sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
