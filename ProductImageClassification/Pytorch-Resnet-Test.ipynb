{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=\n",
      "env: CUDA_VISIBLE_DEVICES=0, 1\n"
     ]
    }
   ],
   "source": [
    "GPU_ID = [0, 1]\n",
    "# tensorboard --logdir=/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytoh/cdiscount/logs_resnet --port=6008\n",
    "# The line below sets the environment\n",
    "# variable CUDA_VISIBLE_DEVICES\n",
    "get_ipython().magic('env CUDA_VISIBLE_DEVICES = ')\n",
    "#%env CUDA_VISIBLE_DEVICES = 0\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import uuid\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread, imsave, imshow, imresize\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers.python.layers import layers as layers_lib\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.01)\n",
    "#, gpu_options=gpu_options\n",
    "tf_sess = tf.Session(config=tf.ConfigProto(device_count={'CPU' : 1, 'GPU' : 0}, allow_soft_placement=True))\n",
    "# now tensorflow will assume there not exist gpu\n",
    "# use this tf_session following, and close in the end\n",
    "#tf_sess.close()\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import time\n",
    "import io\n",
    "from datetime import datetime\n",
    "import gc # garbage collector\n",
    "import logging\n",
    "get_ipython().magic('env CUDA_VISIBLE_DEVICES = {}'.format(', '.join(map(str, GPU_ID))))\n",
    "from tensorboard_logger import configure, log_value\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch_resnet\n",
    "\n",
    "from scipy.sparse import *\n",
    "import tables as tb\n",
    "import random\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "get_ipython().magic('matplotlib inline')\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "get_ipython().magic('load_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/'\n",
    "#PRETRAINED_MODEL_PATH = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytorch/cdiscount/models/resnet101-5d3b4d8f.pth'\n",
    "#PRETRAINED_MODEL_PATH = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytorch/cdiscount/logs_resnet/Resnet_pytorch_state_49485_2017-12-04_11_10_54.pth'\n",
    "PRETRAINED_MODEL_PATH = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytorch/cdiscount/logs_resnet_focal_loss/Resnet_pytorch_state_438453_2017-12-14_06_43_50.pth'\n",
    "\n",
    "\n",
    "LOG_DIR = DATASET_PATH + 'pytorch/cdiscount/logs_resnet_test'\n",
    "TEST_PATH = DATASET_PATH + 'Test/'\n",
    "OUTPUT_PATH = DATASET_PATH + 'pytorch/cdiscount/logs_resnet_test/output_{}.csv'\n",
    "CATEGORY_NAME_PATH = DATASET_PATH + 'category_names.csv'\n",
    "CATEGORY_WEIGHT_PATH = DATASET_PATH + 'catogory_with_weight.csv'\n",
    "PROB_SAVE_FILE = DATASET_PATH + 'pytorch/cdiscount/logs_resnet_test/probs_{}.h5'\n",
    "ID_SAVE_FILE = DATASET_PATH + 'pytorch/cdiscount/logs_resnet_test/ids.csv'\n",
    "\n",
    "NUM_OF_TOPK = 20\n",
    "NUM_TO_AUG = 1\n",
    "#BATCH_SIZE = 5//NUM_TO_AUG\n",
    "BATCH_SIZE = 2048//NUM_TO_AUG\n",
    "IMAGE_WIDTH = 180\n",
    "IMAGE_HEIGHT = 180\n",
    "NUM_CLASS = 5270\n",
    "LEVEL1_CLASS = 49\n",
    "LEVEL2_CLASS = 483\n",
    "TOTAL_EXAMPLES = 3095080\n",
    "INPUT_THREADS = 1\n",
    "NUM_STEPS = int(TOTAL_EXAMPLES / BATCH_SIZE) + 1\n",
    "\n",
    "log_step_interval = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_logging(logger_name, logger_file_name):\n",
    "    log = logging.getLogger(logger_name)\n",
    "    log.setLevel(logging.DEBUG)\n",
    "\n",
    "    # create formatter and add it to the handlers\n",
    "    print_formatter = logging.Formatter('%(message)s')\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(name)s_%(levelname)s: %(message)s')\n",
    "\n",
    "    # create file handler which logs even debug messages\n",
    "    fh = logging.FileHandler(logger_file_name, mode='w')\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    fh.setFormatter(file_formatter)\n",
    "    log.addHandler(fh)\n",
    "    # both output to console and file\n",
    "    consoleHandler = logging.StreamHandler()\n",
    "    consoleHandler.setFormatter(print_formatter)\n",
    "    log.addHandler(consoleHandler)\n",
    "    \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "here is an info message.\n"
     ]
    }
   ],
   "source": [
    "log = set_logging('CDiscount', DATASET_PATH + 'pytorch/cdiscount/resnet_pytorch_test.log')\n",
    "log.info('here is an info message.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB_NAME = 'segment_median'\n",
    "\n",
    "def load_op_module(lib_name):\n",
    "    \"\"\"\n",
    "    Load TensorFlow operator library.\n",
    "    \"\"\"\n",
    "    # use absolute path so that ops.py can be called from other directory\n",
    "    lib_path =  '../lib{0}.so'.format(lib_name)\n",
    "    # duplicate library with a random new name so that\n",
    "    # a running program will not be interrupted when the original library is updated\n",
    "    lib_copy_path = '/tmp/lib{0}_{1}.so'.format(str(uuid.uuid4())[:8], LIB_NAME)\n",
    "    shutil.copyfile(lib_path, lib_copy_path)\n",
    "    oplib = tf.load_op_library(lib_copy_path)\n",
    "    return oplib\n",
    "\n",
    "segment_median = load_op_module(LIB_NAME).segment_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TimeRecorder(object):\n",
    "    def __init__(self):\n",
    "        super(TimeRecorder, self).__init__()\n",
    "        self._tick_map = dict()\n",
    "        self._recorder = dict()\n",
    "        self._use_time = dict()\n",
    "        self._last_interval = dict()\n",
    "        self.register_event('ticks', 1, True)\n",
    "    # register at the very begining\n",
    "    # when not use time, call reset_event with your initial value at each start\n",
    "    def register_event(self, name, tick, use_time=True):\n",
    "        self._tick_map[name] = tick\n",
    "        self._last_interval[name] = 0\n",
    "        self._recorder[name] = 0\n",
    "        if use_time:\n",
    "            self._recorder[name] = time.time() \n",
    "        self._use_time[name] = use_time\n",
    "    def reset_event(self, name, criterion=None):\n",
    "        if self._use_time[name]: self._recorder[name] = time.time()\n",
    "        elif criterion is not None: self._recorder[name] = criterion\n",
    "        self._last_interval[name] = 0\n",
    "    def cancel_event(self, name):\n",
    "        self._tick_map.pop(name, None)\n",
    "        self._last_interval.pop(name, None)\n",
    "        self._recorder.pop(name, None)\n",
    "        self._use_time.pop(name, None)\n",
    "    def get_ticks_passed(self):\n",
    "        passed = time.time() - self._recorder['ticks']\n",
    "        self._recorder['ticks'] = time.time()\n",
    "        return passed/self._tick_map['ticks']\n",
    "    # you can call this to get how log elapsed after you get True from check_for_me\n",
    "    def how_long_before(self, name):\n",
    "        return self._last_interval[name]\n",
    "    def check_for_me(self, name, criterion=None):\n",
    "        if self._use_time[name]:\n",
    "            if time.time() - self._recorder[name] >= self._tick_map[name]:\n",
    "                self._last_interval[name] = time.time() - self._recorder[name]\n",
    "                self._recorder[name] = time.time()\n",
    "                return True\n",
    "        elif criterion is not None:\n",
    "            if criterion - self._recorder[name] >= self._tick_map[name]:\n",
    "                self._last_interval[name] = criterion - self._recorder[name]\n",
    "                self._recorder[name] = criterion\n",
    "                return True\n",
    "        return False\n",
    "def load_pretrain_file(net, pretrain_file, skip=[]):\n",
    "    pretrain_state_dict = torch.load(pretrain_file, map_location=lambda storage, loc: storage)\n",
    "    state_dict = net.state_dict()\n",
    "    keys = list(state_dict.keys())\n",
    "    #print(pretrain_state_dict.keys())\n",
    "    for key in keys:\n",
    "        if any(s in key for s in skip):\n",
    "            continue\n",
    "        pretrain_key = key# 'module.' + key\n",
    "        #if 'layer0.0.conv.' in key: pretrain_key=key.replace('layer0.0.conv.',  'conv1.' )\n",
    "        state_dict[key] = pretrain_state_dict[pretrain_key]\n",
    "\n",
    "    net.load_state_dict(state_dict)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabelMapping(object):\n",
    "    def __init__(self, catogory_file_path):\n",
    "        super(LabelMapping, self).__init__()\n",
    "        self._category_level_csv = catogory_file_path\n",
    "        self._category_map = self.cvt_csv2tfrecord()\n",
    "        self._mapping_strings = tf.constant( [ str(key) for key in self._category_map.keys() ] )\n",
    "        self._index2catogory_inv_table = tf.contrib.lookup.index_to_string_table_from_tensor(self._mapping_strings, default_value=\"0000000000\")\n",
    "       \n",
    "    @property\n",
    "    def category_map(self):\n",
    "        return self._category_map\n",
    "    @property\n",
    "    def index2catogory_inv_table(self):\n",
    "        return self._index2catogory_inv_table\n",
    "   \n",
    "    def cvt_csv2tfrecord(self):\n",
    "        count = 0\n",
    "        category_map = dict()\n",
    "        csv = pd.read_csv(self._category_level_csv).values\n",
    "        for row in csv:  \n",
    "            category_id = row[0]\n",
    "            category_map[category_id] = count\n",
    "            count += 1\n",
    "\n",
    "        return category_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CdiscountDataset(Dataset):\n",
    "    def __init__(self, sess, data_path, file_begin_match, num_examples, num_classes, buffer_size, batch_size, is_training):\n",
    "        super(CdiscountDataset, self).__init__()\n",
    "        self._data_file_list = [ os.path.join(data_path, x) for x in os.listdir(data_path) if lambda x: os.path.isfile(x) and file_begin_match in x ]\n",
    "        self._num_examples = num_examples\n",
    "        self._tf_sess = sess\n",
    "        self._num_classes = num_classes\n",
    "        self._batch_size = batch_size\n",
    "        self._buffer_size = buffer_size\n",
    "        self._is_training = is_training\n",
    "    def __len__(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    @staticmethod\n",
    "    def image_normalized(image):\n",
    "        mean = [0.485, 0.456, 0.406 ]\n",
    "        std  = [0.229, 0.224, 0.225 ]\n",
    "\n",
    "        image = image.transpose((2,0,1))\n",
    "        image = image.astype(float)/255.\n",
    "        \n",
    "        image[0] = (image[0] - mean[0]) / std[0]\n",
    "        image[1] = (image[1] - mean[1]) / std[1]\n",
    "        image[2] = (image[2] - mean[2]) / std[2]\n",
    "\n",
    "        return image.astype(np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_center_crop(image, size=(160,160)):\n",
    "\n",
    "        height, width = image.shape[0:2]\n",
    "        w,h = size\n",
    "\n",
    "        x0 = (width  -w)//2\n",
    "        y0 = (height -h)//2\n",
    "        x1 = x0 + w\n",
    "        y1 = y0 + h\n",
    "        image = image[y0:y1, x0:x1]\n",
    "\n",
    "        return image\n",
    "    @staticmethod\n",
    "    def random_horizontal_flip(image, u=0.5):\n",
    "        if random.random() < u:\n",
    "            image = np.flip(image,1)  #np.fliplr(img) ##left-right\n",
    "        return image\n",
    "    @staticmethod\n",
    "    def random_crop(image, size=(160,160), u=0.5):\n",
    "\n",
    "        height,width=image.shape[0:2]\n",
    "        w,h = size\n",
    "\n",
    "        if random.random() < u:\n",
    "            x0 = np.random.choice(width - w)\n",
    "            y0 = np.random.choice(height - h)\n",
    "        else:\n",
    "            x0 = (width  -w)//2\n",
    "            y0 = (height -h)//2\n",
    "\n",
    "        x1 = x0 + w\n",
    "        y1 = y0 + h\n",
    "        image = image[y0:y1, x0:x1]\n",
    "\n",
    "        return image\n",
    "    @staticmethod\n",
    "    def random_resize(image, scale_x_limits=[0.9, 1.1], scale_y_limits=[0.9, 1.1], u=0.5):\n",
    "        if random.random() < u:\n",
    "            height,width=image.shape[0:2]\n",
    "\n",
    "            scale_x  = random.uniform(scale_x_limits[0],scale_x_limits[1])\n",
    "            if scale_y_limits is not None:\n",
    "                scale_y  = random.uniform(scale_y_limits[0],scale_y_limits[1])\n",
    "            else:\n",
    "                scale_y = scale_x\n",
    "\n",
    "            w = int(scale_x*width )\n",
    "            h = int(scale_y*height)\n",
    "\n",
    "            image = imresize(image,(h,w))\n",
    "        return image\n",
    "\n",
    "    @staticmethod\n",
    "    def _preprocess_by_pytorch_train(image):\n",
    "        image = CdiscountDataset.random_resize(image, scale_x_limits=[0.9,1.1], scale_y_limits=[0.9,1.1], u=0.5)\n",
    "        # flip  random ---------\n",
    "        image = CdiscountDataset.random_crop(image, size=(160,160), u=0.5) \n",
    "        image = CdiscountDataset.random_horizontal_flip(image, u=0.5)\n",
    "        return image.astype(np.float32)\n",
    "    @staticmethod\n",
    "    def _preprocess_by_pytorch_test_with_aug(image):\n",
    "        num_batch_size = image.shape[0]\n",
    "        #print(num_batch_size)\n",
    "        list_of_images = np.split(image, num_batch_size)\n",
    "        return [CdiscountDataset._preprocess_by_pytorch_train(_image) for _image in list_of_images]\n",
    "    @staticmethod\n",
    "    def _preprocess_by_pytorch_test(image):\n",
    "        image  = CdiscountDataset.fix_center_crop(image, size=(160,160))  \n",
    "        return image.astype(np.float32)\n",
    "    @staticmethod\n",
    "    def _preprocess_normalize(image):\n",
    "        return CdiscountDataset.image_normalized(image)\n",
    "    @staticmethod\n",
    "    def _array_to_image_transform(image):\n",
    "        mean = [0.485, 0.456, 0.406 ]\n",
    "        std  = [0.229, 0.224, 0.225 ]\n",
    "        if random.random() < 0.00001:\n",
    "            image_to_save = image\n",
    "            image_to_save[0] = image_to_save[0]*std[0] + mean[0]\n",
    "            image_to_save[1] = image_to_save[1]*std[1] + mean[1]\n",
    "            image_to_save[2] = image_to_save[2]*std[2] + mean[2]\n",
    "\n",
    "            image_to_save = image_to_save*255\n",
    "            image_to_save = np.transpose(image_to_save, (1, 2, 0))\n",
    "            image_to_save = image_to_save.astype(np.uint8)\n",
    "            imsave('/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytorch/cdiscount/Debug/{}.jpg'.format(int(random.random()*100000)), image_to_save)\n",
    "        return image\n",
    "    @staticmethod\n",
    "    def extern_array_to_image_transform(image, filepath):\n",
    "        mean = [0.485, 0.456, 0.406 ]\n",
    "        std  = [0.229, 0.224, 0.225 ]\n",
    "        image_to_save = np.array(image)\n",
    "        image_to_save[0] = image_to_save[0]*std[0] + mean[0]\n",
    "        image_to_save[1] = image_to_save[1]*std[1] + mean[1]\n",
    "        image_to_save[2] = image_to_save[2]*std[2] + mean[2]\n",
    "\n",
    "        image_to_save = image_to_save*255\n",
    "        image_to_save = np.transpose(image_to_save, (1, 2, 0))\n",
    "        image_to_save = image_to_save.astype(np.uint8)\n",
    "        imsave(filepath, image_to_save)\n",
    "\n",
    "    def _parse_function(self, example_proto):\n",
    "        features = {'img_raw': tf.FixedLenFeature([], tf.string, default_value=''),\n",
    "                    'product_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64))}\n",
    "                \n",
    "        parsed_features = tf.parse_single_example(example_proto, features)\n",
    "        image = tf.image.decode_image(parsed_features[\"img_raw\"])\n",
    "        product_label = parsed_features[\"product_id\"]\n",
    "        \n",
    "        image_to_aug = tf.tile(tf.expand_dims(image, 0), tf.constant([NUM_TO_AUG, 1, 1, 1]))\n",
    "        product_id_to_aug = tf.tile(tf.expand_dims(product_label, 0), tf.constant([NUM_TO_AUG]))\n",
    "\n",
    "        image_list = [tf.squeeze(image, 0) for image in tf.split(image_to_aug, tf.ones_like(product_id_to_aug), 0)]\n",
    "        #image_list = tf.unstack(image_to_aug)\n",
    "\n",
    "        if self._is_training:\n",
    "            image_preprocessed_list = [tf.py_func(CdiscountDataset._preprocess_by_pytorch_train, [image], tf.float32, stateful=True) for image in image_list]\n",
    "        else:\n",
    "            image_preprocessed_list = [tf.py_func(CdiscountDataset._preprocess_by_pytorch_test, [image], tf.float32, stateful=False) for image in image_list]\n",
    "        image_preprocessed_list = [tf.py_func(CdiscountDataset._preprocess_normalize, [image], tf.float32, stateful=False) for image in image_preprocessed_list]\n",
    "        #image_preprocessed_list = [tf.py_func(CdiscountDataset._array_to_image_transform, [image], tf.float32, stateful=False) for image in image_preprocessed_list]\n",
    "        \n",
    "        return tf.stack(image_preprocessed_list), product_id_to_aug\n",
    "#     def _parse_function(self, example_proto):\n",
    "#         features = {'img_raw': tf.FixedLenFeature([], tf.string, default_value=''),\n",
    "#                     'product_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64))}\n",
    "                \n",
    "#         parsed_features = tf.parse_single_example(example_proto, features)\n",
    "#         image = tf.image.decode_image(parsed_features[\"img_raw\"])\n",
    "#         product_label = parsed_features[\"product_id\"]\n",
    "        \n",
    "#         image_to_aug = tf.tile(tf.expand_dims(image, 0), tf.constant([NUM_TO_AUG, 1, 1, 1]))\n",
    "#         product_id_to_aug = tf.tile(tf.expand_dims(product_label, 0), tf.constant([NUM_TO_AUG]))\n",
    "\n",
    "#         image_preprocessed_list = tf.py_func(CdiscountDataset._preprocess_by_pytorch_test_with_aug, [image_to_aug], [tf.float32]*NUM_TO_AUG, stateful=True)\n",
    "        \n",
    "#         image_preprocessed_list = [tf.py_func(CdiscountDataset._preprocess_normalize, [image], tf.float32, stateful=False) for image in image_preprocessed_list]\n",
    "#         #image_preprocessed_list = [tf.py_func(CdiscountDataset._array_to_image_transform, [image], tf.float32, stateful=False) for image in image_preprocessed_list]\n",
    "\n",
    "#         return tf.stack(image_preprocessed_list), product_label\n",
    "    \n",
    "    \n",
    "    def get_next(self):\n",
    "        batch_images_aug, batch_id_aug = self._next_iter\n",
    "        batch_images = tf.reshape(batch_images_aug, [-1, 3, 160, 160])\n",
    "        batch_id = tf.reshape(batch_id_aug, [-1])\n",
    "        return batch_images, batch_id\n",
    "    def create_dataset(self):\n",
    "        self._dataset = tf.data.TFRecordDataset(self._data_file_list, compression_type='ZLIB', buffer_size = 409600)\n",
    "        parse_func = lambda example : self._parse_function(example)\n",
    "        self._dataset = self._dataset.map(parse_func, num_parallel_calls=INPUT_THREADS)\n",
    "        self._dataset = self._dataset.prefetch(self._batch_size * 3)\n",
    "        self._dataset = self._dataset.batch(self._batch_size)\n",
    "        self._iterator = self._dataset.make_initializable_iterator()\n",
    "        self._next_iter = self._iterator.get_next()\n",
    "\n",
    "        return self._iterator.initializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-14 20:17:14\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 31/1512\n",
      "\ttest/sec_per_step: 4.240\n",
      "\ttest/roughly  1.744 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 61/1512\n",
      "\ttest/sec_per_step: 3.632\n",
      "\ttest/roughly  1.464 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 91/1512\n",
      "\ttest/sec_per_step: 3.675\n",
      "\ttest/roughly  1.451 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 121/1512\n",
      "\ttest/sec_per_step: 3.766\n",
      "\ttest/roughly  1.455 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 151/1512\n",
      "\ttest/sec_per_step: 3.714\n",
      "\ttest/roughly  1.404 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 181/1512\n",
      "\ttest/sec_per_step: 3.954\n",
      "\ttest/roughly  1.462 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 211/1512\n",
      "\ttest/sec_per_step: 3.903\n",
      "\ttest/roughly  1.411 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 241/1512\n",
      "\ttest/sec_per_step: 3.848\n",
      "\ttest/roughly  1.359 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 271/1512\n",
      "\ttest/sec_per_step: 3.955\n",
      "\ttest/roughly  1.363 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 301/1512\n",
      "\ttest/sec_per_step: 3.895\n",
      "\ttest/roughly  1.310 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 331/1512\n",
      "\ttest/sec_per_step: 3.576\n",
      "\ttest/roughly  1.173 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 361/1512\n",
      "\ttest/sec_per_step: 3.513\n",
      "\ttest/roughly  1.123 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 391/1512\n",
      "\ttest/sec_per_step: 3.567\n",
      "\ttest/roughly  1.111 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 421/1512\n",
      "\ttest/sec_per_step: 3.625\n",
      "\ttest/roughly  1.098 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 451/1512\n",
      "\ttest/sec_per_step: 3.644\n",
      "\ttest/roughly  1.074 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 481/1512\n",
      "\ttest/sec_per_step: 3.625\n",
      "\ttest/roughly  1.038 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 511/1512\n",
      "\ttest/sec_per_step: 3.694\n",
      "\ttest/roughly  1.027 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 541/1512\n",
      "\ttest/sec_per_step: 3.570\n",
      "\ttest/roughly  0.963 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 571/1512\n",
      "\ttest/sec_per_step: 3.597\n",
      "\ttest/roughly  0.940 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 601/1512\n",
      "\ttest/sec_per_step: 3.735\n",
      "\ttest/roughly  0.945 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 631/1512\n",
      "\ttest/sec_per_step: 3.905\n",
      "\ttest/roughly  0.956 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 661/1512\n",
      "\ttest/sec_per_step: 3.958\n",
      "\ttest/roughly  0.936 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 691/1512\n",
      "\ttest/sec_per_step: 3.906\n",
      "\ttest/roughly  0.891 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 721/1512\n",
      "\ttest/sec_per_step: 4.013\n",
      "\ttest/roughly  0.882 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 751/1512\n",
      "\ttest/sec_per_step: 3.974\n",
      "\ttest/roughly  0.840 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 781/1512\n",
      "\ttest/sec_per_step: 3.893\n",
      "\ttest/roughly  0.790 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 811/1512\n",
      "\ttest/sec_per_step: 3.784\n",
      "\ttest/roughly  0.737 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 841/1512\n",
      "\ttest/sec_per_step: 3.689\n",
      "\ttest/roughly  0.688 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 871/1512\n",
      "\ttest/sec_per_step: 3.785\n",
      "\ttest/roughly  0.674 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 901/1512\n",
      "\ttest/sec_per_step: 3.982\n",
      "\ttest/roughly  0.676 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 931/1512\n",
      "\ttest/sec_per_step: 3.973\n",
      "\ttest/roughly  0.641 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 961/1512\n",
      "\ttest/sec_per_step: 3.957\n",
      "\ttest/roughly  0.606 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 991/1512\n",
      "\ttest/sec_per_step: 3.987\n",
      "\ttest/roughly  0.577 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1021/1512\n",
      "\ttest/sec_per_step: 3.948\n",
      "\ttest/roughly  0.538 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1051/1512\n",
      "\ttest/sec_per_step: 3.964\n",
      "\ttest/roughly  0.508 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1081/1512\n",
      "\ttest/sec_per_step: 3.711\n",
      "\ttest/roughly  0.444 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1111/1512\n",
      "\ttest/sec_per_step: 3.735\n",
      "\ttest/roughly  0.416 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1141/1512\n",
      "\ttest/sec_per_step: 3.672\n",
      "\ttest/roughly  0.378 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1171/1512\n",
      "\ttest/sec_per_step: 3.790\n",
      "\ttest/roughly  0.359 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1201/1512\n",
      "\ttest/sec_per_step: 3.900\n",
      "\ttest/roughly  0.337 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1231/1512\n",
      "\ttest/sec_per_step: 3.938\n",
      "\ttest/roughly  0.307 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1261/1512\n",
      "\ttest/sec_per_step: 4.014\n",
      "\ttest/roughly  0.280 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1291/1512\n",
      "\ttest/sec_per_step: 3.899\n",
      "\ttest/roughly  0.239 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1321/1512\n",
      "\ttest/sec_per_step: 3.786\n",
      "\ttest/roughly  0.201 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1351/1512\n",
      "\ttest/sec_per_step: 3.906\n",
      "\ttest/roughly  0.175 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1381/1512\n",
      "\ttest/sec_per_step: 3.794\n",
      "\ttest/roughly  0.138 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1411/1512\n",
      "\ttest/sec_per_step: 3.433\n",
      "\ttest/roughly  0.096 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1441/1512\n",
      "\ttest/sec_per_step: 3.472\n",
      "\ttest/roughly  0.068 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1471/1512\n",
      "\ttest/sec_per_step: 3.487\n",
      "\ttest/roughly  0.040 hours to go.\n",
      "####### testting logging #######\n",
      "\ttest/current_step: 1501/1512\n",
      "\ttest/sec_per_step: 3.704\n",
      "\ttest/roughly  0.011 hours to go.\n",
      "Error raised: segment ids are not increasing\n",
      "\t [[Node: SegmentMean = SegmentMean[T=DT_FLOAT, Tindices=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](concat_1, UniqueWithCounts_1:1)]]\n",
      "\n",
      "Caused by op 'SegmentMean', defined at:\n",
      "  File \"/home/rs/.pyenv/versions/3.5.2/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/rs/.pyenv/versions/3.5.2/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-95834f7a64e7>\", line 77, in <module>\n",
      "    mean_prob = tf.segment_mean(cur_prob_head, idx)\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 3763, in segment_mean\n",
      "    \"SegmentMean\", data=data, segment_ids=segment_ids, name=name)\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/home/kapok/pyenv35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n",
      "    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n",
      "\n",
      "InvalidArgumentError (see above for traceback): segment ids are not increasing\n",
      "\t [[Node: SegmentMean = SegmentMean[T=DT_FLOAT, Tindices=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](concat_1, UniqueWithCounts_1:1)]]\n",
      ".\n",
      "Testting did't finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished Testting: 2017-12-14_21_52_35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0, 1\n"
     ]
    }
   ],
   "source": [
    "def slices_to_dims(slice_indices):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    slice_indices: An [N, k] Tensor mapping to column indices.\n",
    "    Returns:\n",
    "    An index Tensor with shape [N * k, 2], corresponding to indices suitable for\n",
    "    passing to SparseTensor.\n",
    "    \"\"\"\n",
    "    slice_indices = tf.cast(slice_indices, tf.int64)\n",
    "    num_rows = tf.shape(slice_indices, out_type=tf.int64)[0]\n",
    "    row_range = tf.range(num_rows)\n",
    "    # row_range expanded from [num_rows] into [num_rows, 1]\n",
    "    # every item in k_th row of slice_indices are multiplied by num_rows, then added by k with broadcast\n",
    "    item_numbers = slice_indices * num_rows + tf.expand_dims(row_range, axis=1)\n",
    "    # flaten so that each row represent each element\n",
    "    item_numbers_flat = tf.reshape(item_numbers, [-1])\n",
    "    # convert back by zip op\n",
    "    return item_numbers_flat % num_rows, item_numbers_flat // num_rows\n",
    "\n",
    "timer_holder = TimeRecorder()\n",
    "timer_holder.register_event('eval_log_time', log_step_interval, False)\n",
    "\n",
    "cdiscount_net = torch_resnet.resnet152(pretrained=False, num_classes=NUM_CLASS)\n",
    "\n",
    "#print(cdiscount_net)\n",
    "if torch.cuda.is_available():\n",
    "    cdiscount_net = cdiscount_net.cuda()\n",
    "for p in cdiscount_net.parameters():\n",
    "    p.requires_grad = False\n",
    "if len(GPU_ID) > 1:\n",
    "    cdiscount_net = torch.nn.DataParallel(cdiscount_net) #use default\n",
    "cdiscount_net = load_pretrain_file(cdiscount_net, PRETRAINED_MODEL_PATH, [])\n",
    "\n",
    "# we use train augumentation to diversify the input images\n",
    "test_set = CdiscountDataset(tf_sess, TEST_PATH, 'output_file', TOTAL_EXAMPLES, NUM_CLASS, 12000, BATCH_SIZE, False)\n",
    "\n",
    "test_initializer = test_set.create_dataset()\n",
    "\n",
    "# when you first create a session, there will be one default graph with it unless you pass one another\n",
    "tf_sess.run(tf.group(tf.global_variables_initializer(), tf.local_variables_initializer(), tf.tables_initializer()))\n",
    "default_graph = tf.get_default_graph()\n",
    "additional_graph = tf.Graph()\n",
    "tf_additional_sess = tf.Session(graph = additional_graph, config=tf.ConfigProto(device_count={'CPU' : 1, 'GPU' : 0}, allow_soft_placement=True))\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    with additional_graph.as_default():\n",
    "        label_mapping = LabelMapping(CATEGORY_NAME_PATH)\n",
    "        last_prob = tf.placeholder(tf.float32)\n",
    "        last_id = tf.placeholder(tf.int64)\n",
    "        batch_id = tf.placeholder(tf.int64, shape=(None))\n",
    "        logits_pred = tf.placeholder(tf.float32, shape=(None, 5270))\n",
    "\n",
    "        test_probabilities = layers_lib.softmax(logits_pred, scope='torch_logits2prob')\n",
    "        predictions = tf.argmax(test_probabilities, 1)\n",
    "\n",
    "        test_predictions_values = tf.string_to_number(label_mapping.index2catogory_inv_table.lookup(predictions), out_type=tf.int64) \n",
    "\n",
    "        top_values, top_indices = tf.nn.top_k(test_probabilities, k = NUM_OF_TOPK, sorted=True)\n",
    "        (row_indice, col_indice), value_array = slices_to_dims(top_indices), tf.reshape(top_values, [-1])\n",
    "        cur_prob_shape = tf.shape(test_probabilities)\n",
    "        # concat betweent batches\n",
    "        _, idx, count = tf.unique_with_counts(batch_id)\n",
    "        #print(tf.dynamic_partition(batch_id, tf.not_equal(idx, tf.shape(count)[0] - 1).eval(), 2)[1].eval())  \n",
    "        cur_id_tail, _cur_id_head = tf.dynamic_partition(batch_id, tf.cast(tf.not_equal(idx, tf.shape(count)[0] - 1), tf.int32), 2)\n",
    "        with tf.control_dependencies([cur_id_tail, _cur_id_head]):\n",
    "            cur_id_head = tf.concat([last_id, _cur_id_head], axis = 0)\n",
    "        #cur_id_head = tf.concat([last_id, tf.concat(tf.split(batch_id, count)[0:-1], axis = 0)], axis = 0)\n",
    "        #cur_id_tail = tf.split(batch_id, count)[-1]\n",
    "\n",
    "        cur_prob_tail, _cur_prob_head = tf.dynamic_partition(test_probabilities, tf.cast(tf.not_equal(idx, tf.shape(count)[0] - 1), tf.int32), 2)\n",
    "        with tf.control_dependencies([last_prob, _cur_prob_head]):\n",
    "            cur_prob_head = tf.concat([last_prob, _cur_prob_head], axis = 0)\n",
    "        #cur_prob_head = tf.concat([last_prob, tf.concat(tf.split(test_probabilities, count[0:-1]), axis = 0)], axis = 0)\n",
    "        #cur_prob_tail = tf.split(test_probabilities, count)[-1]\n",
    "        with tf.control_dependencies([cur_id_head, cur_prob_head]):\n",
    "            raw_id, idx, _ = tf.unique_with_counts(cur_id_head)\n",
    "            mean_prob = tf.segment_mean(cur_prob_head, idx)\n",
    "            #mean_prob = segment_median(cur_prob_head, tf.cast(idx, tf.float32))\n",
    "            mean_label = tf.string_to_number(label_mapping.index2catogory_inv_table.lookup(tf.argmax(mean_prob, 1)), out_type=tf.int64) \n",
    "            #mean_label = tf.argmax(mean_prob, 1)\n",
    "        with tf.control_dependencies([mean_prob, mean_label]):\n",
    "            #last_id = cur_id_tail\n",
    "            #last_prob = cur_prob_tail\n",
    "            # last partition may have nothing to concat\n",
    "            raw_id_tail, idx_tail, _ = tf.unique_with_counts(cur_id_tail)\n",
    "            mean_prob_tail = tf.segment_mean(cur_prob_tail, idx_tail)\n",
    "            #mean_prob_tail = segment_median(cur_prob_tail, tf.cast(idx_tail, tf.float32))\n",
    "            tail_label = tf.string_to_number(label_mapping.index2catogory_inv_table.lookup(tf.argmax(mean_prob_tail, 1)), out_type=tf.int64) \n",
    "        #total_pred = tf.string_to_number(label_mapping.index2catogory_inv_table.lookup(tf.argmax(mean_prob_tail, 1)), out_type=tf.int64) \n",
    "        tf_additional_sess.run(tf.group(tf.global_variables_initializer(), tf.local_variables_initializer(), tf.tables_initializer()))\n",
    "\n",
    "#tf_sess.run(train_initializer)\n",
    "#print(tf_sess.run(train_set.get_next()))\n",
    "#tf_sess.run(train_set[0])\n",
    "        \n",
    "lats_pred = []\n",
    "last_batch_id = []\n",
    "last_feed_id = np.empty([0])\n",
    "last_feed_prob = np.empty([0, NUM_CLASS])\n",
    "save_file_name = OUTPUT_PATH.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "save_logits_file_name = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytorch/cdiscount/logs_resnet_test/{}.csv'.format(datetime.now().strftime('logits_%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "prob_save_file_name = PROB_SAVE_FILE.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "hdf5_file = tb.open_file(prob_save_file_name, 'w')\n",
    "total_prob_store = hdf5_file.create_earray(hdf5_file.root, 'prob', tb.Float32Atom(), shape=(0,), filters=tb.Filters(complevel=5, complib='zlib'))\n",
    "total_row_indice = hdf5_file.create_earray(hdf5_file.root, 'row', tb.Int64Atom(), shape=(0,), filters=tb.Filters(complevel=5, complib='zlib'))\n",
    "total_col_indice = hdf5_file.create_earray(hdf5_file.root, 'col', tb.Int64Atom(), shape=(0,), filters=tb.Filters(complevel=5, complib='zlib'))\n",
    "log.info(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "#target_onehot = torch.FloatTensor(batch_size, 4)\n",
    "timer_holder.reset_event('eval_log_time', 0)\n",
    "MDEBUG = False\n",
    "\n",
    "try:\n",
    "#if True:\n",
    "    # check on validation every epoches            \n",
    "    cdiscount_net.eval()\n",
    "    tf_sess.run(test_initializer)\n",
    "    timer_holder.reset_event('eval_log_time', 1)\n",
    "    #if False:\n",
    "    for index in range(len(test_set)):\n",
    "        try:\n",
    "            data_value = tf_sess.run(test_set.get_next())\n",
    "            #next_example = [torch.from_numpy(array) for array in data_value]\n",
    "            next_example, next_product_id = torch.FloatTensor(data_value[0]), torch.LongTensor(data_value[1])\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            log.info('dataset run out.')\n",
    "            break\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            example_in = Variable(next_example).cuda()\n",
    "        else:\n",
    "            example_in = Variable(next_example)\n",
    "        #logits_from_pytorch = Variable(torch.rand(next_product_id.size()[0], 5270))\n",
    "        logits_from_pytorch = cdiscount_net(example_in)\n",
    "        _, batch_top1 = torch.topk(nn.Softmax()(logits_from_pytorch), 1)\n",
    "        batch_top1 = batch_top1.type(torch.LongTensor)\n",
    "        if torch.cuda.is_available():\n",
    "            batch_top1 = batch_top1.cuda()\n",
    "        #print(batch_top1.data.cpu().numpy())\n",
    "        \n",
    "        total_pred, last_feed_id, last_feed_prob, test_pred, test_prob, test_batch_id, lats_pred, last_batch_id, = \\\n",
    "                            tf_additional_sess.run([test_predictions_values, cur_id_tail, cur_prob_tail, mean_label, mean_prob, \\\n",
    "                                      raw_id, tail_label, raw_id_tail], feed_dict = {last_prob: last_feed_prob, last_id: last_feed_id, batch_id: data_value[1], logits_pred: logits_from_pytorch.data.cpu().numpy()})\n",
    "        #print(csr_matrix((sparse_value, (sparse_row, sparse_col)), shape=sparse_shape).toarray())\n",
    "        #total_prob_store[last_row_to_save:last_row_to_save + sparse_shape[0],:] = csr_matrix((sparse_value, (sparse_row, sparse_col)), shape=sparse_shape).toarray()\n",
    "        \n",
    "#         print(total_pred)\n",
    "#         print(len(total_pred))\n",
    "        raw_pred = pd.DataFrame(data=total_pred, index=data_value[1])\n",
    "        if not os.path.isfile(save_logits_file_name):\n",
    "            raw_pred.to_csv(save_logits_file_name, mode='a', index=True, sep=',')\n",
    "        else:\n",
    "            raw_pred.to_csv(save_logits_file_name, mode='a', index=True, sep=',', header=False)\n",
    "\n",
    "        #logits_df = pd.DataFrame(data=logits_from_pytorch.data.cpu().numpy(), index=data_value[1])\n",
    "\n",
    "#         if not os.path.isfile(save_file_name):\n",
    "#             logits_df.to_csv(save_logits_file_name, mode='a', index=True, sep=',', compression='bz2')\n",
    "#         else:\n",
    "#             logits_df.to_csv(save_logits_file_name, mode='a', index=True, sep=',', header=False, compression='bz2')\n",
    "\n",
    "\n",
    "#         total_prob_store.append(sparse_value)\n",
    "#         total_row_indice.append(sparse_row)\n",
    "#         total_col_indice.append(sparse_col)\n",
    "        \n",
    "#         print(len(test_batch_id), len(test_pred))\n",
    "#         print(test_batch_id)\n",
    "        #print(test_pred)\n",
    "        #last_row_to_save += sparse_shape[0]\n",
    "        #print(len(test_prob[0]))\n",
    "        df = pd.DataFrame({'_id' : test_batch_id, 'category_id' : test_pred})\n",
    "\n",
    "        if not os.path.isfile(save_file_name):\n",
    "            df.to_csv(save_file_name, mode='a', index=False, sep=',')\n",
    "        else:\n",
    "            df.to_csv(save_file_name, mode='a', index=False, sep=',', header=False)\n",
    "#         log.info('BB ID: {}'.format(data_value[1]))\n",
    "#         log.info('Test Label: {}'.format(test_pred))\n",
    "#         log.info('Test Prob: {}'.format(test_prob))\n",
    "#         log.info('Test Ids: {}'.format(test_batch_id))\n",
    "#         log.info('Last Label: {}'.format(lats_pred))\n",
    "#         #log.info('Test Prob: {}'.format(test_prob))\n",
    "#         log.info('Last Ids: {}'.format(last_batch_id))\n",
    "#         log.info('last_feed_id: {}'.format(last_feed_id))\n",
    "#         log.info('last_feed_prob: {}'.format(last_feed_prob))\n",
    "#         if index > 3:\n",
    "#             break\n",
    "\n",
    "        if timer_holder.check_for_me('eval_log_time', index):\n",
    "            time_passed = timer_holder.get_ticks_passed()\n",
    "            log.info('####### testting logging #######')\n",
    "            log.info('\\ttest/current_step: {}/{}'.format(index, NUM_STEPS))\n",
    "            log.info('\\ttest/sec_per_step: {:.3f}'.format(time_passed/log_step_interval))\n",
    "            log.info('\\ttest/roughly {:6.3f} hours to go.'.format(  time_passed/log_step_interval*( (NUM_STEPS-index) > 0 and (NUM_STEPS-index)/3600. or 0.001 )  ))\n",
    "            #log.info('Test Label: {}'.format(test_pred))\n",
    "            #log.info('Test Prob: {}'.format(test_prob))\n",
    "            #log.info('Test Ids: {}'.format(test_batch_id))\n",
    "            if MDEBUG: break\n",
    "except BaseException as error:\n",
    "#if False:\n",
    "    # use tensorflow to fill the GPU no matter what reason caused\n",
    "    log.info(\"Error raised: {}.\\r\\nTestting did't finished.\".format(error))\n",
    "    tf_sess.close()\n",
    "    get_ipython().magic('env CUDA_VISIBLE_DEVICES = {}'.format(', '.join(map(str, GPU_ID))))\n",
    "    import tensorflow as tf\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1.)\n",
    "    tf_sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options))\n",
    "tf_sess.close()\n",
    "df = pd.DataFrame({'_id' : last_batch_id, 'category_id' : lats_pred})\n",
    "df.to_csv(save_file_name, mode='a', index=False, sep=',', header=False)\n",
    "hdf5_file.close()\n",
    "log.info('Finished Testting: {}'.format(datetime.now().strftime('%Y-%m-%d_%H_%M_%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "              _id  category_id\n",
      "1767848  23597507   1000005732\n",
      "1767849  23597584   1000000504\n",
      "1767850  23597618   1000010151\n",
      "1767851  23597686   1000011427\n",
      "1767852  23597750   1000006458\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(save_file_name)\n",
    "log.info(test_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)\n",
    "print(pd.read_csv('/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytorch/cdiscount/logs_resnet_test/output_2017-12-14 18:32:02.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.read_csv('/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytorch/cdiscount/logs_resnet_test/output_2017-12-14 14:35:36.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              _id  category_id\n",
      "0              10   1000005605\n",
      "1              27   1000022508\n",
      "2              67   1000005986\n",
      "3              94   1000004079\n",
      "4             115   1000002786\n",
      "5             141   1000004079\n",
      "6             165   1000010653\n",
      "7             196   1000010653\n",
      "8             210   1000014026\n",
      "9             231   1000016662\n",
      "10            254   1000005874\n",
      "11            272   1000014245\n",
      "12            285   1000012509\n",
      "13            298   1000005926\n",
      "14            326   1000010653\n",
      "15            338   1000010653\n",
      "16            353   1000006016\n",
      "17            365   1000010667\n",
      "18            370   1000010653\n",
      "19            386   1000010667\n",
      "20            402   1000002194\n",
      "21            421   1000014154\n",
      "22            425   1000010653\n",
      "23            441   1000014311\n",
      "24            456   1000010667\n",
      "25            483   1000001840\n",
      "26            488   1000004141\n",
      "27            499   1000011046\n",
      "28            512   1000005414\n",
      "29            525   1000010667\n",
      "...           ...          ...\n",
      "1768152  23616935   1000010001\n",
      "1768153  23617097   1000014202\n",
      "1768154  23617166   1000018296\n",
      "1768155  23617216   1000010126\n",
      "1768156  23617315   1000005599\n",
      "1768157  23617417   1000010677\n",
      "1768158  23617484   1000011349\n",
      "1768159  23617558   1000018296\n",
      "1768160  23617676   1000003974\n",
      "1768161  23617845   1000010090\n",
      "1768162  23617995   1000005848\n",
      "1768163  23618162   1000018166\n",
      "1768164  23618232   1000003796\n",
      "1768165  23618366   1000016272\n",
      "1768166  23618515   1000018296\n",
      "1768167  23618610   1000014202\n",
      "1768168  23618678   1000020845\n",
      "1768169  23618753   1000010836\n",
      "1768170  23618800   1000015912\n",
      "1768171  23618986   1000014285\n",
      "1768172  23619172   1000010551\n",
      "1768173  23619258   1000010538\n",
      "1768174  23619428   1000001256\n",
      "1768175  23619555   1000018282\n",
      "1768176  23619623   1000018290\n",
      "1768177  23619792   1000003787\n",
      "1768178  23619873   1000014224\n",
      "1768179  23619968   1000010049\n",
      "1768180  23620195   1000017067\n",
      "1768181  23620240   1000008852\n",
      "\n",
      "[1768182 rows x 2 columns]\n",
      "23597750\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_csv('/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytorch/cdiscount/logs_resnet_test/result_mean.csv'))\n",
    "print(pd.read_csv('/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytorch/cdiscount/logs_resnet_test/result_mean.csv')['_id'][1767852])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.concat([pd.read_csv(save_file_name)[:1768182], pd.read_csv('/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytorch/cdiscount/logs_resnet_test/0.6837.csv')[1767853:]], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([pd.read_csv(save_file_name)[:1768182], pd.read_csv('/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytorch/cdiscount/logs_resnet_test/0.6837.csv')[1767853:]], axis=0).to_csv('/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytorch/cdiscount/logs_resnet_test/result_mean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.read_csv(save_file_name)[:1768182])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(save_file_name)[:1768182].to_csv(save_file_name+'fff', index=False, sep=',', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
