{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=\n",
      "env: CUDA_VISIBLE_DEVICES=0, 1\n"
     ]
    }
   ],
   "source": [
    "GPU_ID = [0, 1]\n",
    "# tensorboard --logdir=/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytoh/cdiscount/logs_resnet --port=6008\n",
    "# The line below sets the environment\n",
    "# variable CUDA_VISIBLE_DEVICES\n",
    "get_ipython().magic('env CUDA_VISIBLE_DEVICES = ')\n",
    "#%env CUDA_VISIBLE_DEVICES = 0\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread, imsave, imshow, imresize\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.)\n",
    "tf_sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options))\n",
    "# now tensorflow will assume there not exist gpu\n",
    "# use this tf_session following, and close in the end\n",
    "#tf_sess.close()\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import time\n",
    "import io\n",
    "from datetime import datetime\n",
    "import gc # garbage collector\n",
    "import logging\n",
    "get_ipython().magic('env CUDA_VISIBLE_DEVICES = {}'.format(', '.join(map(str, GPU_ID))))\n",
    "from tensorboard_logger import configure, log_value\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch_resnet\n",
    "# for test\n",
    "import cdscount_preprocessing\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "get_ipython().magic('matplotlib inline')\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "get_ipython().magic('load_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/'\n",
    "#PRETRAINED_MODEL_PATH = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytorch/cdiscount/models/resnet101-5d3b4d8f.pth'\n",
    "PRETRAINED_MODEL_PATH = '/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytorch/cdiscount/models/resnet152-b121ed2d.pth'\n",
    "\n",
    "LOG_DIR = DATASET_PATH + 'pytorch/cdiscount/logs_resnet_focal_loss'\n",
    "LR_FILE_PATH = DATASET_PATH + 'pytorch/cdiscount/logs_resnet_focal_loss/lr_setting/resnet_lr_setting'\n",
    "TRAIN_PATH = DATASET_PATH + 'Split/Train/'\n",
    "#TRAIN_PATH = '/media/rs/FC6CDC6F6CDC25E4/resample_dataset2/'\n",
    "VAL_PATH = DATASET_PATH + 'Split/Validation/'\n",
    "TEST_PATH = DATASET_PATH + 'Test/'\n",
    "CATEGORY_NAME_PATH = DATASET_PATH + 'category_names.csv'\n",
    "CATEGORY_WEIGHT_PATH = DATASET_PATH + 'catogory_with_weight.csv'\n",
    "\n",
    "# following is non-resampled, and only 10mil\n",
    "LEVEL1_WEIGHT = [1.817, 1.528, 1.056, 2.174, 1.622, 2.531, 2.663, 1.103, 1.935, 1.937, 2.898, 1.279, 2.923, 1.095, 2.086, 3.0, 2.218, 3.0, 3.0, 2.123, 3.0, 1.038, 3.0, 3.0, 3.0, 3.0, 1.817, 1.448, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.955, 3.0, 1.946, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0]\n",
    "\n",
    "BATCH_SIZE = 128#112#256\n",
    "VAL_BATCH_SIZE = 16\n",
    "\n",
    "IMAGE_WIDTH = 180\n",
    "IMAGE_HEIGHT = 180\n",
    "NUM_CLASS = 5270\n",
    "LEVEL1_CLASS = 49\n",
    "LEVEL2_CLASS = 483\n",
    "# validation examples num: 2319624\n",
    "# train examples num: 10051704\n",
    "# total step: 157057\n",
    "TOTAL_EXAMPLES = 12301740\n",
    "VAL_EXAMPLES = 69588\n",
    "\n",
    "NUM_EPOCHES = 12\n",
    "EPOCHES_OVER = 8\n",
    "\n",
    "INPUT_THREADS = 8\n",
    "\n",
    "save_time_interval = 7200\n",
    "log_step_interval = 200\n",
    "\n",
    "initial_learning_rate = 0.0005#0.0004\n",
    "stop_learning_rate = 0.0000001\n",
    "momentum = 0.9\n",
    "num_steps_per_train_epoch = int(TOTAL_EXAMPLES / (BATCH_SIZE)) + 1\n",
    "num_steps_per_val_epoch = int(VAL_EXAMPLES / (VAL_BATCH_SIZE)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_logging(logger_name, logger_file_name):\n",
    "    log = logging.getLogger(logger_name)\n",
    "    log.setLevel(logging.DEBUG)\n",
    "\n",
    "    # create formatter and add it to the handlers\n",
    "    print_formatter = logging.Formatter('%(message)s')\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(name)s_%(levelname)s: %(message)s')\n",
    "\n",
    "    # create file handler which logs even debug messages\n",
    "    fh = logging.FileHandler(logger_file_name, mode='w')\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    fh.setFormatter(file_formatter)\n",
    "    log.addHandler(fh)\n",
    "    # both output to console and file\n",
    "    consoleHandler = logging.StreamHandler()\n",
    "    consoleHandler.setFormatter(print_formatter)\n",
    "    log.addHandler(consoleHandler)\n",
    "    \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "here is an info message.\n"
     ]
    }
   ],
   "source": [
    "log = set_logging('CDiscount', DATASET_PATH + 'pytorch/cdiscount/resnet_pytorch_focal_loss.log')\n",
    "log.info('here is an info message.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Saver(object):\n",
    "    def __init__(self, log_dir, ckeckpoint_name, max_to_keep=5):\n",
    "        super(Saver, self).__init__()\n",
    "        self._log_dir = log_dir\n",
    "        self._max_to_keep = max_to_keep\n",
    "        self._ckeckpoint_container_file = os.path.join(self._log_dir, 'checkpoint')\n",
    "        self._ckeckpoint_name = os.path.join(self._log_dir, ckeckpoint_name)\n",
    "        self._best_ckeckpoint_name = os.path.join(self._log_dir, 'best_checkpoint')\n",
    "        os.makedirs(self._log_dir, exist_ok=True)\n",
    "        os.makedirs(self._best_ckeckpoint_name, exist_ok=True)\n",
    "        self._best_ckeckpoint_name = os.path.join(self._best_ckeckpoint_name, ckeckpoint_name)\n",
    "    def save_checkpoint(self, model_state_dict, other_state_dict, tag, is_best=False):\n",
    "        checkpoint_list = list()\n",
    "        if os.path.exists(self._ckeckpoint_container_file):\n",
    "            with open(self._ckeckpoint_container_file, 'r') as checkpoint_file:\n",
    "                for index, line in enumerate(checkpoint_file):\n",
    "                    if index == 0: continue\n",
    "                    if line.strip() != '':\n",
    "                        checkpoint_list.append(line.strip())\n",
    "        if not is_best: \n",
    "            model_save_name = (self._ckeckpoint_name + '_pytorch_state_{}_{}.pth').format(tag, datetime.now().strftime('%Y-%m-%d_%H_%M_%S'))\n",
    "        else:\n",
    "            model_save_name = (self._best_ckeckpoint_name + '_pytorch_state_{}_{}.pth').format(tag, datetime.now().strftime('%Y-%m-%d_%H_%M_%S'))\n",
    "        checkpoint_list.append(model_save_name)\n",
    "\n",
    "        torch.save(model_state_dict, model_save_name)\n",
    "        torch.save(other_state_dict, model_save_name.replace('state', 'others'))\n",
    "\n",
    "        log.info('model saved: {}.'.format(model_save_name))\n",
    "\n",
    "        # remove checkpoint older than 5\n",
    "        if len(checkpoint_list) > self._max_to_keep:\n",
    "            checkpoint_list_to_delete = checkpoint_list[:-self._max_to_keep]\n",
    "            checkpoint_list = checkpoint_list[-self._max_to_keep:]\n",
    "            for model_file in checkpoint_list_to_delete:\n",
    "                if os.path.isfile(model_file): os.remove(model_file)\n",
    "                model_file = model_file.replace('state','others')\n",
    "                if os.path.isfile(model_file):  os.remove(model_file)\n",
    "        with open(self._ckeckpoint_container_file, 'w') as outfile:\n",
    "            outfile.write(model_save_name+'\\n')\n",
    "            for line in checkpoint_list:\n",
    "                outfile.write(line+'\\n')\n",
    "\n",
    "    def restore_from_checkpoint(self, model, step=None):\n",
    "        checkpoint_filename = None\n",
    "        if os.path.exists(self._ckeckpoint_container_file):\n",
    "            with open(self._ckeckpoint_container_file, 'r') as checkpoint_file:\n",
    "                for _, line in enumerate(checkpoint_file):\n",
    "                    line = line.strip()\n",
    "                    if line != '':\n",
    "                        # get the first one\n",
    "                        if step is None:\n",
    "                            checkpoint_filename = line\n",
    "                            break\n",
    "                        # get the specified one\n",
    "                        elif str(step) in line:\n",
    "                            checkpoint_filename = line\n",
    "                            break\n",
    "        if (not os.path.isdir(self._log_dir)) or (checkpoint_filename is None):\n",
    "            return None\n",
    "\n",
    "        model.load_state_dict(torch.load(checkpoint_filename, map_location=lambda storage, loc: storage))    \n",
    "\n",
    "        log.info('model resotred from: {}.'.format(checkpoint_filename))\n",
    "\n",
    "        return torch.load(checkpoint_filename.replace('state','others'))\n",
    "\n",
    "class TimeRecorder(object):\n",
    "    def __init__(self):\n",
    "        super(TimeRecorder, self).__init__()\n",
    "        self._tick_map = dict()\n",
    "        self._recorder = dict()\n",
    "        self._use_time = dict()\n",
    "        self._last_interval = dict()\n",
    "        self.register_event('ticks', 1, True)\n",
    "    # register at the very begining\n",
    "    # when not use time, call reset_event with your initial value at each start\n",
    "    def register_event(self, name, tick, use_time=True):\n",
    "        self._tick_map[name] = tick\n",
    "        self._last_interval[name] = 0\n",
    "        self._recorder[name] = 0\n",
    "        if use_time:\n",
    "            self._recorder[name] = time.time() \n",
    "        self._use_time[name] = use_time\n",
    "    def reset_event(self, name, criterion=None):\n",
    "        if self._use_time[name]: self._recorder[name] = time.time()\n",
    "        elif criterion is not None: self._recorder[name] = criterion\n",
    "        self._last_interval[name] = 0\n",
    "    def cancel_event(self, name):\n",
    "        self._tick_map.pop(name, None)\n",
    "        self._last_interval.pop(name, None)\n",
    "        self._recorder.pop(name, None)\n",
    "        self._use_time.pop(name, None)\n",
    "    def get_ticks_passed(self):\n",
    "        passed = time.time() - self._recorder['ticks']\n",
    "        self._recorder['ticks'] = time.time()\n",
    "        return passed/self._tick_map['ticks']\n",
    "    # you can call this to get how log elapsed after you get True from check_for_me\n",
    "    def how_long_before(self, name):\n",
    "        return self._last_interval[name]\n",
    "    def check_for_me(self, name, criterion=None):\n",
    "        if self._use_time[name]:\n",
    "            if time.time() - self._recorder[name] >= self._tick_map[name]:\n",
    "                self._last_interval[name] = time.time() - self._recorder[name]\n",
    "                self._recorder[name] = time.time()\n",
    "                return True\n",
    "        elif criterion is not None:\n",
    "            if criterion - self._recorder[name] >= self._tick_map[name]:\n",
    "                self._last_interval[name] = criterion - self._recorder[name]\n",
    "                self._recorder[name] = criterion\n",
    "                return True\n",
    "        return False\n",
    "def load_pretrain_file(net, pretrain_file, skip=[]):\n",
    "    pretrain_state_dict = torch.load(pretrain_file)\n",
    "    state_dict = net.state_dict()\n",
    "    keys = list(state_dict.keys())\n",
    "    for key in keys:\n",
    "        if any(s in key for s in skip):\n",
    "            continue\n",
    "        pretrain_key = key\n",
    "        #if 'layer0.0.conv.' in key: pretrain_key=key.replace('layer0.0.conv.',  'conv1.' )\n",
    "        state_dict[key] = pretrain_state_dict[pretrain_key]\n",
    "        \n",
    "    net.load_state_dict(state_dict)\n",
    "    return net\n",
    "\n",
    "class CriterionSmooth(object):\n",
    "    def __init__(self):\n",
    "        super(CriterionSmooth, self).__init__()\n",
    "        self._history = dict()\n",
    "        self._factor = dict()\n",
    "        self._just_add = dict()\n",
    "    def register_smooth(self, name, factor=0.6):\n",
    "        self._history[name] = 0.\n",
    "        self._just_add[name] = False\n",
    "        if factor < 0: self._just_add[name] = True\n",
    "        if factor > 1.: factor=1.\n",
    "        self._factor[name] = 1. - factor\n",
    "    def push_new_value(self, name, value):\n",
    "        if self._just_add[name]: self._history[name] = self._history[name] + value\n",
    "        else: self._history[name] = self._history[name] * (1.-self._factor[name]) + value*self._factor[name]\n",
    "        return value\n",
    "    def smooth_value(self, name):\n",
    "        return self._history[name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_lr_scheduler(optimizer, epoch, init_lr=0.01, lr_decay_epoch=1):\n",
    "    lr = init_lr * (0.27**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if lr < 0.000002: lr = 0.000002\n",
    "        \n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        log.info('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer\n",
    "def read_learning_rate(cur_step, num_steps_per_epoch):\n",
    "    def inner_lr_parser(interval_start, interval_end, lr, dict_in, default_lr, use_epoch_percent, num_steps_per_epoch):\n",
    "        lr = default_lr * lr\n",
    "        if use_epoch_percent:\n",
    "            interval_start = num_steps_per_epoch * interval_start\n",
    "            interval_end = num_steps_per_epoch * interval_end\n",
    "        interval_start = int(interval_start)\n",
    "        interval_end = int(interval_end)\n",
    "        if (interval_start < interval_end) and (lr > 0):\n",
    "            dict_in[(interval_start, interval_end)] = lr\n",
    "            \n",
    "    lr_map = dict()\n",
    "    default_lr = initial_learning_rate\n",
    "    stop_lr = stop_learning_rate\n",
    "    line_index = -1\n",
    "    use_epoch_percent = True\n",
    "    if os.path.exists(LR_FILE_PATH):\n",
    "        with open(LR_FILE_PATH, 'r') as lr_setting_file:\n",
    "            for _, line in enumerate(lr_setting_file):\n",
    "                line = line.strip()\n",
    "                if (line != '') and (not line.startswith('#')):\n",
    "                    line_index += 1\n",
    "                    if line_index == 0:\n",
    "                        default_lr = float(line.split(':')[-1].strip())\n",
    "                        continue\n",
    "                    if line_index == 1:\n",
    "                        stop_lr = float(line.split(':')[-1].strip())\n",
    "                        continue\n",
    "                    if line_index == 2:\n",
    "                        use_epoch_percent = ('EPOCHES_PERCENT' in (line.split(':')[-1].strip()))\n",
    "                        continue\n",
    "                    # this is a list desciption\n",
    "                    if line.startswith('['):\n",
    "                        line = [float(s.strip()) for s in line[1:-1].strip().split()]\n",
    "                        step_interval = (line[1] - line[0])/line[-1]\n",
    "                        lr_interval = (line[3] - line[2])/line[-1]\n",
    "                        begin = line[0]\n",
    "                        lr_begin = line[2]\n",
    "                        for index in range(int(line[-1])):\n",
    "                            inner_lr_parser(begin, begin+step_interval, lr_begin, lr_map, default_lr, use_epoch_percent, num_steps_per_epoch)\n",
    "                            begin += step_interval\n",
    "                            lr_begin += lr_interval\n",
    "                    else:\n",
    "                        interval_start, interval_end, lr = [float(s) for s in line.strip().split()]\n",
    "                        inner_lr_parser(interval_start, interval_end, lr, lr_map, default_lr, use_epoch_percent, num_steps_per_epoch)\n",
    "    lr_ret = default_lr\n",
    "#     print(use_epoch_percent)\n",
    "    for (start, end), lr in lr_map.items():\n",
    "        if (cur_step >= start) and (cur_step <= end):\n",
    "            if (lr < lr_ret):\n",
    "                lr_ret = lr\n",
    "    if lr_ret < stop_lr: lr_ret = stop_lr      \n",
    "    return lr_ret\n",
    "# _ = read_learning_rate(1, num_steps_per_epoch)\n",
    "# lr = []\n",
    "# num_epoches_to_show = 10\n",
    "# num_point = 100\n",
    "# for i in [i*num_epoches_to_show*num_steps_per_epoch/num_point for i in range(num_point)]:\n",
    "#     lr.append(read_learning_rate(i, num_steps_per_epoch))\n",
    "# plt.plot(lr)\n",
    "# plt.ylabel('learning rate')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabelMapping(object):\n",
    "    def __init__(self, catogory_file_path):\n",
    "        super(LabelMapping, self).__init__()\n",
    "        self._category_level_csv = catogory_file_path\n",
    "        self._category_map, self._category_level1_map, self._category_level2_map, self._len_level1, self._len_level2 = self.cvt_csv2tfrecord()\n",
    "        \n",
    "        assert (LEVEL1_CLASS == self._len_level1) and (LEVEL2_CLASS == self._len_level2), 'Other two levels are not mapped correctly.'\n",
    "        self._catogory_weight_map = self.cvt_catogory_weight()\n",
    "        self._mapping_strings = tf.constant( [ str(key) for key in self._category_map.keys() ] )\n",
    "        #print(list(self._category_map.keys())[0])\n",
    "        self._mapping_table = tf.contrib.lookup.index_table_from_tensor(mapping=self._mapping_strings, default_value=0) \n",
    "        \n",
    "        self._level1_table = tf.contrib.lookup.HashTable(tf.contrib.lookup.KeyValueTensorInitializer(list(self._category_level1_map.keys()), list(self._category_level1_map.values()), tf.int64, tf.int64), 0)\n",
    "        self._level2_table = tf.contrib.lookup.HashTable(tf.contrib.lookup.KeyValueTensorInitializer(list(self._category_level2_map.keys()), list(self._category_level2_map.values()), tf.int64, tf.int64), 0)\n",
    "        self._weight_table = tf.contrib.lookup.HashTable(tf.contrib.lookup.KeyValueTensorInitializer(list(self._catogory_weight_map.keys()), list(self._catogory_weight_map.values()), tf.int64, tf.float32), 0)\n",
    "\n",
    "    @property\n",
    "    def category_map(self):\n",
    "        return self._category_map\n",
    "    @property\n",
    "    def level1_table(self):\n",
    "        return self._level1_table\n",
    "    @property\n",
    "    def level2_table(self):\n",
    "        return self._level2_table\n",
    "    @property\n",
    "    def len_level1(self):\n",
    "        return self._len_level1\n",
    "    @property\n",
    "    def len_level2(self):\n",
    "        return self._len_level2\n",
    "    @property\n",
    "    def mapping_table(self):\n",
    "        return self._mapping_table\n",
    "    @property\n",
    "    def weight_table(self):\n",
    "        return self._weight_table\n",
    "    \n",
    "    def cvt_catogory_weight(self):\n",
    "        category_weight_map = dict()\n",
    "        csv = pd.read_csv(CATEGORY_WEIGHT_PATH).values\n",
    "        for row in csv:  \n",
    "            category_id, weight = row[0], row[2]\n",
    "            if weight > 1.5:\n",
    "                weight = 1.5\n",
    "            category_weight_map[int(category_id)] = 1.\n",
    "\n",
    "        return category_weight_map\n",
    "\n",
    "    def cvt_csv2tfrecord(self):\n",
    "        level1_map, level2_map = self.create_level_map()\n",
    "        count = 0\n",
    "        category_map = dict()\n",
    "        category_level1_map = dict()\n",
    "        category_level2_map = dict()\n",
    "        csv = pd.read_csv(self._category_level_csv).values\n",
    "        for row in csv:  \n",
    "            category_id, level1, level2 = row[0], row[1], row[2]\n",
    "            category_map[category_id] = count\n",
    "            category_level1_map[int(category_id)] = level1_map[level1]\n",
    "            category_level2_map[int(category_id)] = level2_map[level2]\n",
    "            count += 1\n",
    "\n",
    "        return category_map, category_level1_map, category_level2_map, len(level1_map), len(level2_map)\n",
    "\n",
    "    def create_level_map(self):\n",
    "        csv = pd.read_csv(self._category_level_csv).values\n",
    "        level_list = [list(), list()]\n",
    "        for row in csv: \n",
    "            for level in range(1,3):\n",
    "                if row[level] not in level_list[level-1]:\n",
    "                    level_list[level-1].append(row[level])\n",
    "        return dict(zip(level_list[0], range(len(level_list[0])))), dict(zip(level_list[1], range(len(level_list[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CdiscountDataset(Dataset):\n",
    "    def __init__(self, sess, data_path, file_begin_match, label_mapping, num_examples, num_classes, buffer_size, batch_size, is_training):\n",
    "        super(CdiscountDataset, self).__init__()\n",
    "        self._data_file_list = [ os.path.join(data_path, x) for x in os.listdir(data_path) if lambda x: os.path.isfile(x) and file_begin_match in x ]\n",
    "        self._num_examples = num_examples\n",
    "        self._tf_sess = sess\n",
    "        self._num_classes = num_classes\n",
    "        self._batch_size = batch_size\n",
    "        self._buffer_size = buffer_size\n",
    "        self._is_training = is_training\n",
    "        self._category_map = label_mapping.category_map\n",
    "        self._level1_table = label_mapping.level1_table\n",
    "        self._level2_table = label_mapping.level2_table\n",
    "        self._len_level1 = label_mapping.len_level1\n",
    "        self._len_level2 = label_mapping.len_level2\n",
    "        self._mapping_table = label_mapping.mapping_table\n",
    "        self._weight_table = label_mapping.weight_table\n",
    "    def __len__(self):\n",
    "        return self._num_examples\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         #print('read',idx)\n",
    "#         try:\n",
    "#             next_example, next_label, next_level0_label, next_level1_label = self._tf_sess.run(self.get_next())\n",
    "#             #print(next_example, next_label, next_level0_label, next_level1_label)\n",
    "#         except tf.errors.OutOfRangeError:\n",
    "#             pass\n",
    "#         return (torch.from_numpy(next_example), torch.from_numpy(next_label), torch.from_numpy(next_level0_label), torch.from_numpy(next_level1_label))\n",
    "    \n",
    "    @staticmethod\n",
    "    def image_normalized(image):\n",
    "        mean = [0.485, 0.456, 0.406 ]\n",
    "        std  = [0.229, 0.224, 0.225 ]\n",
    "\n",
    "        image = image.transpose((2,0,1))\n",
    "        image = image.astype(float)/255.\n",
    "        \n",
    "        image[0] = (image[0] - mean[0]) / std[0]\n",
    "        image[1] = (image[1] - mean[1]) / std[1]\n",
    "        image[2] = (image[2] - mean[2]) / std[2]\n",
    "\n",
    "        return image.astype(np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_center_crop(image, size=(160,160)):\n",
    "\n",
    "        height, width = image.shape[0:2]\n",
    "        w,h = size\n",
    "\n",
    "        x0 = (width  -w)//2\n",
    "        y0 = (height -h)//2\n",
    "        x1 = x0 + w\n",
    "        y1 = y0 + h\n",
    "        image = image[y0:y1, x0:x1]\n",
    "\n",
    "        return image\n",
    "    @staticmethod\n",
    "    def random_horizontal_flip(image, u=0.5):\n",
    "        if random.random() < u:\n",
    "            image = np.flip(image,1)  #np.fliplr(img) ##left-right\n",
    "        return image\n",
    "    @staticmethod\n",
    "    def random_crop(image, size=(160,160), u=0.5):\n",
    "\n",
    "        height,width=image.shape[0:2]\n",
    "        w,h = size\n",
    "\n",
    "        if random.random() < u:\n",
    "            x0 = np.random.choice(width - w)\n",
    "            y0 = np.random.choice(height - h)\n",
    "        else:\n",
    "            x0 = (width  -w)//2\n",
    "            y0 = (height -h)//2\n",
    "\n",
    "        x1 = x0 + w\n",
    "        y1 = y0 + h\n",
    "        image = image[y0:y1, x0:x1]\n",
    "\n",
    "        return image\n",
    "    @staticmethod\n",
    "    def random_resize(image, scale_x_limits=[0.9, 1.1], scale_y_limits=[0.9, 1.1], u=0.5):\n",
    "        if random.random() < u:\n",
    "            height,width=image.shape[0:2]\n",
    "\n",
    "            scale_x  = random.uniform(scale_x_limits[0],scale_x_limits[1])\n",
    "            if scale_y_limits is not None:\n",
    "                scale_y  = random.uniform(scale_y_limits[0],scale_y_limits[1])\n",
    "            else:\n",
    "                scale_y = scale_x\n",
    "\n",
    "            w = int(scale_x*width )\n",
    "            h = int(scale_y*height)\n",
    "\n",
    "            image = imresize(image,(h,w))\n",
    "        return image\n",
    "\n",
    "    @staticmethod\n",
    "    def _preprocess_by_pytorch_train(image):\n",
    "        image = CdiscountDataset.random_resize(image, scale_x_limits=[0.9,1.1], scale_y_limits=[0.9,1.1], u=0.5)\n",
    "        # flip  random ---------\n",
    "        image = CdiscountDataset.random_crop(image, size=(160,160), u=0.5) \n",
    "        image = CdiscountDataset.random_horizontal_flip(image, u=0.5)\n",
    "        return image.astype(np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def _preprocess_by_pytorch_test(image):\n",
    "        image  = CdiscountDataset.fix_center_crop(image, size=(160,160))  \n",
    "        return image.astype(np.float32)\n",
    "    @staticmethod\n",
    "    def _preprocess_normalize(image):\n",
    "        return CdiscountDataset.image_normalized(image)\n",
    "    @staticmethod\n",
    "    def _array_to_image_transform(image):\n",
    "        mean = [0.485, 0.456, 0.406 ]\n",
    "        std  = [0.229, 0.224, 0.225 ]\n",
    "        if random.random() < 0.00001:\n",
    "            image_to_save = image\n",
    "            image_to_save[0] = image_to_save[0]*std[0] + mean[0]\n",
    "            image_to_save[1] = image_to_save[1]*std[1] + mean[1]\n",
    "            image_to_save[2] = image_to_save[2]*std[2] + mean[2]\n",
    "\n",
    "            image_to_save = image_to_save*255\n",
    "            image_to_save = np.transpose(image_to_save, (1, 2, 0))\n",
    "            image_to_save = image_to_save.astype(np.uint8)\n",
    "            imsave('/media/rs/0E06CD1706CD0127/Kapok/kaggle/pytorch/cdiscount/Debug/{}.jpg'.format(int(random.random()*100000)), image_to_save)\n",
    "        return image\n",
    "    def _parse_function(self, example_proto):\n",
    "        features = {'img_raw': tf.FixedLenFeature([], tf.string, default_value=''),\n",
    "            'product_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n",
    "            'category_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64))}\n",
    "                \n",
    "        parsed_features = tf.parse_single_example(example_proto, features)\n",
    "        image = tf.image.decode_image(parsed_features[\"img_raw\"])\n",
    "        raw_label = parsed_features[\"category_id\"]\n",
    "        if self._is_training:\n",
    "            image = tf.py_func(CdiscountDataset._preprocess_by_pytorch_train, [image], tf.float32, stateful=True)\n",
    "            #tf.summary.image('final_train_image', tf.expand_dims(image, 0))\n",
    "        else:\n",
    "            image = tf.py_func(CdiscountDataset._preprocess_by_pytorch_test, [image], tf.float32, stateful=False)\n",
    "            #tf.summary.image('final_test_image', tf.expand_dims(image, 0))\n",
    "        image = tf.py_func(CdiscountDataset._preprocess_normalize, [image], tf.float32, stateful=False)\n",
    "        #image = tf.py_func(CdiscountDataset._array_to_image_transform, [image], tf.float32, stateful=False)\n",
    "        \n",
    "        return image, tf.one_hot(self._mapping_table.lookup(tf.as_string(raw_label)), self._num_classes, axis=-1, dtype=tf.int64),\\\n",
    "                tf.one_hot(self._level1_table.lookup(raw_label), self._len_level1, axis=-1, dtype=tf.int64),\\\n",
    "                tf.one_hot(self._level2_table.lookup(raw_label), self._len_level2, axis=-1, dtype=tf.int64), self._weight_table.lookup(raw_label)\n",
    "#         return image, self._mapping_table.lookup(tf.as_string(raw_label)),\\\n",
    "#                 self._level1_table.lookup(raw_label),\\\n",
    "#                 self._level2_table.lookup(raw_label)\n",
    "#     @staticmethod\n",
    "#     def _dddff(image):\n",
    "#         image = image.transpose((2,0,1))\n",
    "#         return image.astype(np.float32)\n",
    "#     def _parse_function_22(self, example_proto):\n",
    "#         features = {'img_raw': tf.FixedLenFeature([], tf.string, default_value=''),\n",
    "#             'product_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n",
    "#             'category_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64))}\n",
    "                \n",
    "#         parsed_features = tf.parse_single_example(example_proto, features)\n",
    "#         image = tf.image.decode_image(parsed_features[\"img_raw\"])\n",
    "#         raw_label = parsed_features[\"category_id\"]\n",
    "#         image = cdscount_preprocessing.preprocess_image(image, 160, 160, self._is_training)\n",
    "#         image = tf.py_func(CdiscountDataset._dddff, [image], tf.float32, stateful=False)\n",
    "#         return image, tf.one_hot(self._mapping_table.lookup(tf.as_string(raw_label)), self._num_classes, axis=-1, dtype=tf.int64),\\\n",
    "#                 tf.one_hot(self._level1_table.lookup(raw_label), self._len_level1, axis=-1, dtype=tf.int64),\\\n",
    "#                 tf.one_hot(self._level2_table.lookup(raw_label), self._len_level2, axis=-1, dtype=tf.int64)\n",
    "\n",
    "    def get_next(self):\n",
    "        #next_example, next_label, next_level0_label, next_level1_label \n",
    "        return self._next_iter\n",
    "    def create_dataset(self):\n",
    "        self._dataset = tf.data.TFRecordDataset(self._data_file_list, compression_type='ZLIB', buffer_size = 409600)\n",
    "        parse_func = lambda example : self._parse_function(example)\n",
    "        self._dataset = self._dataset.map(parse_func, num_parallel_calls=INPUT_THREADS)\n",
    "        self._dataset = self._dataset.prefetch(self._batch_size * 3)\n",
    "        self._dataset = self._dataset.shuffle(buffer_size=self._buffer_size)\n",
    "        self._dataset = self._dataset.batch(self._batch_size)\n",
    "        # we don't want to repeat until finish training, instead we stop each one epoch finished\n",
    "        #self._dataset = self._dataset.repeat(self._num_epochs)\n",
    "        self._iterator = self._dataset.make_initializable_iterator()\n",
    "        self._next_iter = self._iterator.get_next()\n",
    "#             Compute for 100 epochs.\n",
    "#             for _ in range(100):\n",
    "#               sess.run(iterator.initializer)\n",
    "#               while True:\n",
    "#                 try:\n",
    "#                   sess.run(next_element)\n",
    "#                 except tf.errors.OutOfRangeError:\n",
    "#                   break\n",
    "#         map(\n",
    "#             map_func,\n",
    "#             num_threads=None,\n",
    "#             output_buffer_size=None,\n",
    "#             num_parallel_calls=None\n",
    "#         )\n",
    "#         Maps map_func across this datset. (deprecated arguments)\n",
    "\n",
    "#         SOME ARGUMENTS ARE DEPRECATED. They will be removed in a future version. Instructions for updating: Replace num_threads=T with num_parallel_calls=T. Replace output_buffer_size=N with ds.prefetch(N) on the returned dataset.\n",
    "\n",
    "#         Args:\n",
    "\n",
    "#         map_func: A function mapping a nested structure of tensors (having shapes and types defined by self.output_shapes and self.output_types) to another nested structure of tensors.\n",
    "#         num_threads: (Optional.) Deprecated, use num_parallel_calls instead.\n",
    "#         output_buffer_size: (Optional.) A tf.int64 scalar tf.Tensor, representing the maximum number of processed elements that will be buffered.\n",
    "#         num_parallel_calls: (Optional.) A tf.int32 scalar tf.Tensor, representing the number elements to process in parallel. If not specified, elements will be processed sequentially.\n",
    "        return self._iterator.initializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python\n",
    "# # -*- coding: utf-8 -*-\n",
    "# # --------------------------------------------------------\n",
    "# # Licensed under The MIT License [see LICENSE for details]\n",
    "# # Written by Chao CHEN (chaochancs@gmail.com)\n",
    "# # Created On: 2017-08-11\n",
    "# # --------------------------------------------------------\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch.autograd import Variable\n",
    "\n",
    "   \n",
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, class_num, alpha=None, gamma=2, size_average=True):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         if alpha is None:\n",
    "#             self.alpha = Variable(torch.ones(class_num, 1))\n",
    "#         else:\n",
    "#             if isinstance(alpha, Variable):\n",
    "#                 self.alpha = alpha\n",
    "#             else:\n",
    "#                 self.alpha = Variable(alpha)\n",
    "#         self.gamma = gamma\n",
    "#         self.class_num = class_num\n",
    "#         self.size_average = size_average\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         N = inputs.size(0)\n",
    "#         print(N)\n",
    "#         C = inputs.size(1)\n",
    "#         P = F.softmax(inputs)\n",
    "\n",
    "#         class_mask = inputs.data.new(N, C).fill_(0)\n",
    "#         class_mask = Variable(class_mask)\n",
    "#         ids = targets.view(-1, 1)\n",
    "#         class_mask.scatter_(1, ids.data, 1.)\n",
    "#         #print(class_mask)\n",
    "        \n",
    "\n",
    "#         if inputs.is_cuda and not self.alpha.is_cuda:\n",
    "#             self.alpha = self.alpha.cuda()\n",
    "#         alpha = self.alpha[ids.data.view(-1)]\n",
    "        \n",
    "#         probs = (P*class_mask).sum(1).view(-1,1)\n",
    "\n",
    "#         log_p = probs.log()\n",
    "#         #print('probs size= {}'.format(probs.size()))\n",
    "#         #print(probs)\n",
    "\n",
    "#         batch_loss = -alpha*(torch.pow((1-probs), self.gamma))*log_p \n",
    "#         #print('-----bacth_loss------')\n",
    "#         #print(batch_loss)\n",
    "\n",
    "        \n",
    "#         if self.size_average:\n",
    "#             loss = batch_loss.mean()\n",
    "#         else:\n",
    "#             loss = batch_loss.sum()\n",
    "#         return loss\n",
    "\n",
    "    \n",
    "# class FocalLoss2(nn.Module):\n",
    "#     def __init__(self, gamma):\n",
    "#         super(FocalLoss2, self).__init__()\n",
    "#         self.softmax = nn.Softmax()\n",
    "#         self.gamma = gamma\n",
    "\n",
    "#     def forward(self, logits, targets, alphas):\n",
    "#         probs = self.softmax(logits)\n",
    "#         probs_mask = Variable(torch.zeros(probs.size()))\n",
    "#         probs_mask.scatter_(1, targets.view(-1, 1), 1.)\n",
    "#         probs_on = (probs_mask * probs).sum(1).view(-1)\n",
    "        \n",
    "#         if torch.cuda.is_available(): \n",
    "#             probs_on = probs_on.cuda()\n",
    "#             alphas = alphas.cuda()\n",
    "\n",
    "#         return (-alphas*(torch.pow((1.-probs_on), self.gamma))*probs_on.log()).mean()\n",
    "    \n",
    " \n",
    "# alpha = torch.Tensor([[1],[3],[4],[1.], [1]])\n",
    "# print(alpha)\n",
    "# FL = FocalLoss(5, gamma=2 ,alpha=alpha)\n",
    "# FL2= FocalLoss2(2)\n",
    "# CE = nn.CrossEntropyLoss()\n",
    "# N = 5\n",
    "# C = 5\n",
    "# inputs = torch.rand(N, C)\n",
    "# targets = torch.LongTensor([0,1,2,3,4])\n",
    "# inputs_fl = Variable(inputs.clone(), requires_grad=True)\n",
    "# targets_fl = Variable(targets.clone())\n",
    "\n",
    "# inputs_ce = Variable(inputs.clone(), requires_grad=True)\n",
    "# targets_ce = Variable(targets.clone())\n",
    "# print('----inputs----')\n",
    "# print(inputs)\n",
    "# print('---target-----')\n",
    "# print(targets)\n",
    "\n",
    "# fl_loss = FL(inputs_fl, targets_fl)\n",
    "# fl2_loss = FL2(inputs_fl, targets_fl, Variable(torch.Tensor([1,3,4.,1,1])))\n",
    "# ce_loss = CE(inputs_ce, targets_ce)\n",
    "# print('ce = {}, fl ={}, fl2 ={}'.format(ce_loss.data[0], fl_loss.data[0], fl2_loss.data[0]))\n",
    "# fl_loss.backward()\n",
    "# fl2_loss.backward()\n",
    "# ce_loss.backward()\n",
    "# print(inputs_fl.grad.data)\n",
    "# print(inputs_ce.grad.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, targets, alphas):\n",
    "        probs = self.softmax(logits)\n",
    "        probs_mask = Variable(torch.zeros(probs.size()))\n",
    "        if torch.cuda.is_available(): \n",
    "            probs_mask = probs_mask.cuda()\n",
    "            #alphas = alphas.cuda()\n",
    "        probs_mask.scatter_(1, targets.view(-1, 1), 1.)\n",
    "        probs_on = (probs_mask * probs).sum(1).view(-1)\n",
    "\n",
    "        return (-alphas*(torch.pow((1.-probs_on), self.gamma))*probs_on.log()).mean()\n",
    "    \n",
    "        \n",
    "torch_saver = Saver(LOG_DIR, 'Resnet', 5)\n",
    "\n",
    "smoother = CriterionSmooth()\n",
    "smoother.register_smooth('train_correct', -1.)\n",
    "smoother.register_smooth('train_total', -1.)\n",
    "smoother.register_smooth('val_correct', -1.)\n",
    "smoother.register_smooth('val_total', -1.)\n",
    "\n",
    "timer_holder = TimeRecorder()\n",
    "timer_holder.register_event('save_time', save_time_interval)\n",
    "timer_holder.register_event('log_time', log_step_interval, False)\n",
    "timer_holder.register_event('eval_log_time', log_step_interval, False)\n",
    "\n",
    "cdiscount_net = torch_resnet.resnet152(pretrained=False, num_classes=NUM_CLASS)\n",
    "#print(cdiscount_net)\n",
    "if torch.cuda.is_available():\n",
    "    cdiscount_net = cdiscount_net.cuda()\n",
    "\n",
    "# for param in cdiscount_net.conv1.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in cdiscount_net.bn1.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in cdiscount_net.layer1.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in cdiscount_net.layer2.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in cdiscount_net.layer3.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in cdiscount_net.layer4.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "#criterion = nn.NLLLoss()\n",
    "criterion = FocalLoss(5.)\n",
    "\n",
    "\n",
    "# optimizer = optim.SGD([\n",
    "#             {'params': net.layer0.parameters(), 'lr': 0.001},\n",
    "#             {'params': net.layer1.parameters(), 'lr': 0.001},\n",
    "#             {'params': net.layer2.parameters(), 'lr': 0.001},\n",
    "#             {'params': net.layer3.parameters(), 'lr': 0.001},\n",
    "#             {'params': net.layer4.parameters(), 'lr': 0.001},\n",
    "#             {'params': net.fc.parameters(),     'lr': 0.001},\n",
    "#         ], lr=0.001, momentum=0.9, weight_decay=0.0001,nesterov=True)\n",
    "\n",
    "#optimizer = optim.SGD(cdiscount_net.parameters(), lr=initial_learning_rate, momentum=momentum, weight_decay=0.0001)\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad, cdiscount_net.parameters()), lr=initial_learning_rate, momentum=momentum, weight_decay=0.0001)\n",
    "\n",
    "if False:\n",
    "    cdiscount_net = load_pretrain_file(cdiscount_net, PRETRAINED_MODEL_PATH, ['fc'])\n",
    "    others_state = None\n",
    "else:\n",
    "    others_state = torch_saver.restore_from_checkpoint(cdiscount_net, step=None)\n",
    "start_iter = 0\n",
    "start_epoch = 0\n",
    "global_step = 0\n",
    "others_state = None\n",
    "if others_state is not None:\n",
    "    start_iter  = others_state['iter']\n",
    "    start_epoch = others_state['epoch']\n",
    "    global_step  = others_state['global_step']\n",
    "    optimizer.load_state_dict(others_state['optimizer'])\n",
    "    \n",
    "if len(GPU_ID) > 1:\n",
    "    cdiscount_net = torch.nn.DataParallel(cdiscount_net) #use default\n",
    "    \n",
    "label_mapping = LabelMapping(CATEGORY_NAME_PATH)\n",
    "train_set = CdiscountDataset(tf_sess, TRAIN_PATH, 'output_file', label_mapping, TOTAL_EXAMPLES, NUM_CLASS, 20000, BATCH_SIZE, False)\n",
    "val_set = CdiscountDataset(tf_sess, VAL_PATH, 'output_file', label_mapping, VAL_EXAMPLES, NUM_CLASS, 2000, VAL_BATCH_SIZE, False)\n",
    "\n",
    "train_initializer = train_set.create_dataset()\n",
    "val_initializer = val_set.create_dataset()\n",
    "    \n",
    "tf_sess.run(tf.group(tf.global_variables_initializer(), tf.local_variables_initializer(), tf.tables_initializer()))\n",
    "#tf_sess.run(train_initializer)\n",
    "#print(tf_sess.run(train_set.get_next()))\n",
    "#tf_sess.run(train_set[0])\n",
    "\n",
    "# train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=False, num_workers = 4, drop_last=False)\n",
    "# val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers = 4, drop_last=False)\n",
    "\n",
    "# initialize tensorboard_logger\n",
    "summaries_dir = LOG_DIR + \"/tensorboard_logger_{}\".format(datetime.now().strftime('%Y-%m-%d_%H_%M_%S'))\n",
    "configure(summaries_dir, flush_secs=120)\n",
    "# summary_writer = tf.summary.FileWriter(summaries_dir, tf_sess.graph)\n",
    "\n",
    "# merged_summary = tf.summary.merge_all()\n",
    "# summary = tf_sess.run(merged_summary)\n",
    "# summary_writer.add_summary(summary, 0)\n",
    "        \n",
    "log.info(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "#target_onehot = torch.FloatTensor(batch_size, 4)\n",
    "timer_holder.reset_event('log_time', global_step)\n",
    "MDEBUG = False\n",
    "try:\n",
    "#if True:\n",
    "    for epoch in range(NUM_EPOCHES):\n",
    "        if epoch < start_epoch: continue\n",
    "        log.info('epoch {} of {} start...'.format(epoch, NUM_EPOCHES))\n",
    "        log.info('start from {} of epoch {}.'.format(start_iter, epoch))\n",
    "        cdiscount_net.train()\n",
    "        tf_sess.run(train_initializer)\n",
    "        for index in range(start_iter, len(train_set)):\n",
    "            try:\n",
    "                data = tf_sess.run(train_set.get_next())\n",
    "                #next_example, next_label, next_level0_label, next_level1_label = [torch.from_numpy(array) for array in data]\n",
    "                next_example, next_label, next_level0_label, next_level1_label, next_weight = torch.FloatTensor(data[0]), torch.LongTensor(data[1]), torch.LongTensor(data[2]), torch.LongTensor(data[3]), torch.FloatTensor(data[4])\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                example_in = Variable(next_example).cuda()\n",
    "                label_in = Variable(next_label).cuda()\n",
    "                level0_label_in = Variable(next_level0_label).cuda()\n",
    "                level1_label_in = Variable(next_level1_label).cuda()\n",
    "                next_weight = Variable(next_weight).cuda()\n",
    "            else:\n",
    "                example_in = Variable(next_example)\n",
    "                label_in = Variable(next_label)\n",
    "                level0_label_in = Variable(next_level0_label)\n",
    "                level1_label_in = Variable(next_level1_label)\n",
    "                next_weight = Variable(next_weight)\n",
    "\n",
    "            label_in = torch.topk(label_in, 1)[-1].view(-1)\n",
    "\n",
    "            target_logits = cdiscount_net(example_in)\n",
    "            target_softmax = nn.Softmax()(target_logits)\n",
    "            loss = criterion(target_logits, label_in, next_weight)\n",
    "            _, batch_top1 = torch.topk(target_softmax, 1)\n",
    "            batch_top1 = batch_top1.type(torch.LongTensor)\n",
    "            if torch.cuda.is_available():\n",
    "                batch_top1 = batch_top1.cuda()\n",
    "\n",
    "            num_correct = smoother.push_new_value('train_correct', (label_in == batch_top1.view(-1)).sum().data[0])\n",
    "            smoother.push_new_value('train_total', BATCH_SIZE)\n",
    "    #         target_log_softmax = cdiscount_net(msno_in, artist_in)\n",
    "    #         loss = criterion(target_log_softmax, label_in)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_acc  = num_correct/BATCH_SIZE\n",
    "            batch_loss = loss.data[0]\n",
    "\n",
    "            smooth_train_acc = smoother.smooth_value('train_correct')/smoother.smooth_value('train_total')\n",
    "\n",
    "            if global_step%1000 == 0:\n",
    "                try:\n",
    "                    cur_readed_lr = read_learning_rate(global_step, num_steps_per_train_epoch)\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        param_group['lr'] = cur_readed_lr\n",
    "                except:\n",
    "                    log.info('!!!Error Raised When Read Learning Rate!!!')\n",
    "            if timer_holder.check_for_me('log_time', global_step):\n",
    "                time_passed = timer_holder.get_ticks_passed()\n",
    "                log_value('train/batch_loss', batch_loss, global_step)\n",
    "                log_value('train/sec_per_step', time_passed/log_step_interval, global_step)\n",
    "                log_value('train/learning_rate', optimizer.param_groups[0]['lr'], global_step)\n",
    "                log_value('train/batch_acc', batch_acc, global_step)\n",
    "                log_value('train/smooth_train_acc', smooth_train_acc, global_step)\n",
    "                # to stdout\n",
    "                log.info('####### train logging #######')\n",
    "                step_for_this_epoch = (global_step - int(global_step//num_steps_per_train_epoch)*num_steps_per_train_epoch)\n",
    "                log.info('\\ttrain/current_step: {}({}/{}), cur_epoch: {}'.format(global_step, step_for_this_epoch, num_steps_per_train_epoch, epoch))\n",
    "                log.info('\\ttrain/current_lr: {}'.format(optimizer.param_groups[0]['lr']))\n",
    "                log.info('\\ttrain/sec_per_step: {:.3f}'.format(time_passed/log_step_interval))\n",
    "                log.info('\\ttrain/roughly {:6.3f} hours to go.'.format(  time_passed/log_step_interval*( (num_steps_per_train_epoch-step_for_this_epoch) > 0 and (num_steps_per_train_epoch-step_for_this_epoch)/3600. or 0.001 )  ))\n",
    "                log.info('\\ttrain/batch_loss: {:.3f}, batch_acc: {:.3f}, smooth_acc: {:.3f}'.format(batch_loss, batch_acc*100, smooth_train_acc*100))\n",
    "                if MDEBUG: break\n",
    "            if timer_holder.check_for_me('save_time'):\n",
    "                torch_saver.save_checkpoint(cdiscount_net.state_dict(), {'optimizer': optimizer.state_dict(),\n",
    "                                                        'iter': index, 'epoch': epoch, 'global_step': global_step }, global_step, is_best=False)\n",
    "\n",
    "        # reset start_iter\n",
    "        start_iter = 0\n",
    "        log.info('epoch {} finished.'.format(epoch)) \n",
    "        # save model after each epoch\n",
    "        torch_saver.save_checkpoint(cdiscount_net.state_dict(), {'optimizer': optimizer.state_dict(),\n",
    "                                                        'iter': 0, 'epoch': epoch + 1, 'global_step': global_step }, global_step, is_best=False)\n",
    "        timer_holder.reset_event('save_time')\n",
    "\n",
    "\n",
    "        # check on validation every epoches            \n",
    "        cdiscount_net.eval()\n",
    "        tf_sess.run(val_initializer)\n",
    "        timer_holder.reset_event('eval_log_time', 1)\n",
    "        #if False:\n",
    "        for index in range(len(val_set)):\n",
    "            try:\n",
    "                data = tf_sess.run(val_set.get_next())\n",
    "                #next_example, next_label, next_level0_label, next_level1_label = [torch.from_numpy(array) for array in data]\n",
    "                next_example, next_label, next_level0_label, next_level1_label, next_weight = torch.FloatTensor(data[0]), torch.LongTensor(data[1]), torch.LongTensor(data[2]), torch.LongTensor(data[3]), torch.FloatTensor(data[4])\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                example_in = Variable(next_example).cuda()\n",
    "                label_in = Variable(next_label).cuda()\n",
    "                level0_label_in = Variable(next_level0_label).cuda()\n",
    "                level1_label_in = Variable(next_level1_label).cuda()\n",
    "            else:\n",
    "                example_in = Variable(next_example)\n",
    "                label_in = Variable(next_label)\n",
    "                level0_label_in = Variable(next_level0_label)\n",
    "                level1_label_in = Variable(next_level1_label)\n",
    "\n",
    "            label_in = torch.topk(label_in, 1)[-1].view(-1)\n",
    "\n",
    "            _, batch_top1 = torch.topk(nn.Softmax()(cdiscount_net(example_in)), 1)\n",
    "            batch_top1 = batch_top1.type(torch.LongTensor)\n",
    "            if torch.cuda.is_available():\n",
    "                batch_top1 = batch_top1.cuda()\n",
    "            num_correct = smoother.push_new_value('val_correct', (label_in == batch_top1.view(-1)).sum().data[0])\n",
    "            smoother.push_new_value('val_total', VAL_BATCH_SIZE)        \n",
    "\n",
    "            batch_acc  = num_correct/VAL_BATCH_SIZE\n",
    "\n",
    "            smooth_validation_acc = smoother.smooth_value('val_correct')/smoother.smooth_value('val_total')\n",
    "\n",
    "            if timer_holder.check_for_me('eval_log_time', index):\n",
    "                time_passed = timer_holder.get_ticks_passed()\n",
    "                val_global_step = int(global_step//num_steps_per_train_epoch)*num_steps_per_val_epoch\n",
    "                log_value('validation/batch_acc', batch_acc, val_global_step+index)\n",
    "                log_value('validation/smooth_validation_acc', smooth_validation_acc, val_global_step+index)\n",
    "                log.info('####### validation logging #######')\n",
    "                log.info('\\tvalidation/current_step: {}/{}'.format(index, num_steps_per_val_epoch))\n",
    "                log.info('\\tvalidation/sec_per_step: {:.3f}'.format(time_passed/log_step_interval))\n",
    "                log.info('\\tvalidation/batch_acc: {:.3f}, smooth_acc: {:.3f}'.format(batch_acc*100, smooth_validation_acc*100))\n",
    "                if MDEBUG: break\n",
    "except BaseException as error:\n",
    "#if False:\n",
    "    # use tensorflow to fill the GPU no matter what reason caused\n",
    "    log.info(\"Error raised: {}.\\r\\nTraining did't finished.\".format(error))\n",
    "    tf_sess.close()\n",
    "    get_ipython().magic('env CUDA_VISIBLE_DEVICES = {}'.format(', '.join(map(str, GPU_ID))))\n",
    "    import tensorflow as tf\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1.)\n",
    "    tf_sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options))\n",
    "tf_sess.close()    \n",
    "log.info('Done: {}'.format(datetime.now().strftime('%Y-%m-%d_%H_%M_%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
