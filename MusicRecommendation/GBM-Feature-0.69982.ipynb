{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kapok/pyenv35/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/kapok/pyenv35/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# The line below sets the environment\n",
    "# variable CUDA_VISIBLE_DEVICES\n",
    "get_ipython().magic('env CUDA_VISIBLE_DEVICES =  ')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp      # will come in handy due to the size of the data\n",
    "import os.path\n",
    "import random\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import io\n",
    "from datetime import datetime\n",
    "import gc # garbage collector\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import logging\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "get_ipython().magic('matplotlib inline')\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "get_ipython().magic('load_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a pandas dataframe to disk as gunzip compressed csv\n",
    "- df.to_csv('dfsavename.csv.gz', compression='gzip')\n",
    "\n",
    "## Read from disk\n",
    "- df = pd.read_csv('dfsavename.csv.gz', compression='gzip')\n",
    "\n",
    "## Magic useful\n",
    "- %%timeit for the whole cell\n",
    "- %timeit for the specific line\n",
    "- %%latex to render the cell as a block of latex\n",
    "- %prun and %%prun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/media/rs/0E06CD1706CD0127/Kapok/WSDM/'\n",
    "HDF_FILENAME = DATASET_PATH + 'datas.h5'\n",
    "HDF_FILENAME_TEMPSAVE = DATASET_PATH + 'datas_temp.h5'\n",
    "SUBMISSION_FILENAME = DATASET_PATH + 'submission_{}.csv'\n",
    "VALIDATION_INDICE = DATASET_PATH + 'validation_indice.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_logging(logger_name, logger_file_name):\n",
    "    log = logging.getLogger(logger_name)\n",
    "    log.setLevel(logging.DEBUG)\n",
    "\n",
    "    # create formatter and add it to the handlers\n",
    "    print_formatter = logging.Formatter('%(message)s')\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(name)s_%(levelname)s: %(message)s')\n",
    "\n",
    "    # create file handler which logs even debug messages\n",
    "    fh = logging.FileHandler(logger_file_name, mode='w')\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    fh.setFormatter(file_formatter)\n",
    "    log.addHandler(fh)\n",
    "    # both output to console and file\n",
    "    consoleHandler = logging.StreamHandler()\n",
    "    consoleHandler.setFormatter(print_formatter)\n",
    "    log.addHandler(consoleHandler)\n",
    "    \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "here is an info message.\n"
     ]
    }
   ],
   "source": [
    "log = set_logging('MUSIC', DATASET_PATH + 'music_gbm.log')\n",
    "log.info('here is an info message.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_test = pd.HDFStore(HDF_FILENAME)\n",
    "test_id =  store_test['test_id']\n",
    "store_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# del train_use, validation_use, test\n",
    "gc.collect()\n",
    "float32_list = ['genre_ids', 'language', 'song_year', 'composer_score', 'lyricist_score', 'artist_name_score', 'popular_0', 'num_people_0', 'popular_1', 'popular_2', 'popular_3', 'popular_4', 'active_0', 'num_song_0', 'active_1', 'active_2', 'active_3', 'active_4', 'song_id_by_city', 'msno_by_country', 'msno_by_language', 'genre_ids_score', 'msno_is_in_topK_of_artist_name', 'msno_is_in_topK_of_genre_ids', 'artist_name_is_in_topK_of_genre_ids', 'artist_name_is_in_topK_of_msno', 'source_screen_name_count', 'source_type_count', 'source_system_tab_count', 'source_screen_name_avg_score', 'source_type_avg_score', 'source_system_tab_avg_score', 'composer_by_city_country_language', 'lyricist_by_city_country_language', 'artist_name_by_city_country_language', 'city_hot', 'language_hot']\n",
    "data_type_map =dict(zip(float32_list, [np.float32]*len(float32_list))) \n",
    "train_use = pd.read_csv(DATASET_PATH + 'temp_train_all_comp_encode_id.csv', compression='gzip', dtype = data_type_map)\n",
    "gc.collect()\n",
    "validation_use = pd.read_csv(DATASET_PATH + 'temp_validation_all_comp_encode_id.csv', compression='gzip', dtype = data_type_map)\n",
    "test = pd.read_csv(DATASET_PATH + 'temp_test_all_comp_encode_id.csv', compression='gzip', dtype = data_type_map)\n",
    "#test_id =  test['id']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def catogory_encode_transform(train_data, val_data, test_data, col):\n",
    "    gc.collect()\n",
    "    temp_data = pd.concat([train_data, val_data, test_data], axis=0, join=\"outer\")\n",
    "    gc.collect()\n",
    "    all_values = list(temp_data[col].unique())\n",
    "    gc.collect()\n",
    "    map_dict = dict(zip(all_values, [i for i in range(len(all_values))]))\n",
    "    gc.collect()\n",
    "#     train_data[col] = train_data[col].map(map_dict)\n",
    "#     val_data[col] = val_data[col].map(map_dict)\n",
    "#     test_data[col] = test_data[col].map(map_dict)\n",
    "    return train_data[col].map(map_dict), val_data[col].map(map_dict), test_data[col].map(map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# col = 'msno'\n",
    "# train_use[[col]], validation_use[[col]], test[[col]] = catogory_encode_transform(train_use[[col]], validation_use[[col]], test[[col]], col)\n",
    "# gc.collect()\n",
    "# col = 'song_id'\n",
    "# train_use[[col]], validation_use[[col]], test[[col]] = catogory_encode_transform(train_use[[col]], validation_use[[col]], test[[col]], col)\n",
    "# gc.collect()\n",
    "# col = 'name'\n",
    "# train_use[[col]], validation_use[[col]], test[[col]] = catogory_encode_transform(train_use[[col]], validation_use[[col]], test[[col]], col)\n",
    "# gc.collect()\n",
    "# col = 'composer'\n",
    "# train_use[[col]], validation_use[[col]], test[[col]] = catogory_encode_transform(train_use[[col]], validation_use[[col]], test[[col]], col)\n",
    "# gc.collect()\n",
    "# col = 'lyricist'\n",
    "# train_use[[col]], validation_use[[col]], test[[col]] = catogory_encode_transform(train_use[[col]], validation_use[[col]], test[[col]], col)\n",
    "# gc.collect()\n",
    "# col = 'artist_name'\n",
    "# train_use[[col]], validation_use[[col]], test[[col]] = catogory_encode_transform(train_use[[col]], validation_use[[col]], test[[col]], col)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in test.columns:\n",
    "    if col not in ['song_length', 'id']:\n",
    "        if test[col].dtype == np.float64:\n",
    "            train_use[col] = train_use[col].astype(np.float32)\n",
    "            validation_use[col] = validation_use[col].astype(np.float32)\n",
    "            test[col] = test[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for col in ['msno', 'song_id', 'name', 'composer', 'lyricist', 'artist_name']:\n",
    "#     train_use[col] = train_use[col].astype('category')\n",
    "#     validation_use[col] = validation_use[col].astype('category')\n",
    "#     test[col] = test[col].astype('category')\n",
    "# for col in ['msno', 'song_id', 'name', 'composer', 'lyricist', 'artist_name']:\n",
    "#     train_use[col] = train_use[col].astype('category')\n",
    "#     validation_use[col] = validation_use[col].astype('category')\n",
    "#     test[col] = test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in [col for col in test.columns if col != 'id' ]:\n",
    "    if train_use[col].dtype == object:\n",
    "        train_use[col] = train_use[col].astype('category')\n",
    "        validation_use[col] = validation_use[col].astype('category')\n",
    "        test[col] = test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in test.columns:\n",
    "    if col in ['registered_via', 'bd', 'city', 'registration_year', 'registration_month', 'registration_day', 'expiration_year', 'expiration_year', 'expiration_day']:\n",
    "        if test[col].dtype == np.int64:\n",
    "            train_use[col] = train_use[col].astype(np.int32)\n",
    "            validation_use[col] = validation_use[col].astype(np.int32)\n",
    "            test[col] = test[col].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# float32_list = list()\n",
    "# for col in test.columns:\n",
    "#     if col not in ['song_length', 'id']:\n",
    "#         if test[col].dtype == np.float32:\n",
    "#             float32_list.append(col)\n",
    "# print(float32_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_use.to_csv(DATASET_PATH + 'temp_train_all_comp_encode_id.csv', index = False, compression='gzip')\n",
    "# print('train saved.')\n",
    "# validation_use.to_csv(DATASET_PATH + 'temp_validation_all_comp_encode_id.csv', index = False, compression='gzip')\n",
    "# print('val saved.')\n",
    "# test.to_csv(DATASET_PATH + 'temp_test_all_comp_encode_id.csv', index = False, compression='gzip')\n",
    "# print('test saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_artistname_related(train_data, val_data, test_data):\n",
    "    gc.collect()\n",
    "    temp_data = pd.concat([train_data, val_data, test_data], axis=0, join=\"outer\")\n",
    "\n",
    "    temp_data['avg_active_per_msno'] = temp_data[['active_1', 'active_2', 'active_3', 'active_4']].mean(axis = 1).astype(np.float32)\n",
    "    \n",
    "    grouped = temp_data[['msno', 'artist_name']].groupby(['artist_name'])\n",
    "    \n",
    "    num_people_per_artist = grouped['msno'].agg(lambda x: x.nunique())\n",
    "    num_people_per_artist = num_people_per_artist.reset_index()\n",
    "    num_people_per_artist.columns = ['artist_name', 'num_people_per_artist']\n",
    "    #print(num_people_per_artist)\n",
    "    mean_people_active_per_artist = temp_data[['artist_name', 'avg_active_per_msno']].groupby(['artist_name'])['avg_active_per_msno'].agg('mean')\n",
    "    mean_people_active_per_artist = mean_people_active_per_artist.reset_index()\n",
    "    mean_people_active_per_artist.columns = ['artist_name', 'mean_people_active_per_artist']\n",
    "    #print(sum_people_active_per_artist)\n",
    "    train_data = train_data.merge(right = num_people_per_artist, how = 'left', on='artist_name')\n",
    "    val_data = val_data.merge(right = num_people_per_artist, how = 'left', on='artist_name')\n",
    "    test_data = test_data.merge(right = num_people_per_artist, how = 'left', on='artist_name')\n",
    "    \n",
    "    train_data = train_data.merge(right = mean_people_active_per_artist, how = 'left', on='artist_name')\n",
    "    val_data = val_data.merge(right = mean_people_active_per_artist, how = 'left', on='artist_name')\n",
    "    test_data = test_data.merge(right = mean_people_active_per_artist, how = 'left', on='artist_name')\n",
    "    \n",
    "    return train_data[['num_people_per_artist', 'mean_people_active_per_artist']], val_data[['num_people_per_artist', 'mean_people_active_per_artist']], test_data[['num_people_per_artist', 'mean_people_active_per_artist']]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "train_use[['num_people_per_artist', 'mean_people_active_per_artist']], \\\n",
    "validation_use[['num_people_per_artist', 'mean_people_active_per_artist']], \\\n",
    "test[['num_people_per_artist', 'mean_people_active_per_artist']] = new_artistname_related(train_use[['artist_name', 'msno', 'active_1', 'active_2', 'active_3', 'active_4']], \\\n",
    "                                                                                         validation_use[['artist_name', 'msno', 'active_1', 'active_2', 'active_3', 'active_4']], \\\n",
    "                                                                                         test[['artist_name', 'msno', 'active_1', 'active_2', 'active_3', 'active_4']])\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_wnd = [2018, 0, 2000, 2010, 2014, 2018]\n",
    "def cal_artist_popular(train_data, val_data, test_data):\n",
    "    all_data = pd.concat([train_data[['artist_name', 'song_year']], val_data[['artist_name', 'song_year']], test_data[['artist_name', 'song_year']]], axis=0, join=\"inner\")\n",
    "\n",
    "    for index, _ in enumerate(time_wnd[:-1]):\n",
    "        begin_time, end_time = time_wnd[index] < time_wnd[index+1] and (time_wnd[index], time_wnd[index+1]) or (time_wnd[index+1], time_wnd[index])\n",
    "        \n",
    "        select_data = all_data[all_data['song_year'].map(lambda x: x>=begin_time and x < end_time)]\n",
    "\n",
    "        grouped = select_data[['artist_name']].groupby(['artist_name'])\n",
    "\n",
    "        count_artist_name = grouped['artist_name'].agg(['count'])\n",
    "\n",
    "        popularity = pd.concat([np.log(count_artist_name+1)], axis=1, join=\"inner\")\n",
    "        popularity.columns = ['artist_popular_{}'.format(index)]\n",
    "        popularity = popularity.reset_index(drop=False)\n",
    "        train_data = train_data.merge(popularity, on='artist_name', how ='left')\n",
    "        test_data = test_data.merge(popularity, on='artist_name', how ='left')\n",
    "        val_data = val_data.merge(popularity, on='artist_name', how ='left')\n",
    "    return_list = list()\n",
    "    for index, _ in enumerate(time_wnd[:-1]):\n",
    "        return_list.append('artist_popular_{}'.format(index))\n",
    " \n",
    "    return train_data[return_list], val_data[return_list], test_data[return_list]\n",
    "\n",
    "return_list = ['artist_popular_0', 'artist_popular_1', 'artist_popular_2', 'artist_popular_3', 'artist_popular_4']\n",
    "input_list = ['artist_name', 'song_year']\n",
    "gc.collect()\n",
    "train_use[return_list], validation_use[return_list], test[return_list] = cal_artist_popular(train_use[input_list], validation_use[input_list], test[input_list])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_msno_related(train_data, val_data, test_data):\n",
    "    gc.collect()\n",
    "    temp_data = pd.concat([train_data, val_data, test_data], axis=0, join=\"outer\")\n",
    "\n",
    "    temp_data['avg_popular_per_artist'] = temp_data[['artist_popular_1', 'artist_popular_2', 'artist_popular_3', 'artist_popular_4']].mean(axis = 1).astype(np.float32)\n",
    "    \n",
    "    grouped = temp_data[['msno', 'artist_name']].groupby(['msno'])\n",
    "    \n",
    "    num_artist_per_people = grouped['artist_name'].agg(lambda x: x.nunique())\n",
    "    num_artist_per_people = num_artist_per_people.reset_index()\n",
    "    num_artist_per_people.columns = ['msno', 'num_artist_per_people']\n",
    "    #print(num_people_per_artist)\n",
    "    mean_artist_popular_per_people = temp_data[['msno', 'avg_popular_per_artist']].groupby(['msno'])['avg_popular_per_artist'].agg('mean')\n",
    "    mean_artist_popular_per_people = mean_artist_popular_per_people.reset_index()\n",
    "    mean_artist_popular_per_people.columns = ['msno', 'mean_artist_popular_per_people']\n",
    "    #print(sum_people_active_per_artist)\n",
    "    train_data = train_data.merge(right = num_artist_per_people, how = 'left', on='msno')\n",
    "    val_data = val_data.merge(right = num_artist_per_people, how = 'left', on='msno')\n",
    "    test_data = test_data.merge(right = num_artist_per_people, how = 'left', on='msno')\n",
    "    \n",
    "    train_data = train_data.merge(right = mean_artist_popular_per_people, how = 'left', on='msno')\n",
    "    val_data = val_data.merge(right = mean_artist_popular_per_people, how = 'left', on='msno')\n",
    "    test_data = test_data.merge(right = mean_artist_popular_per_people, how = 'left', on='msno')\n",
    "    \n",
    "    return train_data[['num_artist_per_people', 'mean_artist_popular_per_people']], val_data[['num_artist_per_people', 'mean_artist_popular_per_people']], test_data[['num_artist_per_people', 'mean_artist_popular_per_people']]\n",
    "gc.collect()\n",
    "train_use[['num_artist_per_people', 'mean_artist_popular_per_people']], \\\n",
    "validation_use[['num_artist_per_people', 'mean_artist_popular_per_people']], \\\n",
    "test[['num_artist_per_people', 'mean_artist_popular_per_people']] = new_msno_related(train_use[['artist_name', 'msno', 'artist_popular_1', 'artist_popular_2', 'artist_popular_3', 'artist_popular_4']], \\\n",
    "                                                                                         validation_use[['artist_name', 'msno', 'artist_popular_1', 'artist_popular_2', 'artist_popular_3', 'artist_popular_4']], \\\n",
    "                                                                                         test[['artist_name', 'msno','artist_popular_1', 'artist_popular_2', 'artist_popular_3', 'artist_popular_4']])\n",
    "\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in train_use.columns: print(col, ':', train_use[col].dtype, '; uinque values:', len(train_use[col].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in test.columns: print(col, ':', test[col].dtype, '; uinque values:', len(test[col].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in train_use.columns: print(col, ':', train_use[col].dtype, '; uinque values:', len(train_use[col].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "train_label = train_use['target']\n",
    "#train_use.drop(['target'], axis=1).to_csv(DATASET_PATH + 'train.csv', index=False)\n",
    "train_use = train_use.drop(['target'], axis=1)\n",
    "#del train_use\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(test_id), len(test), len(train_use), len(validation_use))\n",
    "#del train_use_org, test_org, validation_use_org\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = list()\n",
    "for col in test.columns:\n",
    "    if col not in ['id']:\n",
    "        feature_list.append(col)\n",
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catogory_list = list()\n",
    "for col in test.columns:\n",
    "    if col not in ['song_length', 'id']:\n",
    "        if test[col].dtype.name == 'category':\n",
    "            catogory_list.append(col)\n",
    "print(catogory_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#用temp_train_all_comp_2 然后sum_merge_and_drop 和 drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = np.zeros(shape=[len(test)])\n",
    "\n",
    "# features = ['msno', 'song_id', 'source_system_tab', 'source_screen_name', 'source_type', 'city', 'bd', 'gender', 'registered_via', 'song_length', 'genre_ids', 'language', 'name', 'country', 'song_year', 'registration_year', 'registration_month', 'registration_day', 'expiration_year', 'expiration_month', 'expiration_day', 'days', 'composer_score', 'composer', 'lyricist_score', 'lyricist', 'artist_name_score', 'artist_name', 'popular_0', 'num_people_0', 'popular_1', 'num_people_1', 'popular_2', 'num_people_2', 'popular_3', 'num_people_3', 'popular_4', 'num_people_4', 'active_0', 'num_song_0', 'active_1', 'num_song_1', 'active_2', 'num_song_2', 'active_3', 'num_song_3', 'active_4', 'num_song_4', 'composer_by_city', 'composer_by_country', 'composer_by_language', 'lyricist_by_city', 'lyricist_by_country', 'lyricist_by_language', 'artist_name_by_city', 'artist_name_by_country', 'artist_name_by_language', 'song_id_by_city', 'msno_by_country', 'msno_by_language', 'genre_ids_score', 'genre_ids_popular', 'msno_is_in_topK_of_artist_name', 'msno_is_in_topK_of_genre_ids', 'artist_name_is_in_topK_of_genre_ids', 'artist_name_is_in_topK_of_msno', 'source_screen_name_count', 'source_screen_name_mean_popular_0', 'source_screen_name_mean_popular_1', 'source_screen_name_mean_active_0', 'source_screen_name_mean_active_1', 'source_type_count', 'source_type_mean_popular_0', 'source_type_mean_popular_1', 'source_type_mean_active_0', 'source_type_mean_active_1', 'city_by_song_id', 'city_by_msno', 'city_by_genre_ids', 'city_by_artist_name', 'language_by_song_id', 'language_by_msno', 'language_by_genre_ids', 'language_by_artist_name']\n",
    "\n",
    "# train_use_array = train_use[features].values\n",
    "# labels = train_use['target'].values.astype('int').flatten()\n",
    "# #del train_use  # delete dataframe to release memory \n",
    "# gc.collect()\n",
    "# train_data = lgb.Dataset(train_use_array, labels, feature_name = features, categorical_feature = ['msno', 'song_id', 'source_system_tab', 'source_screen_name', 'source_type', 'gender', 'name', 'country', 'composer', 'lyricist', 'artist_name'])\n",
    "\n",
    "#train_data = lgb.Dataset(DATASET_PATH + 'train.csv', label=train_label)\n",
    "train_data = lgb.Dataset(train_use, label=train_label)\n",
    "gc.collect()\n",
    "val_data = lgb.Dataset(validation_use.drop(['target'],axis=1),label=validation_use['target'])\n",
    "del validation_use\n",
    "gc.collect()\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.1 ,\n",
    "    'verbose': 0,\n",
    "    'num_leaves': 128,#108\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_seed': 1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'feature_fraction_seed': 1,\n",
    "    'max_bin': 128,\n",
    "    'max_depth': 12,\n",
    "    #'num_rounds': 800,\n",
    "    'metric' : 'auc',\n",
    "    } \n",
    "\n",
    "bst = lgb.train(params, train_data, 800, valid_sets=[val_data])\n",
    "\n",
    "#del train_data, val_data\n",
    "gc.collect()\n",
    "\n",
    "predictions+=bst.predict(test.drop(['id'],axis=1))\n",
    "print('cur fold finished.')\n",
    "\n",
    "submission = pd.DataFrame({'id': test_id, 'target': predictions})\n",
    "submission.to_csv(SUBMISSION_FILENAME.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Plot feature importances...')\n",
    "ax = lgb.plot_importance(bst, max_num_features=30)\n",
    "plt.show()\n",
    "# last 400 0.696958 800 0.703245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "float32_list = list()\n",
    "for col in test.columns:\n",
    "    if col not in ['song_length', 'id']:\n",
    "        if test[col].dtype == np.float32:\n",
    "            float32_list.append(col)\n",
    "print(float32_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_merge_and_drop(train_data, val_data, test_data):\n",
    "#     merge_columns = [('source_screen_name_mean_popular_0', 'source_screen_name_mean_popular_1', 'source_screen_name_mean_active_0', 'source_screen_name_mean_active_1'),\\\n",
    "#                     ('source_type_mean_popular_0', 'source_type_mean_popular_1', 'source_type_mean_active_0', 'source_type_mean_active_1'),\\\n",
    "#                     ('source_system_tab_mean_popular_0', 'source_system_tab_mean_popular_1', 'source_system_tab_mean_active_0', 'source_system_tab_mean_active_1')]\n",
    "\n",
    "#     merge_columns_name = ['source_screen_name_avg_score', 'source_type_avg_score', 'source_system_tab_avg_score']\n",
    "    \n",
    "    merge_columns = [('source_screen_name_mean_popular_0', 'source_screen_name_mean_popular_1', 'source_screen_name_mean_active_0', 'source_screen_name_mean_active_1'),\\\n",
    "                    ('source_type_mean_popular_0', 'source_type_mean_popular_1', 'source_type_mean_active_0', 'source_type_mean_active_1'),\\\n",
    "                    ('source_system_tab_mean_popular_0', 'source_system_tab_mean_popular_1', 'source_system_tab_mean_active_0', 'source_system_tab_mean_active_1'),\\\n",
    "                    ('composer_by_city', 'composer_by_country', 'composer_by_language'),\\\n",
    "                    ('lyricist_by_city', 'lyricist_by_country', 'lyricist_by_language'),\\\n",
    "                    ('artist_name_by_city', 'artist_name_by_country', 'artist_name_by_language'),\\\n",
    "                    ('city_by_song_id', 'city_by_msno', 'city_by_genre_ids', 'city_by_artist_name'),\\\n",
    "                    ('language_by_song_id', 'language_by_msno', 'language_by_genre_ids', 'language_by_artist_name'),\\\n",
    "                    ('num_song_1', 'num_song_2', 'num_song_3', 'num_song_4'),\\\n",
    "                    ('num_people_1', 'num_people_2', 'num_people_3', 'num_people_4')]\n",
    "\n",
    "    merge_columns_name = ['source_screen_name_avg_score',\\\n",
    "                        'source_type_avg_score',\\\n",
    "                        'source_system_tab_avg_score',\\\n",
    "                        'composer_by_city_country_language',\\\n",
    "                        'lyricist_by_city_country_language',\\\n",
    "                        'artist_name_by_city_country_language',\\\n",
    "                        'city_hot',\\\n",
    "                        'language_hot'\\\n",
    "                        'num_song_sum',\\\n",
    "                        'num_people_sum']\n",
    "    \n",
    "    for i, cols in enumerate(merge_columns):\n",
    "        train_data[merge_columns_name[i]] = train_data[[col for col in cols]].mean(axis = 1).astype(np.float32)\n",
    "        train_data.drop([col for col in cols], axis = 1, inplace=True)\n",
    "\n",
    "        val_data[merge_columns_name[i]] = val_data[[col for col in cols]].mean(axis = 1).astype(np.float32)\n",
    "        val_data.drop([col for col in cols], axis = 1, inplace=True)\n",
    "\n",
    "        test_data[merge_columns_name[i]] = test_data[[col for col in cols]].mean(axis = 1).astype(np.float32)\n",
    "        test_data.drop([col for col in cols], axis = 1, inplace=True)\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "train_use, validation_use, test = sum_merge_and_drop(train_use, validation_use, test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.read_csv(DATASET_PATH+'submission_2017-11-06 22:25:54.csv')#'submission_2017-11-07 17:29:32.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def param_tune_with_val(params, tune_param, param_list, data_list, val_data, less_prefered = False):\n",
    "    #data_list = {'train':{'x':train_d,'y':train_y}, 'validation':{'x':valid_d,'y':valid_y}}\n",
    "    best_metric = (less_prefered and sys.float_info.max or -sys.float_info.max)\n",
    "    best_param = param_list[0]\n",
    "\n",
    "    for par_value in param_list:\n",
    "        params[tune_param] = par_value\n",
    "        # , num_boost_round=params['num_boost_round'], early_stopping_rounds = params['early_stopping_rounds']\n",
    "        model = lgb.train(params, data_list['train']['x'], valid_sets=[data_list['validation']['x']], \\\n",
    "                feature_name='auto', #categorical_feature=['source_system_tab', 'source_screen_name', 'source_type', 'city', 'gender',\\\n",
    "                                     #                       'bd', 'name', 'artist_name', 'composer', 'lyricist', 'msno', 'song_id', 'genre_ids',\\\n",
    "                                     #                       'country', 'language', 'registered_via'],、\n",
    "                        )\n",
    "       \n",
    "        val_predprob = model.predict(val_data)\n",
    "        auroc_score = metrics.roc_auc_score(data_list['validation']['y'], val_predprob)\n",
    "\n",
    "        if (not less_prefered and auroc_score > best_metric) or (less_prefered and auroc_score < best_metric):\n",
    "            best_metric = auroc_score\n",
    "            best_param = par_value\n",
    "    log.info('best param for {}: {}, metric: {}'.format(tune_param, best_param, best_metric))\n",
    "    return best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#{'top_k': 20, 'feature_fraction': 0.8, 'bagging_freq': 1, 'min_data_in_bin': 3, 'min_sum_hessian_in_leaf': 0.001, 'bagging_fraction': 0.9, 'max_depth': 12, 'num_leaves': 100, 'learning_rate': 0.01, 'objective': 'binary', 'lambda_l2': 0.01, 'feature_fraction_seed': 1024, 'min_data_in_leaf': 15, 'max_bin': 100, 'verbose': 0, 'bagging_seed': 6666, 'max_cat_to_onehot': 4, 'metric': 'auc', 'lambda_l1': 1e-05, 'num_threads': 16, 'boosting': 'gbdt', 'min_split_gain': 0.3}\n",
    "\n",
    "#{'bagging_seed': 6666, 'lambda_l1': 1e-05, 'lambda_l2': 0.01, 'metric': 'auc', 'bagging_freq': 1, 'min_sum_hessian_in_leaf': 0.001, 'feature_fraction': 0.8, 'feature_fraction_seed': 1024, 'num_leaves': 90, 'boosting': 'gbdt', 'verbose': 0, 'min_data_in_leaf': 15, 'top_k': 20, 'objective': 'binary', 'min_data_in_bin': 3, 'num_threads': 16, 'max_cat_to_onehot': 4, 'max_depth': 10, 'bagging_fraction': 0.9, 'learning_rate': 0.01, 'max_bin': 80, 'min_split_gain': 0.3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_for_best_params(train, validation, test):\n",
    "    \n",
    "    X_train = lgb.Dataset(np.array(train.drop(['target'], axis=1)), label=train['target'].values)\n",
    "    X_valid = lgb.Dataset(np.array(validation.drop(['target'], axis=1)), label=validation['target'].values)\n",
    "    \n",
    "    y_train = train['target'].values\n",
    "    y_valid = validation['target'].values\n",
    "\n",
    "    X_test = np.array(test.drop(['id'], axis=1))\n",
    "\n",
    "    data_list = {'train':{'x':X_train,'y':y_train}, 'validation':{'x':X_valid,'y':y_valid}}\n",
    "######## for value rather than catogory ################\n",
    "#   params_to_eval = OrderedDict(\n",
    "#         ( \n",
    "#         ('num_boost_round', range(120,150,10)),\n",
    "#         ('num_leaves', range(80,100,10)), # number of leaves in one tree\n",
    "#         ('max_depth', range(8,12,1)),\n",
    "#         ('min_data_in_leaf', 15),\n",
    "#         ('min_sum_hessian_in_leaf', [0.001]),# too high will lead to under-fitting\n",
    "#         ('min_split_gain',[0.3]),# the minimum loss reduction required to make a split\n",
    "#         ('bagging_fraction',[0.9]),# [i/10.0 for i in range(6,10)]\n",
    "#         ('feature_fraction',[0.8]),# typical: 0.5-1\n",
    "#         ('max_bin', range(70,90,10)),\n",
    "#         ('lambda_l2',[0.01]),\n",
    "#         ('lambda_l1',[1e-5]),\n",
    "#         ('learning_rate',[0.01]), # typical: 0.01-0.2\n",
    "#         )\n",
    "#       )\n",
    "     \n",
    "#     initial_params = {\n",
    "#         'objective': 'binary',\n",
    "#         'boosting': 'gbdt',\n",
    "#         'num_boost_round': 140,\n",
    "#         'learning_rate': 0.01 ,\n",
    "#         'verbose': 0,\n",
    "#         'num_leaves': 90,\n",
    "#         'num_threads':16,\n",
    "#         'max_depth': 9,\n",
    "#         'min_data_in_leaf': 15, #minimal number of data in one leaf. Can be used to deal with over-fitting\n",
    "#         'min_sum_hessian_in_leaf': 1e-3, #minimal sum hessian in one leaf. Like min_data_in_leaf, it can be used to deal with over-fitting\n",
    "#         'feature_fraction': 0.8, #colsample_bytree\n",
    "#         'feature_fraction_seed': 1024,\n",
    "#         'bagging_fraction': 0.9, #subsample\n",
    "#         'bagging_freq': 1, #frequency for bagging, 0 means disable bagging. k means will perform bagging at every k iteration\n",
    "#         'bagging_seed': 6666,\n",
    "#         'early_stopping_rounds':10,   \n",
    "#         'lambda_l1': 1e-5, #L1 regularization\n",
    "#         'lambda_l2': 0.01, #L2 regularization\n",
    "#         'max_cat_to_onehot': 4, #when number of categories of one feature smaller than or equal to max_cat_to_onehot, one-vs-other split algorithm will be used\n",
    "#         'top_k': 20, #set this to larger value for more accurate result, but it will slow down the training speed\n",
    "#         'min_split_gain': 0.3, #the minimal gain to perform split\n",
    "#         'max_bin': 70, #max number of bins that feature values will be bucketed in. Small number of bins may reduce training accuracy but may increase general power (deal with over-fitting)\n",
    "#         'min_data_in_bin': 3, #min number of data inside one bin, use this to avoid one-data-one-bin (may over-fitting)       \n",
    "#         'metric' : 'auc',\n",
    "#     } \n",
    "    params_to_eval = OrderedDict(\n",
    "        ( \n",
    "        ('num_boost_round', range(100,400,50)),\n",
    "        ('num_leaves', range(80,160,10)), # number of leaves in one tree\n",
    "        ('max_depth', range(8,18,1)),\n",
    "        ('min_data_in_leaf', range(10,18,2)),\n",
    "        ('min_sum_hessian_in_leaf', [0.001]),# too high will lead to under-fitting\n",
    "        ('min_split_gain',[0.3]),# the minimum loss reduction required to make a split\n",
    "        ('bagging_fraction',[0.9]),# [i/10.0 for i in range(6,10)]\n",
    "        ('feature_fraction',[0.8]),# typical: 0.5-1\n",
    "        ('max_bin', range(80,200,10)),\n",
    "        ('lambda_l2',[0.01]),\n",
    "        ('lambda_l1',[1e-5]),\n",
    "        ('learning_rate',[0.01]), # typical: 0.01-0.2\n",
    "        )\n",
    "      )\n",
    "     \n",
    "    initial_params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'gbdt',\n",
    "        'num_boost_round': 200,\n",
    "        'learning_rate': 0.1 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 120,\n",
    "        'num_threads':16,\n",
    "        'max_depth': 14,\n",
    "        'min_data_in_leaf': 16, #minimal number of data in one leaf. Can be used to deal with over-fitting\n",
    "        'min_sum_hessian_in_leaf': 1e-3, #minimal sum hessian in one leaf. Like min_data_in_leaf, it can be used to deal with over-fitting\n",
    "        'feature_fraction': 0.8, #colsample_bytree\n",
    "        'feature_fraction_seed': 1024,\n",
    "        'bagging_fraction': 0.9, #subsample\n",
    "        'bagging_freq': 1, #frequency for bagging, 0 means disable bagging. k means will perform bagging at every k iteration\n",
    "        'bagging_seed': 6666,\n",
    "        'early_stopping_rounds':10,   \n",
    "        'lambda_l1': 1e-5, #L1 regularization\n",
    "        'lambda_l2': 0.01, #L2 regularization\n",
    "        'max_cat_to_onehot': 4, #when number of categories of one feature smaller than or equal to max_cat_to_onehot, one-vs-other split algorithm will be used\n",
    "        'top_k': 20, #set this to larger value for more accurate result, but it will slow down the training speed\n",
    "        'min_split_gain': 0.3, #the minimal gain to perform split\n",
    "        'max_bin': 140, #max number of bins that feature values will be bucketed in. Small number of bins may reduce training accuracy but may increase general power (deal with over-fitting)\n",
    "        'min_data_in_bin': 3, #min number of data inside one bin, use this to avoid one-data-one-bin (may over-fitting)       \n",
    "        'metric' : 'auc',\n",
    "    } \n",
    "    # only param nin this list are tuned, total list are ['n_estimators', 'reg_alpha', 'reg_lambda', 'subsample', 'colsample_bytree', 'min_child_weight', 'max_depth', 'learning_rate', 'gamma']\n",
    "    #tuned_param_name = ['num_boost_round', 'num_leaves', 'max_depth', 'max_bin']\n",
    "    tuned_param_name = ['num_boost_round', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'min_sum_hessian_in_leaf',\\\n",
    "                        'min_split_gain', 'bagging_fraction', 'feature_fraction', 'max_bin', 'lambda_l2', 'lambda_l1', 'learning_rate']\n",
    "    for par_name, par_list in params_to_eval.items():\n",
    "        if par_name in tuned_param_name:\n",
    "            log.info('tunning {}...'.format(par_name))\n",
    "            if len(par_list) > 1:\n",
    "                initial_params[par_name] = param_tune_with_val(initial_params, par_name, par_list, data_list, np.array(validation.drop(['target'], axis=1)))\n",
    "            else:\n",
    "                initial_params[par_name] = par_list[0]\n",
    "    \n",
    "    return initial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "best_param = search_for_best_params(train_use, validation_use, test)\n",
    "log.info(best_param)\n",
    "time_elapsed = time.time() - start_time\n",
    "log.info('time used: {:.3f}sec'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'gbdt',\n",
    "        'num_boost_round': 140,\n",
    "        'learning_rate': 0.01 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 90,\n",
    "        'num_threads':16,\n",
    "        'max_depth': 9,\n",
    "        'min_data_in_leaf': 15, #minimal number of data in one leaf. Can be used to deal with over-fitting\n",
    "        'min_sum_hessian_in_leaf': 1e-3, #minimal sum hessian in one leaf. Like min_data_in_leaf, it can be used to deal with over-fitting\n",
    "        'feature_fraction': 0.8, #colsample_bytree\n",
    "        'feature_fraction_seed': 1024,\n",
    "        'bagging_fraction': 0.9, #subsample\n",
    "        'bagging_freq': 1, #frequency for bagging, 0 means disable bagging. k means will perform bagging at every k iteration\n",
    "        'bagging_seed': 6666,\n",
    "        'early_stopping_rounds':10,   \n",
    "        'lambda_l1': 1e-5, #L1 regularization\n",
    "        'lambda_l2': 0.01, #L2 regularization\n",
    "        'max_cat_to_onehot': 4, #when number of categories of one feature smaller than or equal to max_cat_to_onehot, one-vs-other split algorithm will be used\n",
    "        'top_k': 20, #set this to larger value for more accurate result, but it will slow down the training speed\n",
    "        'min_split_gain': 0.3, #the minimal gain to perform split\n",
    "        'max_bin': 70, #max number of bins that feature values will be bucketed in. Small number of bins may reduce training accuracy but may increase general power (deal with over-fitting)\n",
    "        'min_data_in_bin': 3, #min number of data inside one bin, use this to avoid one-data-one-bin (may over-fitting)       \n",
    "        'metric' : 'auc',\n",
    "    } \n",
    "X_train = lgb.Dataset(np.array(train_use.drop(['target'], axis=1)), label=train_use['target'].values)\n",
    "X_valid = lgb.Dataset(np.array(validation_use.drop(['target'], axis=1)), label=validation_use['target'].values)\n",
    "X_test = np.array(test.drop(['id'], axis=1))\n",
    "model = lgb.train(params, X_train, valid_sets=[X_valid])\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({'id': test_id, 'target': pred})\n",
    "submission.to_csv(SUBMISSION_FILENAME.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array(train_use.drop(['target'], axis=1))\n",
    "y_train = train_use['target'].values\n",
    "\n",
    "X_valid = np.array(validation_use.drop(['target'], axis=1))\n",
    "y_valid = validation_use['target'].values\n",
    "\n",
    "X_test = np.array(test.drop(['id'], axis=1))\n",
    "\n",
    "# d_train = xgb.DMatrix(X_train)\n",
    "# d_valid = xgb.DMatrix(X_valid) \n",
    "# d_test = xgb.DMatrix(X_test)\n",
    "\n",
    "data_list = {'train':{'x':X_train,'y':y_train}, 'validation':{'x':X_valid,'y':y_valid}}\n",
    "# Train model, evaluate and make predictions\n",
    "params={\n",
    "    'n_estimators':500,\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.75,\n",
    "    'gamma':0.1,\n",
    "    'subsample':0.8,\n",
    "    'colsample_bytree':0.3,\n",
    "    'min_child_weight':3,\n",
    "    'max_depth':16,\n",
    "    'seed':1024,\n",
    "    }\n",
    "\n",
    "param_tune_with_val(params, 'max_depth', [5,1,6], data_list, 'auc', 20)\n",
    "\n",
    "# model = xgb.train(params, d_train, 100, watchlist, early_stopping_rounds=20, \\\n",
    "#     maximize=True, verbose_eval=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array(train_use.drop(['target'], axis=1))\n",
    "y_train = train_use['target'].values\n",
    "\n",
    "X_valid = np.array(validation_use.drop(['target'], axis=1))\n",
    "y_valid = validation_use['target'].values\n",
    "\n",
    "X_test = np.array(test.drop(['id'], axis=1))\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "d_valid = xgb.DMatrix(X_valid, label=y_valid) \n",
    "d_test = xgb.DMatrix(X_test)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "# Train model, evaluate and make predictions\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eta'] = 0.75\n",
    "params['max_depth'] = 16\n",
    "params['silent'] = 1\n",
    "params['eval_metric'] = 'auc'\n",
    "\n",
    "model = xgb.train(params, d_train, 100, watchlist, early_stopping_rounds=20, \\\n",
    "    maximize=True, verbose_eval=5)\n",
    "\n",
    "#Predict training set:\n",
    "train_predictions = model.predict(X_train)\n",
    "train_predprob = model.predict_proba(X_train)[:,1]\n",
    "\n",
    "val_predictions = model.predict(X_valid)\n",
    "val_predprob = model.predict_proba(X_valid)[:,1]\n",
    "\n",
    "#Print model report:\n",
    "print(\"\\nModel Report\")\n",
    "print(\"Train Accuracy : %.4g\" % metrics.accuracy_score(y_train, train_predictions))\n",
    "print(\"Train AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, train_predprob))\n",
    "print(\"ValAccuracy : %.4g\" % metrics.accuracy_score(y_valid, val_predictions))\n",
    "print(\"Validation AUC Score (Train): %f\" % metrics.roc_auc_score(y_valid, val_predprob))\n",
    "\n",
    "feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')\n",
    "\n",
    "p_test = model.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27)\n",
    "modelfit(xgb1, train_use.drop(['target'],axis=1), train_use['target'], validation_use.drop(['target'],axis=1), validation_use['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['Disbursed'], eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Disbursed'].values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Disbursed'], dtrain_predprob))\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, train, label, validation, val_label, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(train.values, label=label.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds, metrics='auc', early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(train, label, eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    train_predictions = alg.predict(train)\n",
    "    train_predprob = alg.predict_proba(train)[:,1]\n",
    "    \n",
    "    val_predictions = alg.predict(validation)\n",
    "    val_predprob = alg.predict_proba(validation)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Train Accuracy : %.4g\" % metrics.accuracy_score(label.values, train_predictions))\n",
    "    print(\"Train AUC Score (Train): %f\" % metrics.roc_auc_score(label, train_predprob))\n",
    "    print(\"ValAccuracy : %.4g\" % metrics.accuracy_score(val_label.values, val_predictions))\n",
    "    print(\"Validation AUC Score (Train): %f\" % metrics.roc_auc_score(val_label, val_predprob))\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27)\n",
    "modelfit(xgb1, train_use.drop(['target'],axis=1), train_use['target'], validation_use.drop(['target'],axis=1), validation_use['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "predictions = np.zeros(shape=[len(test)])\n",
    "\n",
    "\n",
    "train_data = lgb.Dataset(train_use.drop(['target'],axis=1), label=train_use['target'])\n",
    "val_data = lgb.Dataset(validation_use.drop(['target'],axis=1), label=validation_use['target'])\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.1 ,\n",
    "    'verbose': 0,\n",
    "    'num_leaves': 108,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_seed': 1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'feature_fraction_seed': 1,\n",
    "    'max_bin': 128,\n",
    "    'max_depth': 10,\n",
    "    'num_rounds': 200,\n",
    "    'metric' : 'auc',\n",
    "    } \n",
    "\n",
    "bst = lgb.train(params, train_data, 100, valid_sets=[val_data])\n",
    "predictions=bst.predict(test.drop(['id'],axis=1))\n",
    "print('finished.')\n",
    "\n",
    "    \n",
    "predictions = predictions/3\n",
    "\n",
    "submission = pd.DataFrame({'id': test_id, 'target': predictions})\n",
    "submission.to_csv(SUBMISSION_FILENAME.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "predictions = np.zeros(shape=[len(test)])\n",
    "\n",
    "for train_indices,val_indices in kf.split(train) : \n",
    "    train_data = lgb.Dataset(train.drop(['target'],axis=1).loc[train_indices,:],label=train.loc[train_indices,'target'])\n",
    "    val_data = lgb.Dataset(train.drop(['target'],axis=1).loc[val_indices,:],label=train.loc[val_indices,'target'])\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'gbdt',\n",
    "        'learning_rate': 0.1 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 108,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 0.9,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_bin': 128,\n",
    "        'max_depth': 10,\n",
    "        'num_rounds': 200,\n",
    "        'metric' : 'auc',\n",
    "        } \n",
    "    \n",
    "    bst = lgb.train(params, train_data, 100, valid_sets=[val_data])\n",
    "    predictions+=bst.predict(test.drop(['id'],axis=1))\n",
    "    print('cur fold finished.')\n",
    "    del bst\n",
    "    \n",
    "predictions = predictions/3\n",
    "\n",
    "submission = pd.DataFrame({'id': test_id, 'target': predictions})\n",
    "submission.to_csv(SUBMISSION_FILENAME.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess songs data\n",
    "songs_genres = np.array(songs['genre_ids']\\\n",
    "    .apply(lambda x: [int(v) for v in str(x).split('|')]))\n",
    "genres_list = songs_genres.ravel().unique()\n",
    "print('Number of genres: ' + str(len(genres_list)))\n",
    "\n",
    "ohe_genres = np.zeros((len(songs_genres), len(genres_list)))\n",
    "for s_i, s_genres in enumerate(songs_genres):\n",
    "    for genre in s_genres:\n",
    "        g_i = genres_list.find(genre)\n",
    "        ohe_genres[s_i, g_i] = 1\n",
    "        \n",
    "for g_i, g in enumerate(genres_list):\n",
    "    songs['genre_' + str(g)] = ohe_genres[:, g_i]\n",
    "print(songs.head())\n",
    "songs = songs.drop(['genre_ids'], axis=1)\n",
    "\n",
    "song_cols = songs.columns\n",
    "\n",
    "# Preprocess dataset\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n",
    "\n",
    "cols = list(train.columns)\n",
    "cols.remove('target')\n",
    "\n",
    "for col in tqdm(cols):\n",
    "    if train[col].dtype == 'object':\n",
    "        train[col] = train[col].apply(str)\n",
    "        test[col] = test[col].apply(str)\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        train_vals = list(train[col].unique())\n",
    "        test_vals = list(test[col].unique())\n",
    "        le.fit(train_vals + test_vals)\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col] = le.transform(test[col])\n",
    "\n",
    "        print(col + ': ' + str(len(train_vals)) + ', ' + str(len(test_vals)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## import packages\n",
    "########################################\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Activation, Reshape\n",
    "from keras.layers.merge import concatenate, dot\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "\n",
    "########################################\n",
    "## load the data\n",
    "########################################\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "uid = train.msno\n",
    "sid = train.song_id\n",
    "target = train.target\n",
    "\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "id_test = test.id\n",
    "uid_test = test.msno\n",
    "sid_test = test.song_id\n",
    "\n",
    "########################################\n",
    "## encoding\n",
    "########################################\n",
    "\n",
    "usr_encoder = LabelEncoder()\n",
    "usr_encoder.fit(uid.append(uid_test))\n",
    "uid = usr_encoder.transform(uid)\n",
    "uid_test = usr_encoder.transform(uid_test)\n",
    "\n",
    "sid_encoder = LabelEncoder()\n",
    "sid_encoder.fit(sid.append(sid_test))\n",
    "sid = sid_encoder.transform(sid)\n",
    "sid_test = sid_encoder.transform(sid_test)\n",
    "\n",
    "u_cnt = int(max(uid.max(), uid_test.max()) + 1)\n",
    "s_cnt = int(max(sid.max(), sid_test.max()) + 1)\n",
    "\n",
    "########################################\n",
    "## train-validation split\n",
    "########################################\n",
    "\n",
    "perm = np.random.permutation(len(train))\n",
    "trn_cnt = int(len(train) * 0.85)\n",
    "uid_trn = uid[perm[:trn_cnt]]\n",
    "uid_val = uid[perm[trn_cnt:]]\n",
    "sid_trn = sid[perm[:trn_cnt]]\n",
    "sid_val = sid[perm[trn_cnt:]]\n",
    "target_trn = target[perm[:trn_cnt]]\n",
    "target_val = target[perm[trn_cnt:]]\n",
    "\n",
    "########################################\n",
    "## define the model\n",
    "########################################\n",
    "\n",
    "def get_model():\n",
    "    user_embeddings = Embedding(u_cnt,\n",
    "            64,\n",
    "            embeddings_initializer=RandomUniform(minval=-0.1, maxval=0.1),\n",
    "            embeddings_regularizer=l2(1e-4),\n",
    "            input_length=1,\n",
    "            trainable=True)\n",
    "    song_embeddings = Embedding(s_cnt,\n",
    "            64,\n",
    "            embeddings_initializer=RandomUniform(minval=-0.1, maxval=0.1),\n",
    "            embeddings_regularizer=l2(1e-4),\n",
    "            input_length=1,\n",
    "            trainable=True)\n",
    "\n",
    "    uid_input = Input(shape=(1,), dtype='int32')\n",
    "    embedded_usr = user_embeddings(uid_input)\n",
    "    embedded_usr = Reshape((64,))(embedded_usr)\n",
    "\n",
    "    sid_input = Input(shape=(1,), dtype='int32')\n",
    "    embedded_song = song_embeddings(sid_input)\n",
    "    embedded_song = Reshape((64,))(embedded_song)\n",
    "\n",
    "    preds = dot([embedded_usr, embedded_song], axes=1)\n",
    "    preds = concatenate([embedded_usr, embedded_song, preds])\n",
    "    \n",
    "    preds = Dense(128, activation='relu')(preds)\n",
    "    preds = Dropout(0.5)(preds)\n",
    "    \n",
    "    preds = Dense(1, activation='sigmoid')(preds)\n",
    "\n",
    "    model = Model(inputs=[uid_input, sid_input], outputs=preds)\n",
    "    \n",
    "    opt = RMSprop(lr=1e-3)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "\n",
    "    return model\n",
    "\n",
    "########################################\n",
    "## train the model\n",
    "########################################\n",
    "   \n",
    "model = get_model()\n",
    "early_stopping =EarlyStopping(monitor='val_acc', patience=5)\n",
    "model_path = 'bst_model.h5'\n",
    "model_checkpoint = ModelCheckpoint(model_path, save_best_only=True, \\\n",
    "        save_weights_only=True)\n",
    "\n",
    "hist = model.fit([uid_trn, sid_trn], target_trn, validation_data=([uid_val, sid_val], \\\n",
    "        target_val), epochs=100, batch_size=32768, shuffle=True, \\\n",
    "        callbacks=[early_stopping, model_checkpoint])\n",
    "model.load_weights(model_path)\n",
    "\n",
    "preds_val = model.predict([uid_val, sid_val], batch_size=32768)\n",
    "val_auc = roc_auc_score(target_val, preds_val)\n",
    "\n",
    "########################################\n",
    "## make the submission\n",
    "########################################\n",
    "\n",
    "preds_test = model.predict([uid_test, sid_test], batch_size=32768, verbose=1)\n",
    "sub = pd.DataFrame({'id': id_test, 'target': preds_test.ravel()})\n",
    "sub.to_csv('./sub_%.5f.csv'%(val_auc), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear algebra:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Graphics:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  \n",
    "# Frameworks:\n",
    "import lightgbm as lgb # LightGBM\n",
    "# Utils:\n",
    "import gc # garbage collector\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "IDIR = '../input/' # main path\n",
    "members = pd.read_csv(IDIR + 'members.csv')\n",
    "songs = pd.read_csv(IDIR + 'songs.csv')\n",
    "song_extra_info = pd.read_csv(IDIR + 'song_extra_info.csv')\n",
    "train = pd.read_csv(IDIR + 'train.csv')\n",
    "test = pd.read_csv(IDIR + 'test.csv')\n",
    "\n",
    "# Adding songs' info:\n",
    "train_aug1 = pd.merge(left=train, right=songs, on='song_id', how='left')\n",
    "test_aug1 = pd.merge(left=test, right=songs, on='song_id', how='left')\n",
    "# Adding extra info about songs:\n",
    "train_aug2 = pd.merge(left=train_aug1, right=song_extra_info, on='song_id', how='left')\n",
    "test_aug2 = pd.merge(left=test_aug1, right=song_extra_info, on='song_id', how='left')\n",
    "del train_aug1, test_aug1\n",
    "# Addind users' info:\n",
    "train_aug3 = pd.merge(left=train_aug2, right=members, on='msno', how='left')\n",
    "test_aug3 = pd.merge(left=test_aug2, right=members, on='msno', how='left')\n",
    "del train_aug2, test_aug2\n",
    "# Merging train and test data:\n",
    "train_aug3.drop(['song_id'], axis=1, inplace=True)\n",
    "train_aug3['set'] = 0\n",
    "test_aug3.drop(['song_id'], axis=1, inplace=True)\n",
    "test_aug3['set'] = 1\n",
    "test_aug3['target'] = -1\n",
    "all_aug = pd.concat([train_aug3, test_aug3], axis=0)\n",
    "del train_aug3, test_aug3\n",
    "gc.collect();\n",
    "\n",
    "\n",
    "\n",
    "# source_system_tab/source_screen_name/source_type/genre_ids/artist_name/composer/lyricist/name/isrc/gender 用'NA'填补并one-hot编码\n",
    "# genre_ids encoding:\n",
    "all_aug['genre_ids'] = all_aug.genre_ids.fillna('NA')\n",
    "all_aug['genre_ids'] = all_aug.genre_ids.astype(np.str)\n",
    "genre_ids_le = LabelEncoder()\n",
    "genre_ids_le.fit(all_aug.genre_ids)\n",
    "all_aug['genre_ids'] = genre_ids_le.transform(all_aug.genre_ids).astype(np.int16)\n",
    "\n",
    "# language encoding:\n",
    "all_aug['language'] = all_aug.language.fillna(-2)\n",
    "all_aug['language'] = all_aug.language.astype(np.int8)\n",
    "\n",
    "# city encoding:\n",
    "all_aug['city'] = all_aug.city.astype(np.int8)\n",
    "# bd encoding:\n",
    "all_aug['bd'] = all_aug.bd.astype(np.int16)\n",
    "\n",
    "# registered_via encoding:\n",
    "all_aug['registered_via'] = all_aug.registered_via.astype(np.int8)\n",
    "# registration_init_time encoding:\n",
    "all_aug['registration_init_time'] = all_aug.registration_init_time.astype(np.int32)\n",
    "# expiration_date encoding:\n",
    "all_aug['expiration_date'] = all_aug.expiration_date.astype(np.int32)\n",
    "# Info:\n",
    "all_aug.info(max_cols=0)\n",
    "all_aug.head(2)\n",
    "\n",
    "\n",
    "all_aug['exp_reg_time'] = all_aug.expiration_date - all_aug.registration_init_time\n",
    "\n",
    "\n",
    "\n",
    "gc.collect();\n",
    "d_train = lgb.Dataset(all_aug[all_aug.set == 0].drop(['target', 'msno', 'id', 'set'], axis=1), \n",
    "                      label=all_aug[all_aug.set == 0].pop('target'))\n",
    "ids_train = all_aug[all_aug.set == 0].pop('msno')\n",
    "\n",
    "lgb_params = {\n",
    "    'learning_rate': 1.0,\n",
    "    'max_depth': 15,\n",
    "    'num_leaves': 250, \n",
    "    'objective': 'binary',\n",
    "    'metric': {'auc'},\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 5,\n",
    "    'max_bin': 100}\n",
    "cv_result_lgb = lgb.cv(lgb_params, \n",
    "                       d_train, \n",
    "                       num_boost_round=5000, \n",
    "                       nfold=3, \n",
    "                       stratified=True, \n",
    "                       early_stopping_rounds=50, \n",
    "                       verbose_eval=100, \n",
    "                       show_stdv=True)\n",
    "\n",
    "num_boost_rounds_lgb = len(cv_result_lgb['auc-mean'])\n",
    "print('num_boost_rounds_lgb=' + str(num_boost_rounds_lgb))\n",
    "\n",
    "\n",
    "\n",
    "%%time\n",
    "ROUNDS = num_boost_rounds_lgb\n",
    "print('light GBM train :-)')\n",
    "bst = lgb.train(lgb_params, d_train, ROUNDS)\n",
    "# lgb.plot_importance(bst, figsize=(9,20))\n",
    "# del d_train\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "feature_imp = pd.Series(dict(zip(d_train.feature_name, \n",
    "                                 bst.feature_importance()))).sort_values(ascending=False)\n",
    "sns.barplot(x=feature_imp.values, y=feature_imp.index.values, orient='h', color='g')\n",
    "plt.subplot(1,2,2)\n",
    "train_scores = np.array(cv_result_lgb['auc-mean'])\n",
    "train_stds = np.array(cv_result_lgb['auc-stdv'])\n",
    "plt.plot(train_scores, color='green')\n",
    "plt.fill_between(range(len(cv_result_lgb['auc-mean'])), \n",
    "                 train_scores - train_stds, train_scores + train_stds, \n",
    "                 alpha=0.1, color='green')\n",
    "plt.title('LightGMB CV-results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
