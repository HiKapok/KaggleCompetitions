{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=\n"
     ]
    }
   ],
   "source": [
    "# The line below sets the environment\n",
    "# variable CUDA_VISIBLE_DEVICES\n",
    "get_ipython().magic('env CUDA_VISIBLE_DEVICES = ')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import io\n",
    "from datetime import datetime\n",
    "import gc # garbage collector\n",
    "import math\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import logging\n",
    "from tensorboard_logger import configure, log_value\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "get_ipython().magic('matplotlib inline')\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "get_ipython().magic('load_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a pandas dataframe to disk as gunzip compressed csv\n",
    "- df.to_csv('dfsavename.csv.gz', compression='gzip')\n",
    "\n",
    "## Read from disk\n",
    "- df = pd.read_csv('dfsavename.csv.gz', compression='gzip')\n",
    "\n",
    "## Magic useful\n",
    "- %%timeit for the whole cell\n",
    "- %timeit for the specific line\n",
    "- %%latex to render the cell as a block of latex\n",
    "- %prun and %%prun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/media/rs/0E06CD1706CD0127/Kapok/WSDM/'\n",
    "HDF_FILENAME = DATASET_PATH + 'datas.h5'\n",
    "HDF_FILENAME_TEMPSAVE = DATASET_PATH + 'datas_temp.h5'\n",
    "SUBMISSION_FILENAME = DATASET_PATH + 'submission_{}.csv'\n",
    "VALIDATION_INDICE = DATASET_PATH + 'validation_indice.csv'\n",
    "\n",
    "LOG_DIR = DATASET_PATH + 'music_logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_logging(logger_name, logger_file_name):\n",
    "    log = logging.getLogger(logger_name)\n",
    "    log.setLevel(logging.DEBUG)\n",
    "\n",
    "    # create formatter and add it to the handlers\n",
    "    print_formatter = logging.Formatter('%(message)s')\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(name)s_%(levelname)s: %(message)s')\n",
    "\n",
    "    # create file handler which logs even debug messages\n",
    "    fh = logging.FileHandler(logger_file_name, mode='w')\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    fh.setFormatter(file_formatter)\n",
    "    log.addHandler(fh)\n",
    "    # both output to console and file\n",
    "    consoleHandler = logging.StreamHandler()\n",
    "    consoleHandler.setFormatter(print_formatter)\n",
    "    log.addHandler(consoleHandler)\n",
    "    \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "here is an info message.\n"
     ]
    }
   ],
   "source": [
    "log = set_logging('MUSIC', DATASET_PATH + 'music_pytorch.log')\n",
    "log.info('here is an info message.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "train_use = pd.read_csv(DATASET_PATH + 'msno_artist_train.csv', compression='gzip')\n",
    "gc.collect()\n",
    "validation_use = pd.read_csv(DATASET_PATH + 'msno_artist_val.csv', compression='gzip')\n",
    "test = pd.read_csv(DATASET_PATH + 'msno_artist_test.csv', compression='gzip')\n",
    "#test_id =  test['id']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7277418 100000 2556790\n"
     ]
    }
   ],
   "source": [
    "print(len(train_use), len(validation_use), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- msno: 0-34402\n",
    "- artist_name: 0-45045\n",
    "- count:0, 1, 2-8, 9-496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model resotred from: /media/rs/0E06CD1706CD0127/Kapok/WSDM/music_logs/checkpoint_pytorch_state_2017-11-18_03_39_18.pth.\n",
      "####### test logging #######\n",
      "\ttest/current_step: 1000/39950\n",
      "\ttest/sec_per_step: 0.005\n",
      "####### test logging #######\n",
      "\ttest/current_step: 2000/39950\n",
      "\ttest/sec_per_step: 0.005\n",
      "####### test logging #######\n",
      "\ttest/current_step: 3000/39950\n",
      "\ttest/sec_per_step: 0.005\n",
      "####### test logging #######\n",
      "\ttest/current_step: 4000/39950\n",
      "\ttest/sec_per_step: 0.006\n",
      "####### test logging #######\n",
      "\ttest/current_step: 5000/39950\n",
      "\ttest/sec_per_step: 0.006\n",
      "####### test logging #######\n",
      "\ttest/current_step: 6000/39950\n",
      "\ttest/sec_per_step: 0.006\n",
      "####### test logging #######\n",
      "\ttest/current_step: 7000/39950\n",
      "\ttest/sec_per_step: 0.007\n",
      "####### test logging #######\n",
      "\ttest/current_step: 8000/39950\n",
      "\ttest/sec_per_step: 0.007\n",
      "####### test logging #######\n",
      "\ttest/current_step: 9000/39950\n",
      "\ttest/sec_per_step: 0.008\n",
      "####### test logging #######\n",
      "\ttest/current_step: 10000/39950\n",
      "\ttest/sec_per_step: 0.007\n",
      "####### test logging #######\n",
      "\ttest/current_step: 11000/39950\n",
      "\ttest/sec_per_step: 0.007\n",
      "####### test logging #######\n",
      "\ttest/current_step: 12000/39950\n",
      "\ttest/sec_per_step: 0.007\n",
      "####### test logging #######\n",
      "\ttest/current_step: 13000/39950\n",
      "\ttest/sec_per_step: 0.008\n",
      "####### test logging #######\n",
      "\ttest/current_step: 14000/39950\n",
      "\ttest/sec_per_step: 0.008\n",
      "####### test logging #######\n",
      "\ttest/current_step: 15000/39950\n",
      "\ttest/sec_per_step: 0.008\n",
      "####### test logging #######\n",
      "\ttest/current_step: 16000/39950\n",
      "\ttest/sec_per_step: 0.009\n",
      "####### test logging #######\n",
      "\ttest/current_step: 17000/39950\n",
      "\ttest/sec_per_step: 0.012\n",
      "####### test logging #######\n",
      "\ttest/current_step: 18000/39950\n",
      "\ttest/sec_per_step: 0.009\n",
      "####### test logging #######\n",
      "\ttest/current_step: 19000/39950\n",
      "\ttest/sec_per_step: 0.012\n",
      "####### test logging #######\n",
      "\ttest/current_step: 20000/39950\n",
      "\ttest/sec_per_step: 0.013\n",
      "####### test logging #######\n",
      "\ttest/current_step: 21000/39950\n",
      "\ttest/sec_per_step: 0.018\n",
      "####### test logging #######\n",
      "\ttest/current_step: 22000/39950\n",
      "\ttest/sec_per_step: 0.020\n",
      "####### test logging #######\n",
      "\ttest/current_step: 23000/39950\n",
      "\ttest/sec_per_step: 0.020\n",
      "####### test logging #######\n",
      "\ttest/current_step: 24000/39950\n",
      "\ttest/sec_per_step: 0.020\n",
      "####### test logging #######\n",
      "\ttest/current_step: 25000/39950\n",
      "\ttest/sec_per_step: 0.023\n",
      "####### test logging #######\n",
      "\ttest/current_step: 26000/39950\n",
      "\ttest/sec_per_step: 0.021\n",
      "####### test logging #######\n",
      "\ttest/current_step: 27000/39950\n",
      "\ttest/sec_per_step: 0.024\n",
      "####### test logging #######\n",
      "\ttest/current_step: 28000/39950\n",
      "\ttest/sec_per_step: 0.023\n",
      "####### test logging #######\n",
      "\ttest/current_step: 29000/39950\n",
      "\ttest/sec_per_step: 0.025\n",
      "####### test logging #######\n",
      "\ttest/current_step: 30000/39950\n",
      "\ttest/sec_per_step: 0.023\n",
      "####### test logging #######\n",
      "\ttest/current_step: 31000/39950\n",
      "\ttest/sec_per_step: 0.024\n",
      "####### test logging #######\n",
      "\ttest/current_step: 32000/39950\n",
      "\ttest/sec_per_step: 0.025\n",
      "####### test logging #######\n",
      "\ttest/current_step: 33000/39950\n",
      "\ttest/sec_per_step: 0.026\n",
      "####### test logging #######\n",
      "\ttest/current_step: 34000/39950\n",
      "\ttest/sec_per_step: 0.030\n",
      "####### test logging #######\n",
      "\ttest/current_step: 35000/39950\n",
      "\ttest/sec_per_step: 0.031\n",
      "####### test logging #######\n",
      "\ttest/current_step: 36000/39950\n",
      "\ttest/sec_per_step: 0.031\n",
      "####### test logging #######\n",
      "\ttest/current_step: 37000/39950\n",
      "\ttest/sec_per_step: 0.032\n",
      "####### test logging #######\n",
      "\ttest/current_step: 38000/39950\n",
      "\ttest/sec_per_step: 0.032\n",
      "####### test logging #######\n",
      "\ttest/current_step: 39000/39950\n",
      "\ttest/sec_per_step: 0.032\n",
      "Done: 2017-11-18_15_57_06\n"
     ]
    }
   ],
   "source": [
    "from tensorboard_logger import configure, log_value\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "\n",
    "embedding_dim = 64\n",
    "batch_size = 64\n",
    "\n",
    "msno_count = 34403\n",
    "artist_count = 45046\n",
    "\n",
    "log_step_interval = 1000\n",
    "\n",
    "test_examples_num = 2556790\n",
    "num_steps_per_val_epoch = int(test_examples_num / (batch_size)) + 1\n",
    "\n",
    "class MusicDataset(Dataset):\n",
    "    def __init__(self, data_input):\n",
    "        super(MusicDataset, self).__init__()\n",
    "        self._msno = data_input['msno'].values\n",
    "        self._artist = data_input['artist_name'].values\n",
    "        self._num_examples = len(data_input)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self._msno[idx], self._artist[idx])\n",
    "    \n",
    "\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NCF, self).__init__()\n",
    "        self._msno_embedding = nn.Embedding(msno_count, embedding_dim)\n",
    "        self._artist_embedding = nn.Embedding(artist_count, embedding_dim)\n",
    "    \n",
    "        self.layer1 = nn.Sequential(nn.Linear(2 * embedding_dim, 64), nn.ReLU(True))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(64, 32), nn.ReLU(True))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(32, 16), nn.ReLU(True))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        #self.layer4 = nn.Sequential(nn.Linear(16, 4), nn.ReLU(True))\n",
    "        self.layer4 = nn.Linear(16, 4)\n",
    "        #self.softmax = nn.LogSoftmax()\n",
    "        #self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, msno_id, artist_id):\n",
    "        msno_embedded = self._msno_embedding(msno_id)\n",
    "        artist_embedded = self._artist_embedding(artist_id)\n",
    "        input_x = torch.cat((msno_embedded, artist_embedded), 1)\n",
    "        input_x = self.layer1(input_x)\n",
    "        input_x = self.layer2(input_x)\n",
    "        input_x = self.layer3(input_x)\n",
    "        input_x = self.dropout(input_x)\n",
    "        input_x = self.layer4(input_x)\n",
    "        \n",
    "        return input_x#self.softmax(input_x)\n",
    "\n",
    "def restore_from_checkpoint(log_dir, model):\n",
    "    checkpoint_filename = None\n",
    "    if os.path.exists(os.path.join(log_dir, 'checkpoint')):\n",
    "        with open(os.path.join(log_dir, 'checkpoint'), 'r') as checkpoint_file:\n",
    "            for _, line in enumerate(checkpoint_file):\n",
    "                if line.strip() != '':\n",
    "                    checkpoint_filename = line.strip()\n",
    "                    break\n",
    "    if (not os.path.isdir(log_dir)) or (checkpoint_filename is None):\n",
    "        return None\n",
    "    \n",
    "    model.load_state_dict(torch.load(checkpoint_filename, map_location=lambda storage, loc: storage))    \n",
    "\n",
    "    log.info('model resotred from: {}.'.format(checkpoint_filename))\n",
    "    \n",
    "    return torch.load(checkpoint_filename.replace('state','others'))    \n",
    "\n",
    "NCF_encoder = NCF()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    NCF_encoder = NCF_encoder.cuda()\n",
    "\n",
    "restore_from_checkpoint(LOG_DIR, NCF_encoder)\n",
    "\n",
    "test_set = MusicDataset(test)\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers = 4, drop_last=False)\n",
    "    \n",
    "#target_onehot = torch.FloatTensor(batch_size, 4)\n",
    "\n",
    "# check on validation every epoches            \n",
    "NCF_encoder.eval()\n",
    "last_val_step = 1\n",
    "step_start_time = time.time()\n",
    "\n",
    "logits_df = None\n",
    "for index, data in enumerate(test_loader, 1):\n",
    "    msno, artist = data\n",
    "\n",
    "    msno_tensor = torch.LongTensor(msno)\n",
    "    artist_tensor = torch.LongTensor(artist)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        msno_in = Variable(msno_tensor).cuda()\n",
    "        artist_in = Variable(artist_tensor).cuda()\n",
    "    else:\n",
    "        msno_in = Variable(msno_tensor)\n",
    "        artist_in = Variable(artist_tensor)\n",
    "\n",
    "    logits = NCF_encoder(msno_in, artist_in)\n",
    "    if logits_df is None:\n",
    "        logits_df = pd.DataFrame(logits.data.numpy())\n",
    "        logits_df.columns = ['logits_0', 'logits_1', 'logits_2', 'logits_3'] \n",
    "    else:\n",
    "        temp_df = pd.DataFrame(logits.data.numpy())\n",
    "        temp_df.columns = ['logits_0', 'logits_1', 'logits_2', 'logits_3'] \n",
    "        logits_df = pd.concat([logits_df, temp_df], axis = 0, join=\"outer\")\n",
    "    #logits_df = logits_df.reset_index(drop=True)\n",
    "\n",
    "    #print(logits_df)\n",
    "    #print(logits.data.numpy())\n",
    "    #if index > 2:\n",
    "    #    break\n",
    "    if index % log_step_interval == 0:\n",
    "        log.info('####### test logging #######')\n",
    "        log.info('\\ttest/current_step: {}/{}'.format(index, num_steps_per_val_epoch))\n",
    "        log.info('\\ttest/sec_per_step: {:.3f}'.format((time.time()-step_start_time)/(index-last_val_step+1)))\n",
    "        last_val_step = index\n",
    "        step_start_time = time.time()\n",
    "logits_df = logits_df.reset_index(drop=True)\n",
    "logits_df.to_csv(DATASET_PATH + 'msno_artist_logits_test.csv', index = False, compression='gzip')\n",
    "log.info('Done: {}'.format(datetime.now().strftime('%Y-%m-%d_%H_%M_%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
