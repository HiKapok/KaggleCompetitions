{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kapok/pyenv35/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/kapok/pyenv35/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# The line below sets the environment\n",
    "# variable CUDA_VISIBLE_DEVICES\n",
    "get_ipython().magic('env CUDA_VISIBLE_DEVICES =  ')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp      # will come in handy due to the size of the data\n",
    "import os.path\n",
    "import random\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import io\n",
    "from datetime import datetime\n",
    "import gc # garbage collector\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import logging\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "get_ipython().magic('matplotlib inline')\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "get_ipython().magic('load_ext autoreload')\n",
    "get_ipython().magic('autoreload 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a pandas dataframe to disk as gunzip compressed csv\n",
    "- df.to_csv('dfsavename.csv.gz', compression='gzip')\n",
    "\n",
    "## Read from disk\n",
    "- df = pd.read_csv('dfsavename.csv.gz', compression='gzip')\n",
    "\n",
    "## Magic useful\n",
    "- %%timeit for the whole cell\n",
    "- %timeit for the specific line\n",
    "- %%latex to render the cell as a block of latex\n",
    "- %prun and %%prun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/media/rs/0E06CD1706CD0127/Kapok/WSDM/'\n",
    "HDF_FILENAME = DATASET_PATH + 'datas.h5'\n",
    "HDF_FILENAME_TEMPSAVE = DATASET_PATH + 'datas_temp.h5'\n",
    "SUBMISSION_FILENAME = DATASET_PATH + 'submission_{}.csv'\n",
    "VALIDATION_INDICE = DATASET_PATH + 'validation_indice.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_logging(logger_name, logger_file_name):\n",
    "    log = logging.getLogger(logger_name)\n",
    "    log.setLevel(logging.DEBUG)\n",
    "\n",
    "    # create formatter and add it to the handlers\n",
    "    print_formatter = logging.Formatter('%(message)s')\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(name)s_%(levelname)s: %(message)s')\n",
    "\n",
    "    # create file handler which logs even debug messages\n",
    "    fh = logging.FileHandler(logger_file_name, mode='w')\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    fh.setFormatter(file_formatter)\n",
    "    log.addHandler(fh)\n",
    "    # both output to console and file\n",
    "    consoleHandler = logging.StreamHandler()\n",
    "    consoleHandler.setFormatter(print_formatter)\n",
    "    log.addHandler(consoleHandler)\n",
    "    \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "here is an info message.\n"
     ]
    }
   ],
   "source": [
    "log = set_logging('MUSIC', DATASET_PATH + 'music_gbm.log')\n",
    "log.info('here is an info message.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAIN_FILE = DATASET_PATH + 'train.csv'\n",
    "# TEST_FILE = DATASET_PATH + 'test.csv'\n",
    "# MEMBER_FILE = DATASET_PATH + 'members.csv'\n",
    "# SONG_FILE = DATASET_PATH + 'fix_songs.csv'\n",
    "# SONG_EXTRA_FILE = DATASET_PATH + 'song_extra_info.csv'\n",
    "\n",
    "# train_data = pd.read_csv(TRAIN_FILE)\n",
    "# test_data = pd.read_csv(TEST_FILE)\n",
    "# member_data = pd.read_csv(MEMBER_FILE)\n",
    "# song_data = pd.read_csv(SONG_FILE)\n",
    "# song_extra_data = pd.read_csv(SONG_EXTRA_FILE)\n",
    "\n",
    "# songs_all = pd.merge(left = song_data, right = song_extra_data, how = 'left', on='song_id')\n",
    "# train_with_mem = pd.merge(left = train_data, right = member_data, how = 'left', on='msno')\n",
    "# train_all = pd.merge(left = train_with_mem, right = songs_all, how = 'left', on='song_id')\n",
    "# test_with_mem = pd.merge(left = test_data, right = member_data, how = 'left', on='msno')\n",
    "# test_all = pd.merge(left = test_with_mem, right = songs_all, how = 'left', on='song_id')\n",
    "# del train_with_mem, test_with_mem; gc.collect()\n",
    "\n",
    "# def convert_unicode_to_str(df):\n",
    "#     df.columns = df.columns.astype(str)\n",
    "#     types = df.apply(lambda x: pd.api.types.infer_dtype(df.values))\n",
    "#     #print(types)#mixed-integer\n",
    "#     for col in types[types == 'mixed-integer'].index:\n",
    "#         df[col] = df[col].astype(str)\n",
    "#     for col in types[types == 'mixed'].index:\n",
    "#         df[col] = df[col].astype(str)\n",
    "#     return df\n",
    "\n",
    "# store = pd.HDFStore(HDF_FILENAME)\n",
    "# store['train_data'] = convert_unicode_to_str(train_all)\n",
    "# store['test_data'] = convert_unicode_to_str(test_all)\n",
    "# store['song_data'] = convert_unicode_to_str(songs_all)\n",
    "# store['test_id'] = test_data.id\n",
    "# store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store_test = pd.HDFStore(HDF_FILENAME)\n",
    "# train = store_test['train_data'][0:100]\n",
    "# test = store_test['test_data'][0:100]\n",
    "# test_id =  store_test['test_id'][0:100]\n",
    "# store_test.close()\n",
    "store_test = pd.HDFStore(HDF_FILENAME)\n",
    "train = store_test['train_data']\n",
    "test = store_test['test_data']\n",
    "test_id =  store_test['test_id']\n",
    "store_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_country(input_data):\n",
    "    def get_country(isrc):\n",
    "        if isinstance(isrc, str) and isrc != 'nan':\n",
    "            return isrc[0:2]\n",
    "        else:\n",
    "            return np.nan\n",
    "    countries = train['isrc'].apply(get_country)\n",
    "    country_list = list(countries.value_counts().index)\n",
    "    country_map = dict(zip(country_list, country_list))\n",
    "    country_map['QM'] = 'QZ'\n",
    "    country_map['US'] = 'QZ'\n",
    "    return countries.map(country_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['country'] = split_country(train)\n",
    "test['country'] = split_country(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isrc_to_year(isrc):\n",
    "    if isinstance(isrc, str) and isrc != 'nan':\n",
    "        if int(isrc[5:7]) > 17:\n",
    "            return 1900 + int(isrc[5:7])\n",
    "        else:\n",
    "            return 2000 + int(isrc[5:7])\n",
    "    else:\n",
    "        return np.nan\n",
    "        \n",
    "train['song_year'] = train['isrc'].apply(isrc_to_year)\n",
    "test['song_year'] = test['isrc'].apply(isrc_to_year)\n",
    "train.drop(['isrc'], axis = 1, inplace = True)\n",
    "test.drop(['isrc'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_reg_date(input_data):\n",
    "    input_data['registration_year'] = input_data['registration_init_time'].apply(lambda x : int(str(x)[0:4]))\n",
    "    input_data['registration_year'] = pd.to_numeric(input_data['registration_year'], downcast='unsigned')\n",
    "\n",
    "    input_data['registration_month'] = input_data['registration_init_time'].apply(lambda x : int(str(x)[4:6]))\n",
    "    input_data['registration_month'] = pd.to_numeric(input_data['registration_month'], downcast='unsigned')\n",
    "\n",
    "    input_data['registration_day'] = input_data['registration_init_time'].apply(lambda x : int(str(x)[6:8]))\n",
    "    input_data['registration_day'] = pd.to_numeric(input_data['registration_day'], downcast='unsigned')\n",
    "\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_expir_date(input_data):\n",
    "    input_data['expiration_year'] = input_data['expiration_date'].apply(lambda x : int(str(x)[0:4]))\n",
    "    input_data['expiration_year'] = pd.to_numeric(input_data['expiration_year'], downcast='unsigned')\n",
    "\n",
    "    input_data['expiration_month'] = input_data['expiration_date'].apply(lambda x : int(str(x)[4:6]))\n",
    "    input_data['expiration_month'] = pd.to_numeric(input_data['expiration_month'], downcast='unsigned')\n",
    "\n",
    "    input_data['expiration_day'] = input_data['expiration_date'].apply(lambda x : int(str(x)[6:8]))\n",
    "    input_data['expiration_day'] = pd.to_numeric(input_data['expiration_day'], downcast='unsigned')\n",
    "    \n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_to_day(input_data):\n",
    "    # 转换注册时间\n",
    "    input_data['registration_init_time'] = pd.to_datetime(input_data['registration_init_time'],format=\"%Y%m%d\")\n",
    "    input_data['expiration_date'] = pd.to_datetime(input_data['expiration_date'],format=\"%Y%m%d\")\n",
    "    days = input_data.expiration_date - input_data.registration_init_time\n",
    "    days = [d.days for d in days]\n",
    "    input_data['days']=days\n",
    "    \n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = split_reg_date(train)\n",
    "test = split_reg_date(test)\n",
    "train = split_expir_date(train)\n",
    "test = split_expir_date(test)\n",
    "\n",
    "train = date_to_day(train)\n",
    "test = date_to_day(test)\n",
    "\n",
    "train.drop('registration_init_time',axis=1,inplace=True)\n",
    "train.drop('expiration_date',axis=1,inplace=True)\n",
    "test.drop('registration_init_time',axis=1,inplace=True)\n",
    "test.drop('expiration_date',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['song_length'] = pd.to_numeric(train['song_length'].replace('nan', '235415'), downcast='unsigned')\n",
    "test['song_length'] = pd.to_numeric(test['song_length'].replace('nan', '235415'), downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in train.columns: print(col, ':', train[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in [col for col in test.columns if col != 'id' ]:\n",
    "    if train[col].dtype == object:\n",
    "        train[col] = train[col].astype('category')\n",
    "        test[col] = test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # encode registered_via, the less number of occurrences are merged into the top item which has the max number of occurrences\n",
    "# registered_via_hist = pd.concat([train['registered_via'], test['registered_via']], axis = 0).value_counts()\n",
    "# registered_via_map = dict(zip(registered_via_hist.index, [int(s) for s in registered_via_hist.index.values]))\n",
    "# registered_via_map[registered_via_hist.index[-1]] = int(str(registered_via_hist.index.values[0]))\n",
    "# train['registered_via'] = train['registered_via'].map(registered_via_map)\n",
    "# test['registered_via'] = test['registered_via'].map(registered_via_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # encode language, fill nan with most occurrences item\n",
    "# language_hist = pd.concat([train['language'], test['language']], axis = 0).value_counts()\n",
    "# language_map = dict(zip(language_hist.index, [int(float(s)) for s in language_hist.index.values if s != 'nan']))\n",
    "# language_map['nan'] = int(float(str(language_hist.index.values[0])))\n",
    "# train['language'] = train['language'].map(language_map)\n",
    "# test['language'] = test['language'].map(language_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # encode country, fill nan with most occurrences item\n",
    "# country_hist = pd.concat([train['country'], test['country']], axis = 0).value_counts()\n",
    "# merge_per = 0.25\n",
    "# country_map = dict(zip(country_hist.index, list(range(len(country_hist)))))\n",
    "# for key in list(country_hist[-int(len(country_hist)*merge_per):].index):\n",
    "#     country_map[key] = int(len(country_hist)*(1-merge_per)) + 1\n",
    "# train['country'] = train['country'].map(country_map)\n",
    "# test['country'] = test['country'].map(country_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# msno : category ; uinque values: 30755\n",
    "# song_id : category ; uinque values: 359966\n",
    "# - source_system_tab : category ; uinque values: 10\n",
    "# - source_screen_name : category ; uinque values: 21\n",
    "# - source_type : category ; uinque values: 13\n",
    "# - target : object ; uinque values: 2\n",
    "# - city : category ; uinque values: 21\n",
    "# - bd : category ; uinque values: 92\n",
    "# - gender : category ; uinque values: 3\n",
    "# - registered_via : category ; uinque values: 5\n",
    "# song_length : uint32 ; uinque values: 60271\n",
    "# genre_ids : category ; uinque values: 573\n",
    "# artist_name : category ; uinque values: 40587\n",
    "# composer : category ; uinque values: 76072\n",
    "# lyricist : category ; uinque values: 33895\n",
    "# - language : category ; uinque values: 11\n",
    "# name : category ; uinque values: 234144\n",
    "# - country : category ; uinque values: 107\n",
    "# - song_year : float64 ; uinque values: 100\n",
    "# - registration_year : uint16 ; uinque values: 14\n",
    "# - registration_month : uint8 ; uinque values: 12\n",
    "# - registration_date : uint8 ; uinque values: 31\n",
    "# - expiration_year : uint16 ; uinque values: 18\n",
    "# - expiration_month : uint8 ; uinque values: 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_transform(input_train_data, input_test_data, columns_to_transform):\n",
    "    for col in columns_to_transform:\n",
    "        le = LabelEncoder()\n",
    "        train_values = list(input_train_data[col].unique())\n",
    "        test_values = list(input_test_data[col].unique())\n",
    "        le.fit(train_values + test_values)\n",
    "        input_train_data[col] = le.transform(input_train_data[col])\n",
    "        input_test_data[col] = le.transform(input_test_data[col])\n",
    "    return input_train_data, input_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train, test = one_hot_transform(train, test, ['source_system_tab', 'source_screen_name', 'source_type', 'city', 'gender', 'name'])#, 'artist_name', 'composer', 'lyricist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: wether song_id should be merged like this or not? 231475 reserved and 188364 merged\n",
    "def encode_with_merge(input_train, input_test, columns, merge_value):\n",
    "    for index, col in enumerate(columns):\n",
    "        values_hist = pd.concat([input_train[col], input_train[col]], axis = 0).value_counts()\n",
    "        reserve_rows = values_hist[values_hist!=merge_value[index]]\n",
    "        merge_rows = values_hist[values_hist==merge_value[index]]\n",
    "\n",
    "        reserve_dict = dict(zip(list(reserve_rows.index), list(range(len(reserve_rows)))))\n",
    "        merge_dict = dict(zip(list(merge_rows.index), [len(reserve_rows)+1]*len(merge_rows.index)))\n",
    "        \n",
    "        map_dict = {**reserve_dict, **merge_dict}\n",
    "        \n",
    "        language_map['nan'] = int(float(str(language_hist.index.values[0])))\n",
    "        input_train[col] = input_train[col].map(map_dict)\n",
    "        input_test[col] = input_test[col].map(map_dict)\n",
    "    return input_train, input_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train, test = encode_with_merge(train, test, ['msno', 'song_id', 'genre_ids'], [1, 1, 1])\n",
    "# print(train.head())\n",
    "# print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_org, test_org = train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train = train_org.copy(deep=True)\n",
    "#test = test_org.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_test = pd.HDFStore(VALIDATION_INDICE)\n",
    "validation_list = store_test['keep_index']['index'].values\n",
    "store_test.close()\n",
    "train['target'] = pd.to_numeric(train['target'], downcast='signed')\n",
    "#validation_use = train.iloc[validation_list].copy(deep=True).reset_index(drop=True)\n",
    "validation_use = train.iloc[list(range(7277417, 7377417))].copy(deep=True).reset_index(drop=True)\n",
    "#train_use = train.drop(validation_list)\n",
    "train_use = train.drop(list(range(7277417, 7377417)))\n",
    "# train['target'] = pd.to_numeric(train['target'], downcast='signed')\n",
    "# validation_use = train[50:].copy(deep=True).reset_index(drop=True)\n",
    "# train_use = train.drop(list(range(50,100)))\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for col in train_use.columns: print(col, ':', train_use[col].dtype, '; uinque values:', len(train_use[col].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_transform(train_data, validation_data, test_data):\n",
    "    train_data['song_length'] = np.log(pd.to_numeric(train_data['song_length'], downcast='float') + 1)\n",
    "    validation_data['song_length'] = np.log(pd.to_numeric(validation_data['song_length'], downcast='float') + 1)\n",
    "    test_data['song_length'] = np.log(pd.to_numeric(test_data['song_length'], downcast='float') + 1)\n",
    "    return train_data, validation_data, test_data\n",
    "train_use, validation_use, test = log_transform(train_use, validation_use, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_composer_hot_rate(train_data, val_data, test_data):\n",
    "    \n",
    "    temp_data = pd.concat([train_data[['composer']], val_data[['composer']], test_data[['composer']]], axis=0, join=\"outer\")\n",
    "    temp_data['composer'] = temp_data['composer'].apply(lambda x : x.replace(u'、','|'))\n",
    "\n",
    "    df_temp = temp_data['composer'].str.split('\\s{0,}[\\|\\\\\\\\/]\\s{0,}', 3, expand=True)\n",
    "    df_temp.columns = ['composer_{}'.format(x) for x in df_temp.columns]\n",
    "   \n",
    "    temp_data = pd.concat([df_temp['composer_0'], df_temp['composer_1'], df_temp['composer_2']], axis=0, join=\"outer\")\n",
    "    temp_data.reset_index(drop=True)\n",
    "\n",
    "    composer_hot = np.log(temp_data.value_counts()+1)\n",
    "    #composer_hot = temp_data.value_counts()\n",
    "    composer_hot['nan'] = 0.\n",
    "    composer_hot['nan'] = composer_hot.mean()\n",
    "    #print(composer_hot)\n",
    "    def encoder_each(input_data, hot_hist):\n",
    "        input_data = input_data.copy()\n",
    "        input_data['composer'] = input_data['composer'].apply(lambda x : x.replace(u'、','|'))\n",
    "        df_temp = input_data['composer'].str.split('\\s{0,}[\\|\\\\\\\\/]\\s{0,}', 3, expand=True)\n",
    "        df_temp.columns = ['composer_{}'.format(x) for x in df_temp.columns]\n",
    "        hot_hist = hot_hist.reset_index()\n",
    "        hot_hist.index.name='index'\n",
    "        \n",
    "        hot_hist.columns = ['composer_0', 'composer_0_score']\n",
    "        df_temp = df_temp.merge(right = hot_hist, how = 'left', on='composer_0')\n",
    "        hot_hist.columns = ['composer_1', 'composer_1_score']\n",
    "        df_temp = df_temp.merge(right = hot_hist, how = 'left', on='composer_1')\n",
    "        hot_hist.columns = ['composer_2', 'composer_2_score']\n",
    "        df_temp = df_temp.merge(right = hot_hist, how = 'left', on='composer_2')\n",
    "        df_temp['composer_score'] = df_temp[['composer_0_score','composer_1_score','composer_2_score']].max(axis=1)\n",
    "        #df_temp['composer_score'] = df_temp['composer_0_score']\n",
    "        \n",
    "        input_data['composer_score'] = df_temp['composer_score']\n",
    "        input_data.drop('composer', inplace=True, axis = 1)\n",
    "        #input_data = input_data.drop('composer', inplace=False, axis = 1)\n",
    "        input_data['composer'] = df_temp['composer_0']\n",
    "        return input_data\n",
    "    train_data = encoder_each(train_data, composer_hot)\n",
    "    val_data = encoder_each(val_data, composer_hot)\n",
    "    test_data = encoder_each(test_data, composer_hot)\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_use, validation_use, test = cal_composer_hot_rate(train_use, validation_use, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_lyricist_hot_rate(train_data, val_data, test_data):\n",
    "    temp_data = pd.concat([train_data[['lyricist']], val_data[['lyricist']], test_data[['lyricist']]], axis=0, join=\"outer\")\n",
    "    temp_data['lyricist'] = temp_data['lyricist'].apply(lambda x : x.replace(u'、','|'))\n",
    "\n",
    "    df_temp = temp_data['lyricist'].str.split('\\s{0,}[\\|\\\\\\\\/]\\s{0,}', 3, expand=True)\n",
    "    df_temp.columns = ['lyricist_{}'.format(x) for x in df_temp.columns]\n",
    "   \n",
    "    #temp_data = df_temp['lyricist_0']\n",
    "    temp_data = pd.concat([df_temp['lyricist_0'], df_temp['lyricist_1'], df_temp['lyricist_2']], axis=0, join=\"outer\")\n",
    "    temp_data.reset_index(drop=True)\n",
    "    lyricist_hot = np.log(temp_data.value_counts()+1)\n",
    "    #composer_hot = temp_data.value_counts()\n",
    "    lyricist_hot['nan'] = 0.\n",
    "    lyricist_hot['nan'] = lyricist_hot.mean()\n",
    "\n",
    "    #print(lyricist_hot)\n",
    "    def encoder_each(input_data, hot_hist):\n",
    "        input_data = input_data.copy()\n",
    "        input_data['lyricist'] = input_data['lyricist'].apply(lambda x : x.replace(u'、','|'))\n",
    "        df_temp = input_data['lyricist'].str.split('\\s{0,}[\\|\\\\\\\\/]\\s{0,}', 3, expand=True)\n",
    "        df_temp.columns = ['lyricist_{}'.format(x) for x in df_temp.columns]\n",
    "        hot_hist = hot_hist.reset_index()\n",
    "        hot_hist.index.name='index'\n",
    "        \n",
    "        hot_hist.columns = ['lyricist_0', 'lyricist_0_score']\n",
    "        df_temp = df_temp.merge(right = hot_hist, how = 'left', on='lyricist_0')\n",
    "        \n",
    "        df_temp['lyricist_score'] = df_temp['lyricist_0_score']\n",
    "        \n",
    "        input_data['lyricist_score'] = df_temp['lyricist_score']\n",
    "        input_data.drop('lyricist', inplace=True, axis = 1)\n",
    "        input_data['lyricist'] = df_temp['lyricist_0']\n",
    "        return input_data\n",
    "    train_data = encoder_each(train_data, lyricist_hot)\n",
    "    val_data = encoder_each(val_data, lyricist_hot)\n",
    "    test_data = encoder_each(test_data, lyricist_hot)\n",
    "    \n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_use, validation_use, test = cal_lyricist_hot_rate(train_use, validation_use, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_artist_hot_rate(train_data, val_data, test_data):\n",
    "    temp_data = pd.concat([train_data[['artist_name']], val_data[['artist_name']], test_data[['artist_name']]], axis=0, join=\"outer\")\n",
    "    temp_data['artist_name'] = temp_data['artist_name'].apply(lambda x : x.replace(u'、','|'))\n",
    "\n",
    "    df_temp = temp_data['artist_name'].str.split('\\s{0,}[\\|\\\\\\\\/]\\s{0,}', 3, expand=True)\n",
    "    df_temp.columns = ['artist_name_{}'.format(x) for x in df_temp.columns]\n",
    "   \n",
    "    #temp_data = df_temp['artist_name_0']\n",
    "    temp_data = pd.concat([df_temp['artist_name_0'], df_temp['artist_name_1'], df_temp['artist_name_2']], axis=0, join=\"outer\")\n",
    "    temp_data.reset_index(drop=True)\n",
    "    artist_hot = np.log(temp_data.value_counts()+1)\n",
    "    #composer_hot = temp_data.value_counts()\n",
    "    artist_hot['nan'] = 0.\n",
    "    artist_hot['nan'] = artist_hot.mean()\n",
    "    #print(artist_hot)\n",
    "\n",
    "    def encoder_each(input_data, hot_hist):\n",
    "        input_data = input_data.copy()\n",
    "        input_data['artist_name'] = input_data['artist_name'].apply(lambda x : x.replace(u'、','|'))\n",
    "        df_temp = input_data['artist_name'].str.split('\\s{0,}[\\|\\\\\\\\/]\\s{0,}', 3, expand=True)\n",
    "        df_temp.columns = ['artist_name_{}'.format(x) for x in df_temp.columns]\n",
    "        hot_hist = hot_hist.reset_index()\n",
    "        hot_hist.index.name='index'\n",
    "        \n",
    "        hot_hist.columns = ['artist_name_0', 'artist_name_0_score']\n",
    "        df_temp = df_temp.merge(right = hot_hist, how = 'left', on='artist_name_0')\n",
    "        \n",
    "        df_temp['artist_name_score'] = df_temp['artist_name_0_score']\n",
    "        \n",
    "        input_data['artist_name_score'] = df_temp['artist_name_score']\n",
    "        input_data.drop('artist_name', inplace=True, axis = 1)\n",
    "        input_data['artist_name'] = df_temp['artist_name_0']\n",
    "        return input_data\n",
    "    train_data = encoder_each(train_data, artist_hot)\n",
    "    val_data = encoder_each(val_data, artist_hot)\n",
    "    test_data = encoder_each(test_data, artist_hot)\n",
    "    \n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_use, validation_use, test = cal_artist_hot_rate(train_use, validation_use, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_use.head().columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# temp_data = pd.concat([train_use[['composer']], validation_use[['composer']], test[['composer']]], axis=0, join=\"inner\")\n",
    "\n",
    "# temp_data['composer'].apply(lambda x : len(x.replace(u'、','|').split('|'))).value_counts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = train_use.head(100000).copy(deep=True)\n",
    "# print(df['lyricist'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#time_wnd = [2018, 0]\n",
    "time_wnd = [2018, 0, 2000, 2010, 2014, 2018]\n",
    "def cal_song_listen_times(train_data, val_data, test_data):\n",
    "    all_data = pd.concat([train_data[['song_id', 'song_year', 'msno']], val_data[['song_id', 'song_year', 'msno']], test_data[['song_id', 'song_year', 'msno']]], axis=0, join=\"inner\")\n",
    "    #all_data['song_id'] = pd.to_numeric(all_data['song_id'], downcast='unsigned')\n",
    "    #all_data['msno'] = pd.to_numeric(all_data['msno'], downcast='unsigned')\n",
    "    for index, _ in enumerate(time_wnd[:-1]):\n",
    "        begin_time, end_time = time_wnd[index] < time_wnd[index+1] and (time_wnd[index], time_wnd[index+1]) or (time_wnd[index+1], time_wnd[index])\n",
    "#         begin_time = time_wnd[index]\n",
    "#         end_time = time_wnd[index+1]\n",
    "        select_data = all_data[all_data['song_year'].map(lambda x: x>=begin_time and x < end_time)]\n",
    "        \n",
    "        #select_data['target'] = pd.to_numeric(select_data['target'], downcast='signed')\n",
    "        \n",
    "        grouped = select_data[['song_id', 'msno']].groupby(['song_id'])\n",
    "\n",
    "        count_song = grouped.agg(['count'])\n",
    "        num_people_per_song = grouped.agg({\"msno\": lambda x: np.log(x.nunique()+1)})\n",
    "\n",
    "        popularity = pd.concat([np.log(count_song+1), num_people_per_song], axis=1, join=\"inner\")\n",
    "        popularity.columns = ['popular_{}'.format(index), 'num_people_{}'.format(index)]\n",
    "        popularity = popularity.reset_index(drop=False)\n",
    "        train_data = train_data.merge(popularity, on='song_id', how ='left')\n",
    "        test_data = test_data.merge(popularity, on='song_id', how ='left')\n",
    "        val_data = val_data.merge(popularity, on='song_id', how ='left')\n",
    "    return train_data, val_data, test_data\n",
    "def cal_song_listen_times_seperate(train_data, val_data, test_data):\n",
    "    def cal_each_of_them(input_data):\n",
    "        all_data = input_data[['song_id', 'song_year', 'msno']]\n",
    "        #all_data['song_id'] = pd.to_numeric(all_data['song_id'], downcast='unsigned')\n",
    "        #all_data['msno'] = pd.to_numeric(all_data['msno'], downcast='unsigned')\n",
    "        for index, _ in enumerate(time_wnd[:-1]):\n",
    "            begin_time, end_time = time_wnd[index] < time_wnd[index+1] and (time_wnd[index], time_wnd[index+1]) or (time_wnd[index+1], time_wnd[index])\n",
    "    #         begin_time = time_wnd[index]\n",
    "    #         end_time = time_wnd[index+1]\n",
    "            select_data = all_data[all_data['song_year'].map(lambda x: x>=begin_time and x < end_time)]\n",
    "        \n",
    "            grouped = select_data[['song_id', 'msno']].groupby(['song_id'])\n",
    "\n",
    "            count_song = grouped.agg(['count'])\n",
    "            num_people_per_song = grouped.agg({\"msno\": lambda x: np.log(x.nunique()+1)})\n",
    "\n",
    "            popularity = pd.concat([np.log(count_song+1), num_people_per_song], axis=1, join=\"inner\")\n",
    "            popularity.columns = ['popular_{}'.format(index), 'num_people_{}'.format(index)]\n",
    "            popularity = popularity.reset_index(drop=False)\n",
    "            all_data = input_data.merge(popularity, on='song_id', how ='left')\n",
    "        return all_data\n",
    "    return cal_each_of_them(train_data), cal_each_of_them(val_data), cal_each_of_them(test_data)\n",
    "\n",
    "# time_wnd = [2018, 0, 2000, 2010, 2014, 2018]\n",
    "# def cal_song_listen_times(train_data, test_data):\n",
    "#     test_data['song_id'] = pd.to_numeric(test_data['song_id'], downcast='unsigned')\n",
    "#     for index, _ in enumerate(time_wnd[:-1]):\n",
    "#         begin_time, end_time = time_wnd[index] < time_wnd[index+1] and (time_wnd[index], time_wnd[index+1]) or (time_wnd[index+1], time_wnd[index])\n",
    "# #         begin_time = time_wnd[index]\n",
    "# #         end_time = time_wnd[index+1]\n",
    "#         select_data = train_data[train_data['song_year'].map(lambda x: x>=begin_time and x < end_time)]\n",
    "        \n",
    "#         select_data['target'] = pd.to_numeric(select_data['target'], downcast='signed')\n",
    "        \n",
    "#         grouped = select_data[['song_id', 'target']].groupby(['song_id'])\n",
    "\n",
    "#         count_song = grouped.agg(['count'])\n",
    "#         mean_repeat_song = grouped['target'].mean()\n",
    "\n",
    "#         popularity = pd.concat([np.log(count_song+1), mean_repeat_song, np.log(count_song.multiply(mean_repeat_song, axis=0)+1)], axis=1, join=\"inner\")\n",
    "#         popularity.columns = ['popular_{}'.format(index), 'mean_repeat_{}'.format(index), 'replay_prob_{}'.format(index)]\n",
    "#         popularity = popularity.reset_index(drop=False)\n",
    "#         test_data = test_data.merge(popularity, on='song_id', how ='left')\n",
    "#         train_data = train_data.merge(popularity, on='song_id', how ='left')\n",
    "#     return train_data, test_data\n",
    "\n",
    "\n",
    "# time_wnd = [2018, 0, 2000, 2010, 2014, 2018]\n",
    "# def cal_song_listen_times(train_data):\n",
    "#     train_data['song_id'] = pd.to_numeric(train_data['song_id'], downcast='unsigned')\n",
    "#     for index, _ in enumerate(time_wnd[:-1]):\n",
    "#         begin_time, end_time = time_wnd[index] < time_wnd[index+1] and (time_wnd[index], time_wnd[index+1]) or (time_wnd[index+1], time_wnd[index])\n",
    "# #         begin_time = time_wnd[index]\n",
    "# #         end_time = time_wnd[index+1]\n",
    "#         select_data = train_data[train_data['song_year'].map(lambda x: x>=begin_time and x < end_time)]\n",
    "        \n",
    "#         select_data['target'] = pd.to_numeric(select_data['target'], downcast='signed')\n",
    "        \n",
    "#         grouped = select_data[['song_id', 'target']].groupby(['song_id'])\n",
    "\n",
    "#         count_song = grouped.agg(['count'])\n",
    "#         mean_repeat_song = grouped['target'].mean()\n",
    "\n",
    "#         popularity = pd.concat([np.log(count_song+1), mean_repeat_song, np.log(count_song.multiply(mean_repeat_song, axis=0)+1)], axis=1, join=\"inner\")\n",
    "#         popularity.columns = ['popular_{}'.format(index), 'mean_repeat_{}'.format(index), 'replay_prob_{}'.format(index)]\n",
    "#         popularity = popularity.reset_index(drop=False)\n",
    "#         train_data = train_data.merge(popularity, on='song_id', how ='left')\n",
    "#     return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_use, validation_use, test = cal_song_listen_times(train_use, validation_use, test)\n",
    "# train = cal_song_listen_times(train)\n",
    "# test = cal_song_listen_times(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for col in train_use.columns: print(col, ':', train_use[col].dtype, '; uinque values:', len(train_use[col].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#people_time_wnd = [2018, 0]\n",
    "people_time_wnd = [2018, 0, 2000, 2010, 2014, 2018]\n",
    "def get_people_active(train_data, val_data, test_data):\n",
    "    all_data = pd.concat([train_data[['song_id', 'song_year', 'msno']], val_data[['song_id', 'song_year', 'msno']], test_data[['song_id', 'song_year', 'msno']]], axis=0, join=\"inner\")\n",
    "    #all_data['song_id'] = pd.to_numeric(all_data['song_id'], downcast='unsigned')\n",
    "    #all_data['msno'] = pd.to_numeric(all_data['msno'], downcast='unsigned')\n",
    "    for index, _ in enumerate(people_time_wnd[:-1]):\n",
    "        begin_time, end_time = people_time_wnd[index] < people_time_wnd[index+1] and (people_time_wnd[index], people_time_wnd[index+1]) or (people_time_wnd[index+1], people_time_wnd[index])\n",
    "#         begin_time = time_wnd[index]\n",
    "#         end_time = time_wnd[index+1]\n",
    "        select_data = all_data[all_data['song_year'].map(lambda x: x>=begin_time and x < end_time)]\n",
    "        \n",
    "        #select_data['target'] = pd.to_numeric(select_data['target'], downcast='signed')\n",
    "        \n",
    "        grouped = select_data[['song_id', 'msno']].groupby(['msno'])\n",
    "\n",
    "        count_song = grouped.agg(['count'])\n",
    "        num_people_per_song = grouped.agg({\"song_id\": lambda x: np.log(x.nunique()+1)})\n",
    "\n",
    "        popularity = pd.concat([np.log(count_song+1), num_people_per_song], axis=1, join=\"inner\")\n",
    "        popularity.columns = ['active_{}'.format(index), 'num_song_{}'.format(index)]\n",
    "        popularity = popularity.reset_index(drop=False)\n",
    "        train_data = train_data.merge(popularity, on='msno', how ='left')\n",
    "        test_data = test_data.merge(popularity, on='msno', how ='left')\n",
    "        val_data = val_data.merge(popularity, on='msno', how ='left')\n",
    "    return train_data, val_data, test_data\n",
    "def get_people_active_seperate(train_data, val_data, test_data):\n",
    "    def cal_each_of_them(input_data):\n",
    "        all_data = input_data[['song_id', 'song_year', 'msno']]\n",
    "        #all_data['song_id'] = pd.to_numeric(all_data['song_id'], downcast='unsigned')\n",
    "        #all_data['msno'] = pd.to_numeric(all_data['msno'], downcast='unsigned')\n",
    "        for index, _ in enumerate(people_time_wnd[:-1]):\n",
    "            begin_time, end_time = people_time_wnd[index] < people_time_wnd[index+1] and (people_time_wnd[index], people_time_wnd[index+1]) or (people_time_wnd[index+1], people_time_wnd[index])\n",
    "    #         begin_time = time_wnd[index]\n",
    "    #         end_time = time_wnd[index+1]\n",
    "            select_data = all_data[all_data['song_year'].map(lambda x: x>=begin_time and x < end_time)]\n",
    "        \n",
    "            grouped = select_data[['song_id', 'msno']].groupby(['msno'])\n",
    "\n",
    "            count_song = grouped.agg(['count'])\n",
    "            num_people_per_song = grouped.agg({\"song_id\": lambda x: np.log(x.nunique()+1)})\n",
    "\n",
    "            popularity = pd.concat([np.log(count_song+1), num_people_per_song], axis=1, join=\"inner\")\n",
    "            popularity.columns = ['active_{}'.format(index), 'num_song_{}'.format(index)]\n",
    "            popularity = popularity.reset_index(drop=False)\n",
    "            all_data = input_data.merge(popularity, on='msno', how ='left')\n",
    "        return all_data\n",
    "    return cal_each_of_them(train_data), cal_each_of_them(val_data), cal_each_of_them(test_data)\n",
    "\n",
    "# test = test.reset_index(drop=False)\n",
    "# #test['msno'] = test['msno'].astype(int)   \n",
    "# train['target'] = pd.to_numeric(train['target'], downcast='signed')\n",
    "\n",
    "# grouped = train[['msno', 'target']].groupby(['msno'])\n",
    "\n",
    "# count_msno = grouped.agg(['count'])\n",
    "# mean_repeat_msno = grouped['target'].mean()\n",
    "\n",
    "# popularity = pd.concat([np.log(count_msno+1), mean_repeat_msno, np.log(count_msno.multiply(mean_repeat_msno, axis=0)+1)], axis=1, join=\"inner\")\n",
    "# popularity.columns = ['ms_popular', 'ms_mean_repeat', 'ms_replay_prob']\n",
    "# popularity = popularity.reset_index(drop=False)\n",
    "# test = test.merge(popularity, on='msno', how ='left')\n",
    "# train = train.merge(popularity, on='msno', how ='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_use, validation_use, test = get_people_active(train_use, validation_use, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_by_different_city_lang_country(train_data, val_data, test_data):\n",
    "    temp_msno_songid = pd.concat([train_data[['composer', 'lyricist', 'artist_name', 'city', 'country', 'language']], val_data[['composer', 'lyricist', 'artist_name', 'city', 'country', 'language']], test_data[['composer', 'lyricist', 'artist_name', 'city', 'country', 'language']]], axis=0, join=\"outer\")\n",
    "    \n",
    "    count_dict = dict()\n",
    "    \n",
    "    for col in ['composer', 'lyricist', 'artist_name']:\n",
    "        temp_df = None\n",
    "        for target in ['city', 'country', 'language']:\n",
    "            grouped = temp_msno_songid.groupby([col])\n",
    "            df = grouped.agg({target: lambda x: x.nunique()})\n",
    "            # !!!!!!remove log here!!!!!\n",
    "            df = np.log(df+1)\n",
    "#             print(df)\n",
    "#             break\n",
    "            if temp_df is not None:\n",
    "                temp_df = pd.concat([temp_df, df[target]], axis=1, join=\"inner\")\n",
    "            else:\n",
    "                temp_df = df\n",
    "        temp_df = temp_df.reset_index()\n",
    "        temp_df.index.name='index'\n",
    "        \n",
    "        temp_df.columns = [col, *[col + '_by_' + col_name for col_name in ['city', 'country', 'language']]]\n",
    "        #print(temp_df)    \n",
    "        train_data = train_data.merge(right = temp_df, how = 'left', on=col)\n",
    "        test_data = test_data.merge(right = temp_df, how = 'left', on=col)\n",
    "        val_data = val_data.merge(right = temp_df, how = 'left', on=col)\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_use_org, test_org, validation_use_org = measure_by_different_city_lang_country(train_use, test, validation_use)\n",
    "train_use, validation_use, test = measure_by_different_city_lang_country(train_use, validation_use, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_use, test, validation_use = train_use_org.copy(deep=True), test_org.copy(deep=True), validation_use_org.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def song_msno_by_different_city_lang_country(train_data, val_data, test_data):\n",
    "    temp_msno_songid = pd.concat([train_data[['song_id', 'msno', 'city', 'country', 'language']], val_data[['song_id', 'msno', 'city', 'country', 'language']], test_data[['song_id', 'msno', 'city', 'country', 'language']]], axis=0, join=\"outer\")\n",
    "    \n",
    "    count_dict = dict()\n",
    "    \n",
    "    for col in ['song_id', 'msno']:\n",
    "        temp_df = None\n",
    "        if col == 'song_id':\n",
    "            target_list = ['city']\n",
    "        else:\n",
    "            target_list = ['country', 'language']\n",
    "        for target in target_list:\n",
    "            grouped = temp_msno_songid.groupby([col])\n",
    "            df = grouped.agg({target: lambda x: x.nunique()})\n",
    "            # !!!!!!remove log here!!!!!\n",
    "            df = np.log(df+1)\n",
    "            #print(df)\n",
    "#             break\n",
    "            if temp_df is not None:\n",
    "                temp_df = pd.concat([temp_df, df[target]], axis=1, join=\"inner\")\n",
    "            else:\n",
    "                temp_df = df\n",
    "        temp_df = temp_df.reset_index()\n",
    "        temp_df.index.name='index'\n",
    "        \n",
    "        temp_df.columns = [col, *[col + '_by_' + col_name for col_name in target_list]]\n",
    "        #print(temp_df)    \n",
    "        train_data = train_data.merge(right = temp_df, how = 'left', on=col)\n",
    "        test_data = test_data.merge(right = temp_df, how = 'left', on=col)\n",
    "        val_data = val_data.merge(right = temp_df, how = 'left', on=col)\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_use, validation_use, test = song_msno_by_different_city_lang_country(train_use, validation_use, test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_use['genre_ids'].apply(lambda x : len(x.split('|'))).value_counts().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_genre_hot_rate(train_data, val_data, test_data):\n",
    "    # 0.685742\n",
    "#     temp_data = pd.concat([train_data[['genre_ids']], val_data[['genre_ids']], test_data[['genre_ids']]], axis=0, join=\"outer\")\n",
    "#     temp_data.reset_index(drop=True)\n",
    "\n",
    "#     genre_hot = np.log(temp_data['genre_ids'].value_counts()+1)\n",
    "#     #composer_hot = temp_data.value_counts()\n",
    "#     genre_hot['nan'] = 0.\n",
    "#     genre_hot['nan'] = genre_hot.mean()\n",
    "#     #print(composer_hot)\n",
    "#     genre_hot = genre_hot.reset_index()\n",
    "#     genre_hot.index.name='index'\n",
    "    \n",
    "#     genre_hot.columns = ['genre_ids', 'genre_ids_score']\n",
    "#     genre_hot['num_genre'] = genre_hot['genre_ids'].apply(lambda x : len(x.split('|')))\n",
    "#     train_data = train_data.merge(right = genre_hot, how = 'left', on='genre_ids')\n",
    "#     test_data = test_data.merge(right = genre_hot, how = 'left', on='genre_ids')\n",
    "#     val_data = val_data.merge(right = genre_hot, how = 'left', on='genre_ids')\n",
    "#     return train_data, test_data, val_data\n",
    "#     def encoder_each(input_data, hot_hist):\n",
    "#         input_data = input_data.copy()\n",
    "#         input_data['composer'] = input_data['genre_ids'].apply(lambda x : x.replace(u'、','|'))\n",
    "#         df_temp = input_data['composer'].str.split('\\s{0,}[\\|\\\\\\\\/]\\s{0,}', 3, expand=True)\n",
    "#         df_temp.columns = ['composer_{}'.format(x) for x in df_temp.columns]\n",
    "#         hot_hist = hot_hist.reset_index()\n",
    "#         hot_hist.index.name='index'\n",
    "        \n",
    "#         hot_hist.columns = ['composer_0', 'composer_0_score']\n",
    "#         df_temp = df_temp.merge(right = hot_hist, how = 'left', on='composer_0')\n",
    "#         hot_hist.columns = ['composer_1', 'composer_1_score']\n",
    "#         df_temp = df_temp.merge(right = hot_hist, how = 'left', on='composer_1')\n",
    "#         hot_hist.columns = ['composer_2', 'composer_2_score']\n",
    "#         df_temp = df_temp.merge(right = hot_hist, how = 'left', on='composer_2')\n",
    "#         df_temp['composer_score'] = df_temp[['composer_0_score','composer_1_score','composer_2_score']].max(axis=1)\n",
    "#         #df_temp['composer_score'] = df_temp['composer_0_score']\n",
    "        \n",
    "#         input_data['composer_score'] = df_temp['composer_score']\n",
    "#         input_data.drop('genre_id', inplace=True, axis = 1)\n",
    "#         #input_data = input_data.drop('composer', inplace=False, axis = 1)\n",
    "#         input_data['genre_id'] = df_temp['composer_0']\n",
    "#         return input_data\n",
    "#     train_data = encoder_each(train_data, genre_hot)\n",
    "#     val_data = encoder_each(val_data, genre_hot)\n",
    "#     val_data = encoder_each(test_data, genre_hot)\n",
    "    # 0.684454 with bd filled\n",
    "    temp_data = pd.concat([train_data[['genre_ids']], val_data[['genre_ids']], test_data[['genre_ids']]], axis=0, join=\"outer\")\n",
    "\n",
    "    df_temp = temp_data['genre_ids'].str.split('\\s{0,}\\|\\s{0,}', 3, expand=True)\n",
    "    \n",
    "    df_temp.columns = ['genre_ids_{}'.format(x) for x in df_temp.columns]\n",
    "   \n",
    "    temp_data = pd.concat([df_temp['genre_ids_0'], df_temp['genre_ids_1'], df_temp['genre_ids_2']], axis=0, join=\"outer\")\n",
    "    temp_data.reset_index(drop=True)\n",
    "\n",
    "    genre_hot = np.log(temp_data.value_counts()+1)\n",
    "    #composer_hot = temp_data.value_counts()\n",
    "    genre_hot['nan'] = 0.\n",
    "    genre_hot['nan'] = genre_hot.mean()\n",
    "    #print(composer_hot)\n",
    "    def encoder_each(input_data, hot_hist):\n",
    "        input_data = input_data.copy()\n",
    "        df_temp = input_data['genre_ids'].str.split('\\s{0,}\\|\\s{0,}', 3, expand=True)\n",
    "        df_temp.columns = ['genre_ids_{}'.format(x) for x in df_temp.columns]\n",
    "        hot_hist = hot_hist.reset_index()\n",
    "        hot_hist.index.name = 'index'\n",
    "        \n",
    "        hot_hist.columns = ['genre_ids_0', 'genre_ids_0_score']\n",
    "        df_temp = df_temp.merge(right = hot_hist, how = 'left', on='genre_ids_0')\n",
    "        hot_hist.columns = ['genre_ids_1', 'genre_ids_1_score']\n",
    "        df_temp = df_temp.merge(right = hot_hist, how = 'left', on='genre_ids_1')\n",
    "        hot_hist.columns = ['genre_ids_2', 'genre_ids_2_score']\n",
    "        df_temp = df_temp.merge(right = hot_hist, how = 'left', on='genre_ids_2')\n",
    "        df_temp['genre_ids_score'] = df_temp[['genre_ids_0_score','genre_ids_1_score','genre_ids_2_score']].max(axis=1)\n",
    "        idx_max = df_temp[['genre_ids_0_score','genre_ids_1_score','genre_ids_2_score']].idxmax(axis=1)\n",
    "        idx_max = idx_max.apply(lambda x : x.strip('_score'))\n",
    "        #print(idx_max)\n",
    "        #print(df_temp[['genre_ids_0','genre_ids_1','genre_ids_2']])\n",
    "        #print(df_temp[['genre_ids_0','genre_ids_1','genre_ids_2']].lookup(idx_max.index, idx_max.values))\n",
    "        \n",
    "        #return input_data\n",
    "        #df_temp['genre_ids_score'] = df_temp['genre_ids_0_score']\n",
    "        \n",
    "        input_data['genre_ids_score'] = df_temp['genre_ids_score']\n",
    "        #input_data.drop('genre_ids', inplace=True, axis = 1)\n",
    "        #input_data = input_data.drop('genre_ids', inplace=False, axis = 1)\n",
    "        input_data['genre_ids_popular'] = input_data['genre_ids'].apply(lambda x : len(x.split('|')))\n",
    "        input_data['genre_ids'] = df_temp[['genre_ids_0','genre_ids_1','genre_ids_2']].lookup(idx_max.index, idx_max.values)\n",
    "        return input_data\n",
    "    train_data = encoder_each(train_data, genre_hot)\n",
    "    val_data = encoder_each(val_data, genre_hot)\n",
    "    test_data = encoder_each(test_data, genre_hot)\n",
    "    \n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_use, validation_use, test = cal_genre_hot_rate(train_use, validation_use, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_use.to_csv(DATASET_PATH + 'temp_train.csv', index = False)\n",
    "# validation_use.to_csv(DATASET_PATH + 'temp_validation.csv', index = False)\n",
    "# test.to_csv(DATASET_PATH + 'temp_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_use = pd.read_csv(DATASET_PATH + 'temp_train.csv')\n",
    "# validation_use = pd.read_csv(DATASET_PATH + 'temp_validation.csv')\n",
    "# test = pd.read_csv(DATASET_PATH + 'temp_test.csv')\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_with_songid_msno(train_data, val_data, test_data):\n",
    "    for index, col in enumerate(['song_id', 'msno']):\n",
    "        temp_data = pd.concat([train_data[[col]], val_data[[col]], test_data[[col]]], axis=0, join=\"outer\")[col].value_counts()\n",
    "        encode_dict = dict(zip(list(temp_data.index), [str(i) for i in range(len(temp_data))]))\n",
    "        #reserve_dict = dict(zip([str(i) for i in range(len(temp_data))], list(temp_data.index)))\n",
    "        train_data[col] = train_data[col].map(encode_dict)\n",
    "        val_data[col] = val_data[col].map(encode_dict)\n",
    "        test_data[col] = test_data[col].map(encode_dict)\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_use, validation_use, test = encode_with_songid_msno(train_use, validation_use, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for col in [col for col in test.columns if col != 'id' ]:\n",
    "#     if test[col].dtype == object:\n",
    "#         train_use[col] = train_use[col].astype('category')\n",
    "#         validation_use[col] = validation_use[col].astype('category')\n",
    "#         test[col] = test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in test.columns:\n",
    "    if col not in ['song_length']:\n",
    "        if test[col].dtype == np.float64:\n",
    "            train_use[col] = train_use[col].astype(np.float32)\n",
    "            validation_use[col] = validation_use[col].astype(np.float32)\n",
    "            test[col] = test[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_use.to_csv(DATASET_PATH + 'temp_train_all_comp_1.csv', index = False, compression='gzip')\n",
    "print('train saved.')\n",
    "validation_use.to_csv(DATASET_PATH + 'temp_validation_all_comp_1.csv', index = False, compression='gzip')\n",
    "print('val saved.')\n",
    "test.to_csv(DATASET_PATH + 'temp_test_all_comp_1.csv', index = False, compression='gzip')\n",
    "print('test saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float32_list = list()\n",
    "for col in test.columns:\n",
    "    if col not in ['song_length', 'id']:\n",
    "        if test[col].dtype == np.float32:\n",
    "            float32_list.append(col)\n",
    "print(float32_list)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_use, validation_use, test\n",
    "gc.collect()\n",
    "float32_list = ['song_year', 'composer_score', 'lyricist_score', 'artist_name_score', 'popular_0', 'num_people_0', 'popular_1', 'num_people_1', 'popular_2', 'num_people_2', 'popular_3', 'num_people_3', 'popular_4', 'num_people_4', 'active_0', 'num_song_0', 'active_1', 'num_song_1', 'active_2', 'num_song_2', 'active_3', 'num_song_3', 'active_4', 'num_song_4', 'composer_by_city', 'composer_by_country', 'composer_by_language', 'lyricist_by_city', 'lyricist_by_country', 'lyricist_by_language', 'artist_name_by_city', 'artist_name_by_country', 'artist_name_by_language', 'song_id_by_city', 'msno_by_country', 'msno_by_language', 'genre_ids_score']\n",
    "data_type_map =dict(zip(float32_list, [np.float32]*len(float32_list))) \n",
    "train_use = pd.read_csv(DATASET_PATH + 'temp_train_all_comp_1.csv', compression='gzip', dtype = data_type_map)\n",
    "validation_use = pd.read_csv(DATASET_PATH + 'temp_validation_all_comp_1.csv', compression='gzip', dtype = data_type_map)\n",
    "test = pd.read_csv(DATASET_PATH + 'temp_test_all_comp_1.csv', compression='gzip', dtype = data_type_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_data_of_birth(train_data, val_data, test_data):\n",
    "    #temp_data = pd.concat([train_data[['bd']], val_data[['bd']], test_data[['bd']]], axis=0, join=\"outer\")\n",
    "    #mean_bd = temp_data['bd'].mean(axis=0)\n",
    "#     mean_bd = temp_data['bd'].replace(0, np.nan).mean(axis=0)\n",
    "#     train_data = train_data.fillna(value={'bd': mean_bd})\n",
    "#     val_data = val_data.fillna(value={'bd': mean_bd})\n",
    "#     test_data = test_data.fillna(value={'bd': mean_bd})\n",
    "    train_data['bd'] = train_data['bd'].replace(0, np.nan)\n",
    "    val_data['bd'] = val_data['bd'].replace(0, np.nan)\n",
    "    test_data['bd'] = test_data['bd'].replace(0, np.nan)\n",
    "    \n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_use, validation_use, test = fill_data_of_birth(train_use, validation_use, test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wheteher is the most genre of a artist or song or msno\n",
    "def binary_encode_genre_ids(train_data, val_data, test_data):\n",
    "    temp_msno_songid = pd.concat([train_data[['msno', 'artist_name', 'genre_ids']], val_data[['msno', 'artist_name', 'genre_ids']], test_data[['msno', 'artist_name', 'genre_ids']]], axis=0, join=\"outer\")\n",
    "    #df.groupby('id')['value'].nlargest(2)\n",
    "\n",
    "    mode = lambda x: x.mode() if len(x) > 2 else np.array(x)\n",
    "    for left, right in [('msno', 'artist_name'), ('msno', 'genre_ids'), ('artist_name', 'genre_ids'), ('artist_name', 'msno')]:\n",
    "        #grouped = temp_msno_songid.groupby(left)[right]#.agg(mode)\n",
    "        grouped = temp_msno_songid.groupby(left)[right].agg(lambda x: list(x.value_counts().index[0:3]))\n",
    "\n",
    "        #print(grouped.index)\n",
    "        grouped_split = pd.DataFrame(grouped.values.tolist(), columns=[str(right)+'_0',str(right)+'_1',str(right)+'_2'])\n",
    "        grouped_split.index = grouped.index\n",
    "\n",
    "        grouped_split = grouped_split.reset_index()\n",
    "        grouped_split.index.name='index'\n",
    "        #print(grouped_split)\n",
    "        temp_df = temp_msno_songid[[left, right]].merge(right = grouped_split, how = 'left', on=left)\n",
    "       \n",
    "        temp_train_data = train_data[[left, right]].merge(right = grouped_split, how = 'left', on=left)\n",
    "        temp_val_data = val_data[[left, right]].merge(right = grouped_split, how = 'left', on=left)\n",
    "        temp_test_data = test_data[[left, right]].merge(right = grouped_split, how = 'left', on=left)\n",
    "        for df in [temp_train_data, temp_val_data, temp_test_data]:\n",
    "            #weights = [1., 0.8, 0.6]\n",
    "            weights = [1., 0.2, 0.]\n",
    "            for i, col in enumerate([str(right)+'_0',str(right)+'_1',str(right)+'_2']):\n",
    "                df['in_top_'+str(i)+'_'+col] = (df[col] == df[right]).astype(np.float32)*weights[i]\n",
    "            df[left+'_is_in_topK_of_'+right] = df[['in_top_'+str(i)+'_'+col for i, col in enumerate([str(right)+'_0',str(right)+'_1',str(right)+'_2'])]].sum(axis=1).astype(np.float32)\n",
    "\n",
    "        train_data = pd.concat([train_data, temp_train_data[[left+'_is_in_topK_of_'+right]]], axis=1, join=\"outer\")\n",
    "        val_data = pd.concat([val_data, temp_val_data[[left+'_is_in_topK_of_'+right]]], axis=1, join=\"outer\")\n",
    "        test_data = pd.concat([test_data, temp_test_data[[left+'_is_in_topK_of_'+right]]], axis=1, join=\"outer\")\n",
    "        \n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd_to_merge, column_to_concat = binary_encode_genre_ids(train_use[['msno', 'artist_name', 'genre_ids']], validation_use[['msno', 'artist_name', 'genre_ids']], test[['msno', 'artist_name', 'genre_ids']])\n",
    "# for i, _ in enumerate(column_to_concat):\n",
    "#     train_use = pd.concat([train_use, pd_to_merge[i][0:len(train_use)]], axis=1, join=\"outer\")\n",
    "#     validation_use = pd.concat([validation_use, pd_to_merge[i][len(train_use):len(train_use)+len(validation_use)]], axis=1, join=\"outer\")\n",
    "#     test = pd.concat([test, pd_to_merge[i][len(train_use)+len(validation_use):]], axis=1, join=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_use, validation_use, test = binary_encode_genre_ids(train_use, validation_use, test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def routine_type_encode(train_data, val_data, test_data):\n",
    "    temp_msno_songid = pd.concat([train_data[['source_screen_name', 'source_type', 'popular_0', 'popular_1', 'active_0', 'active_1']], val_data[['source_screen_name', 'source_type', 'popular_0', 'popular_1', 'active_0', 'active_1']], test_data[['source_screen_name', 'source_type', 'popular_0', 'popular_1', 'active_0', 'active_1']]], axis=0, join=\"outer\")\n",
    "\n",
    "    for col in ['source_screen_name', 'source_type']:\n",
    "        grouped = temp_msno_songid.groupby(col)\n",
    "        count_type = np.log(grouped.size()+1)\n",
    "        count_type = count_type.reset_index()\n",
    "        count_type.columns=[col, col + '_count']\n",
    "        #print(count_type)\n",
    "        group_mean0 = grouped['popular_0'].agg(['mean'])\n",
    "        group_mean0 = group_mean0.reset_index()\n",
    "        group_mean0.columns=[col, col + 'popular_0_mean']\n",
    "        \n",
    "        group_mean1 = grouped['popular_1'].agg(['mean'])\n",
    "        group_mean1 = group_mean1.reset_index()\n",
    "        group_mean1.columns=[col, col + 'popular_1_mean']\n",
    "        \n",
    "        group_mean2 = grouped['active_0'].agg(['mean'])\n",
    "        group_mean2 = group_mean2.reset_index()\n",
    "        group_mean2.columns=[col, col + 'active_0_mean']\n",
    "        \n",
    "        group_mean3 = grouped['active_1'].agg(['mean'])\n",
    "        group_mean3 = group_mean3.reset_index()\n",
    "        group_mean3.columns=[col, col + 'active_1_mean']\n",
    "        type_score = count_type.merge(right = group_mean0, how = 'left', on=col)\n",
    "        type_score = type_score.merge(right = group_mean1, how = 'left', on=col)\n",
    "        type_score = type_score.merge(right = group_mean2, how = 'left', on=col)\n",
    "        type_score = type_score.merge(right = group_mean3, how = 'left', on=col)\n",
    "\n",
    "        type_score.index.name='index'\n",
    "        #print(type_score)\n",
    "        type_score.columns = [col, col + '_count', col + '_mean_popular_0', col + '_mean_popular_1', col + '_mean_active_0', col + '_mean_active_1']\n",
    "\n",
    "        train_data = train_data.merge(right = type_score, how = 'left', on=col)\n",
    "        val_data = val_data.merge(right = type_score, how = 'left', on=col)\n",
    "        test_data = test_data.merge(right = type_score, how = 'left', on=col)\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_use, validation_use, test = routine_type_encode(train_use, validation_use, test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_city_lang_country_by_others(train_data, val_data, test_data):\n",
    "#     temp_msno_songid = pd.concat([train_data[['song_id', 'msno', 'genre_ids', 'artist_name', 'city', 'country', 'language']], val_data[['song_id', 'msno', 'genre_ids', 'artist_name', 'city', 'country', 'language']], test_data[['song_id', 'msno', 'genre_ids', 'artist_name', 'city', 'country', 'language']]], axis=0, join=\"outer\")\n",
    "    \n",
    "#     count_dict = dict()\n",
    "    \n",
    "#     for col in ['city', 'country', 'language']:\n",
    "#         temp_df = None\n",
    "#         for target in ['song_id', 'msno', 'genre_ids', 'artist_name']:\n",
    "#             grouped = temp_msno_songid.groupby([col])\n",
    "#             df = grouped.agg({target: lambda x: x.nunique()})\n",
    "#             df = np.log(df+1)\n",
    "# #             print(df)\n",
    "# #             break\n",
    "#             if temp_df is not None:\n",
    "#                 temp_df = pd.concat([temp_df, df[target]], axis=1, join=\"inner\")\n",
    "#             else:\n",
    "#                 temp_df = df\n",
    "#         temp_df = temp_df.reset_index()\n",
    "#         temp_df.index.name='index'\n",
    "        \n",
    "#         temp_df.columns = [col, *[col + '_by_' + col_name for col_name in ['song_id', 'msno', 'genre_ids', 'artist_name']]]\n",
    "#         #print(temp_df)    \n",
    "#         train_data = train_data.merge(right = temp_df, how = 'left', on=col)\n",
    "#         test_data = test_data.merge(right = temp_df, how = 'left', on=col)\n",
    "#         val_data = val_data.merge(right = temp_df, how = 'left', on=col)\n",
    "#     return train_data, val_data, test_data\n",
    "    temp_msno_songid = pd.concat([train_data[['song_id', 'msno', 'genre_ids', 'artist_name', 'city', 'language']], val_data[['song_id', 'msno', 'genre_ids', 'artist_name', 'city', 'language']], test_data[['song_id', 'msno', 'genre_ids', 'artist_name', 'city', 'language']]], axis=0, join=\"outer\")\n",
    "    \n",
    "    count_dict = dict()\n",
    "    \n",
    "    for col in ['city', 'language']:\n",
    "        temp_df = None\n",
    "        for target in ['song_id', 'msno', 'genre_ids', 'artist_name']:\n",
    "            grouped = temp_msno_songid.groupby([col])\n",
    "            df = grouped.agg({target: lambda x: x.nunique()})\n",
    "            df = np.log(df+1)\n",
    "#             print(df)\n",
    "#             break\n",
    "            if temp_df is not None:\n",
    "                temp_df = pd.concat([temp_df, df[target]], axis=1, join=\"inner\")\n",
    "            else:\n",
    "                temp_df = df\n",
    "        temp_df = temp_df.reset_index()\n",
    "        temp_df.index.name='index'\n",
    "        \n",
    "        temp_df.columns = [col, *[col + '_by_' + col_name for col_name in ['song_id', 'msno', 'genre_ids', 'artist_name']]]\n",
    "        #print(temp_df)    \n",
    "        train_data = train_data.merge(right = temp_df, how = 'left', on=col)\n",
    "        test_data = test_data.merge(right = temp_df, how = 'left', on=col)\n",
    "        val_data = val_data.merge(right = temp_df, how = 'left', on=col)\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_use, validation_use, test = measure_city_lang_country_by_others(train_use, validation_use, test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(validation_use.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def encode_binary_feature(train_data, test_data, val_data):\n",
    "#     mode = lambda x: x.mode() if len(x) > 2 else np.array(x)\n",
    "# >>> df.groupby('tag')['category'].agg(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in test.columns:\n",
    "    if col not in ['song_length', 'id']:\n",
    "        if test[col].dtype == np.float64:\n",
    "            train_use[col] = train_use[col].astype(np.float32)\n",
    "            validation_use[col] = validation_use[col].astype(np.float32)\n",
    "            test[col] = test[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in [col for col in test.columns if col != 'id' ]:\n",
    "    if train_use[col].dtype == object:\n",
    "        train_use[col] = train_use[col].astype('category')\n",
    "        validation_use[col] = validation_use[col].astype('category')\n",
    "        test[col] = test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_use.drop(['composer_score', 'lyricist_score', 'composer_by_city', 'composer_by_country', 'composer_by_language', 'lyricist_by_city', 'lyricist_by_country', 'lyricist_by_language', 'msno_by_country', 'genre_ids_score', 'city_by_song_id', 'city_by_genre_ids', 'language_by_song_id', 'language_by_genre_ids'], axis=1, inplace=True)\n",
    "# validation_use.drop(['composer_score', 'lyricist_score', 'composer_by_city', 'composer_by_country', 'composer_by_language', 'lyricist_by_city', 'lyricist_by_country', 'lyricist_by_language', 'msno_by_country', 'genre_ids_score', 'city_by_song_id', 'city_by_genre_ids', 'language_by_song_id', 'language_by_genre_ids'], axis=1, inplace=True)\n",
    "# test.drop(['composer_score', 'lyricist_score', 'composer_by_city', 'composer_by_country', 'composer_by_language', 'lyricist_by_city', 'lyricist_by_country', 'lyricist_by_language', 'msno_by_country', 'genre_ids_score', 'city_by_song_id', 'city_by_genre_ids', 'language_by_song_id', 'language_by_genre_ids'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is barrier [end] for faster testing, load and use next\n",
    "#del train_use, validation_use, test\n",
    "# gc.collect()\n",
    "# float32_list = ['genre_ids', 'language', 'song_year', 'composer_score', 'lyricist_score', 'artist_name_score', 'popular_0', 'num_people_0', 'popular_1', 'num_people_1', 'popular_2', 'num_people_2', 'popular_3', 'num_people_3', 'popular_4', 'num_people_4', 'active_0', 'num_song_0', 'active_1', 'num_song_1', 'active_2', 'num_song_2', 'active_3', 'num_song_3', 'active_4', 'num_song_4', 'composer_by_city', 'composer_by_country', 'composer_by_language', 'lyricist_by_city', 'lyricist_by_country', 'lyricist_by_language', 'artist_name_by_city', 'artist_name_by_country', 'artist_name_by_language', 'song_id_by_city', 'msno_by_country', 'msno_by_language', 'genre_ids_score', 'msno_is_in_topK_of_artist_name', 'msno_is_in_topK_of_genre_ids', 'artist_name_is_in_topK_of_genre_ids', 'artist_name_is_in_topK_of_msno', 'source_screen_name_count', 'source_screen_name_mean_popular_0', 'source_screen_name_mean_popular_1', 'source_screen_name_mean_active_0', 'source_screen_name_mean_active_1', 'source_type_count', 'source_type_mean_popular_0', 'source_type_mean_popular_1', 'source_type_mean_active_0', 'source_type_mean_active_1', 'city_by_song_id', 'city_by_msno', 'city_by_genre_ids', 'city_by_artist_name', 'language_by_song_id', 'language_by_msno', 'language_by_genre_ids', 'language_by_artist_name']\n",
    "# data_type_map =dict(zip(float32_list, [np.float32]*len(float32_list))) \n",
    "# train_use = pd.read_csv(DATASET_PATH + 'temp_train_all_comp.csv', compression='gzip', dtype = data_type_map)\n",
    "# validation_use = pd.read_csv(DATASET_PATH + 'temp_validation_all_comp.csv', compression='gzip', dtype = data_type_map)\n",
    "# test = pd.read_csv(DATASET_PATH + 'temp_test_all_comp.csv', compression='gzip', dtype = data_type_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_system_tab_encode(train_data, val_data, test_data):\n",
    "    temp_msno_songid = pd.concat([train_data[['source_system_tab', 'popular_0', 'popular_1', 'active_0', 'active_1']], val_data[['source_system_tab', 'popular_0', 'popular_1', 'active_0', 'active_1']], test_data[['source_system_tab', 'popular_0', 'popular_1', 'active_0', 'active_1']]], axis=0, join=\"outer\")\n",
    "\n",
    "    for col in ['source_system_tab']:\n",
    "        grouped = temp_msno_songid.groupby(col)\n",
    "        count_type = np.log(grouped.size()+1)\n",
    "        count_type = count_type.reset_index()\n",
    "        count_type.columns=[col, col + '_count']\n",
    "        #print(count_type)\n",
    "        group_mean0 = grouped['popular_0'].agg(['mean'])\n",
    "        group_mean0 = group_mean0.reset_index()\n",
    "        group_mean0.columns=[col, col + 'popular_0_mean']\n",
    "        \n",
    "        group_mean1 = grouped['popular_1'].agg(['mean'])\n",
    "        group_mean1 = group_mean1.reset_index()\n",
    "        group_mean1.columns=[col, col + 'popular_1_mean']\n",
    "        \n",
    "        group_mean2 = grouped['active_0'].agg(['mean'])\n",
    "        group_mean2 = group_mean2.reset_index()\n",
    "        group_mean2.columns=[col, col + 'active_0_mean']\n",
    "        \n",
    "        group_mean3 = grouped['active_1'].agg(['mean'])\n",
    "        group_mean3 = group_mean3.reset_index()\n",
    "        group_mean3.columns=[col, col + 'active_1_mean']\n",
    "        \n",
    "        type_score = count_type.merge(right = group_mean0, how = 'left', on=col)\n",
    "        type_score = type_score.merge(right = group_mean1, how = 'left', on=col)\n",
    "        type_score = type_score.merge(right = group_mean2, how = 'left', on=col)\n",
    "        type_score = type_score.merge(right = group_mean3, how = 'left', on=col)\n",
    "\n",
    "        type_score.index.name='index'\n",
    "        #print(type_score)\n",
    "        type_score.columns = [col, col + '_count', col + '_mean_popular_0', col + '_mean_popular_1', col + '_mean_active_0', col + '_mean_active_1']\n",
    "\n",
    "        train_data = train_data.merge(right = type_score, how = 'left', on=col)\n",
    "        val_data = val_data.merge(right = type_score, how = 'left', on=col)\n",
    "        test_data = test_data.merge(right = type_score, how = 'left', on=col)\n",
    "    return train_data, val_data, test_data\n",
    "gc.collect()\n",
    "train_use, validation_use, test = source_system_tab_encode(train_use, validation_use, test)\n",
    "for col in test.columns:\n",
    "    if col not in ['source_system_tab_count', 'source_system_tab_mean_popular_0', 'source_system_tab_mean_popular_1', 'source_system_tab_mean_active_0', 'source_system_tab_mean_active_1']:\n",
    "        if test[col].dtype == np.float64:\n",
    "            train_use[col] = train_use[col].astype(np.float32)\n",
    "            validation_use[col] = validation_use[col].astype(np.float32)\n",
    "            test[col] = test[col].astype(np.float32)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_use.drop(['composer_score', 'lyricist_score', 'composer_by_city', 'composer_by_country', 'composer_by_language', 'lyricist_by_city', 'lyricist_by_country', 'lyricist_by_language', 'msno_by_country', 'genre_ids_score', 'city_by_song_id', 'city_by_genre_ids', 'language_by_song_id', 'language_by_genre_ids'], axis=1, inplace=True)\n",
    "# validation_use.drop(['composer_score', 'lyricist_score', 'composer_by_city', 'composer_by_country', 'composer_by_language', 'lyricist_by_city', 'lyricist_by_country', 'lyricist_by_language', 'msno_by_country', 'genre_ids_score', 'city_by_song_id', 'city_by_genre_ids', 'language_by_song_id', 'language_by_genre_ids'], axis=1, inplace=True)\n",
    "# test.drop(['composer_score', 'lyricist_score', 'composer_by_city', 'composer_by_country', 'composer_by_language', 'lyricist_by_city', 'lyricist_by_country', 'lyricist_by_language', 'msno_by_country', 'genre_ids_score', 'city_by_song_id', 'city_by_genre_ids', 'language_by_song_id', 'language_by_genre_ids'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_target_from_test(train_data, val_data, test_data):\n",
    "    weight = 0.6\n",
    "\n",
    "    test_group = test.groupby(['msno', 'song_id'])['msno'].agg(['count'])\n",
    "    test_group = test_group.reset_index()\n",
    "    test_group.columns = ['msno', 'song_id', 'occur_cout_in_test']\n",
    "\n",
    "    train_data = pd.merge(train_data, test_group,  how='left', left_on=['msno','song_id'], right_on = ['msno','song_id']).fillna({'occur_cout_in_test':0})\n",
    "    train_data['ref_target'] = train_data['target']  + train_data['occur_cout_in_test'] * weight\n",
    "    train_data['ref_target'] = train_data['target'].clip(lower=0, upper=1, axis=0)\n",
    "\n",
    "    val_data = pd.merge(val_data, test_group,  how='left', left_on=['msno','song_id'], right_on = ['msno','song_id']).fillna({'occur_cout_in_test':0})\n",
    "    val_data['ref_target'] = val_data['target']  + val_data['occur_cout_in_test'] * weight\n",
    "    val_data['ref_target'] = val_data['target'].clip(lower=0, upper=1, axis=0)\n",
    "\n",
    "    train_data.drop('occur_cout_in_test', axis = 1, inplace=True)\n",
    "    val_data.drop('occur_cout_in_test', axis = 1, inplace=True)\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "#train_use, validation_use, test = fix_target_from_test(train_use, validation_use, test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "789"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum_merge_and_drop(train_data, val_data, test_data):\n",
    "#     merge_columns = [('source_screen_name_mean_popular_0', 'source_screen_name_mean_popular_1', 'source_screen_name_mean_active_0', 'source_screen_name_mean_active_1'),\\\n",
    "#                     ('source_type_mean_popular_0', 'source_type_mean_popular_1', 'source_type_mean_active_0', 'source_type_mean_active_1'),\\\n",
    "#                     ('source_system_tab_mean_popular_0', 'source_system_tab_mean_popular_1', 'source_system_tab_mean_active_0', 'source_system_tab_mean_active_1')]\n",
    "\n",
    "#     merge_columns_name = ['source_screen_name_avg_score', 'source_type_avg_score', 'source_system_tab_avg_score']\n",
    "    \n",
    "    merge_columns = [('source_screen_name_mean_popular_0', 'source_screen_name_mean_popular_1', 'source_screen_name_mean_active_0', 'source_screen_name_mean_active_1'),\\\n",
    "                    ('source_type_mean_popular_0', 'source_type_mean_popular_1', 'source_type_mean_active_0', 'source_type_mean_active_1'),\\\n",
    "                    ('source_system_tab_mean_popular_0', 'source_system_tab_mean_popular_1', 'source_system_tab_mean_active_0', 'source_system_tab_mean_active_1'),\\\n",
    "                    ('composer_by_city', 'composer_by_country', 'composer_by_language'),\\\n",
    "                    ('lyricist_by_city', 'lyricist_by_country', 'lyricist_by_language'),\\\n",
    "                    ('artist_name_by_city', 'artist_name_by_country', 'artist_name_by_language'),\\\n",
    "                    ('city_by_song_id', 'city_by_msno', 'city_by_genre_ids', 'city_by_artist_name'),\\\n",
    "                    ('language_by_song_id', 'language_by_msno', 'language_by_genre_ids', 'language_by_artist_name')]\n",
    "\n",
    "    merge_columns_name = ['source_screen_name_avg_score',\\\n",
    "                        'source_type_avg_score',\\\n",
    "                        'source_system_tab_avg_score',\\\n",
    "                        'composer_by_city_country_language',\\\n",
    "                        'lyricist_by_city_country_language',\\\n",
    "                        'artist_name_by_city_country_language',\\\n",
    "                        'city_hot',\\\n",
    "                        'language_hot']\n",
    "    \n",
    "    for i, cols in enumerate(merge_columns):\n",
    "        train_data[merge_columns_name[i]] = train_data[[col for col in cols]].mean(axis = 1).astype(np.float32)\n",
    "        train_data.drop([col for col in cols], axis = 1, inplace=True)\n",
    "\n",
    "        val_data[merge_columns_name[i]] = val_data[[col for col in cols]].mean(axis = 1).astype(np.float32)\n",
    "        val_data.drop([col for col in cols], axis = 1, inplace=True)\n",
    "\n",
    "        test_data[merge_columns_name[i]] = test_data[[col for col in cols]].mean(axis = 1).astype(np.float32)\n",
    "        test_data.drop([col for col in cols], axis = 1, inplace=True)\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "train_use, validation_use, test = sum_merge_and_drop(train_use, validation_use, test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_use.drop([ 'num_song_1', 'num_song_2', 'num_song_3', 'num_song_4', 'num_people_1', 'num_people_2', 'num_people_3', 'num_people_4'], axis=1, inplace=True)\n",
    "validation_use.drop([ 'num_song_1', 'num_song_2', 'num_song_3', 'num_song_4', 'num_people_1', 'num_people_2', 'num_people_3', 'num_people_4'], axis=1, inplace=True)\n",
    "test.drop([ 'num_song_1', 'num_song_2', 'num_song_3', 'num_song_4', 'num_people_1', 'num_people_2', 'num_people_3', 'num_people_4'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train saved.\n",
      "val saved.\n",
      "test saved.\n"
     ]
    }
   ],
   "source": [
    "train_use.to_csv(DATASET_PATH + 'temp_train_all_comp_delete.csv', index = False, compression='gzip')\n",
    "print('train saved.')\n",
    "validation_use.to_csv(DATASET_PATH + 'temp_validation_all_comp_delete.csv', index = False, compression='gzip')\n",
    "print('val saved.')\n",
    "test.to_csv(DATASET_PATH + 'temp_test_all_comp_delete.csv', index = False, compression='gzip')\n",
    "print('test saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['genre_ids', 'language', 'song_year', 'composer_score', 'lyricist_score', 'artist_name_score', 'popular_0', 'num_people_0', 'popular_1', 'popular_2', 'popular_3', 'popular_4', 'active_0', 'num_song_0', 'active_1', 'active_2', 'active_3', 'active_4', 'song_id_by_city', 'msno_by_country', 'msno_by_language', 'genre_ids_score', 'msno_is_in_topK_of_artist_name', 'msno_is_in_topK_of_genre_ids', 'artist_name_is_in_topK_of_genre_ids', 'artist_name_is_in_topK_of_msno', 'source_screen_name_count', 'source_type_count', 'source_system_tab_count', 'source_screen_name_avg_score', 'source_type_avg_score', 'source_system_tab_avg_score', 'composer_by_city_country_language', 'lyricist_by_city_country_language', 'artist_name_by_city_country_language', 'city_hot', 'language_hot']\n"
     ]
    }
   ],
   "source": [
    "float32_list = list()\n",
    "for col in test.columns:\n",
    "    if col not in ['song_length', 'id']:\n",
    "        if test[col].dtype == np.float32:\n",
    "            float32_list.append(col)\n",
    "print(float32_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this it barrier [start] for faster testing, save first\n",
    "# store = pd.HDFStore(HDF_FILENAME_TEMPSAVE)\n",
    "# store['train'] = train_use\n",
    "# print('train saved.')\n",
    "# store['val'] = validation_use\n",
    "# print('val saved.')\n",
    "# store['test'] = test\n",
    "# print('test saved.')\n",
    "# store.close()\n",
    "train_use.to_csv(DATASET_PATH + 'temp_train_all_comp_2.csv', index = False, compression='gzip')\n",
    "print('train saved.')\n",
    "validation_use.to_csv(DATASET_PATH + 'temp_validation_all_comp_2.csv', index = False, compression='gzip')\n",
    "print('val saved.')\n",
    "test.to_csv(DATASET_PATH + 'temp_test_all_comp_2.csv', index = False, compression='gzip')\n",
    "print('test saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train_use, validation_use, test\n",
    "gc.collect()\n",
    "float32_list = ['genre_ids', 'language', 'song_year', 'composer_score', 'lyricist_score', 'artist_name_score', 'popular_0', 'num_people_0', 'popular_1', 'popular_2', 'popular_3', 'popular_4', 'active_0', 'num_song_0', 'active_1', 'active_2', 'active_3', 'active_4', 'song_id_by_city', 'msno_by_country', 'msno_by_language', 'genre_ids_score', 'msno_is_in_topK_of_artist_name', 'msno_is_in_topK_of_genre_ids', 'artist_name_is_in_topK_of_genre_ids', 'artist_name_is_in_topK_of_msno', 'source_screen_name_count', 'source_type_count', 'source_system_tab_count', 'source_screen_name_avg_score', 'source_type_avg_score', 'source_system_tab_avg_score', 'composer_by_city_country_language', 'lyricist_by_city_country_language', 'artist_name_by_city_country_language', 'city_hot', 'language_hot']\n",
    "data_type_map =dict(zip(float32_list, [np.float32]*len(float32_list))) \n",
    "train_use = pd.read_csv(DATASET_PATH + 'temp_train_all_comp_delete.csv', compression='gzip', dtype = data_type_map)\n",
    "validation_use = pd.read_csv(DATASET_PATH + 'temp_validation_all_comp_delete.csv', compression='gzip', dtype = data_type_map)\n",
    "test = pd.read_csv(DATASET_PATH + 'temp_test_all_comp_delete.csv', compression='gzip', dtype = data_type_map)\n",
    "test_id =  test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in [col for col in test.columns if col != 'id' ]:\n",
    "    if train_use[col].dtype == object:\n",
    "        train_use[col] = train_use[col].astype('category')\n",
    "        validation_use[col] = validation_use[col].astype('category')\n",
    "        test[col] = test[col].astype('category')\n",
    "for col in test.columns:\n",
    "    if col not in ['song_length', 'id']:\n",
    "        if test[col].dtype == np.float64:\n",
    "            train_use[col] = train_use[col].astype(np.float32)\n",
    "            validation_use[col] = validation_use[col].astype(np.float32)\n",
    "            test[col] = test[col].astype(np.float32)\n",
    "for col in test.columns:\n",
    "    if col in ['registered_via', 'bd', 'city', 'registration_year', 'registration_month', 'registration_day', 'expiration_year', 'expiration_year', 'expiration_day']:\n",
    "        if test[col].dtype == np.int64:\n",
    "            train_use[col] = train_use[col].astype(np.int32)\n",
    "            validation_use[col] = validation_use[col].astype(np.int32)\n",
    "            test[col] = test[col].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msno : category ; uinque values: 30571\n",
      "song_id : category ; uinque values: 357496\n",
      "source_system_tab : category ; uinque values: 9\n",
      "source_screen_name : category ; uinque values: 20\n",
      "source_type : category ; uinque values: 12\n",
      "target : int64 ; uinque values: 2\n",
      "city : int32 ; uinque values: 21\n",
      "bd : int32 ; uinque values: 91\n",
      "gender : category ; uinque values: 2\n",
      "registered_via : int32 ; uinque values: 5\n",
      "song_length : float64 ; uinque values: 60028\n",
      "genre_ids : float32 ; uinque values: 153\n",
      "language : float32 ; uinque values: 10\n",
      "name : category ; uinque values: 232729\n",
      "country : category ; uinque values: 107\n",
      "song_year : float32 ; uinque values: 100\n",
      "registration_year : int32 ; uinque values: 14\n",
      "registration_month : int32 ; uinque values: 12\n",
      "registration_day : int32 ; uinque values: 31\n",
      "expiration_year : int32 ; uinque values: 18\n",
      "expiration_month : int64 ; uinque values: 12\n",
      "expiration_day : int32 ; uinque values: 31\n",
      "days : int64 ; uinque values: 4319\n",
      "composer_score : float32 ; uinque values: 2218\n",
      "composer : category ; uinque values: 49086\n",
      "lyricist_score : float32 ; uinque values: 1652\n",
      "lyricist : category ; uinque values: 24205\n",
      "artist_name_score : float32 ; uinque values: 1842\n",
      "artist_name : category ; uinque values: 39234\n",
      "popular_0 : float32 ; uinque values: 2041\n",
      "num_people_0 : float32 ; uinque values: 2003\n",
      "popular_1 : float32 ; uinque values: 457\n",
      "popular_2 : float32 ; uinque values: 1018\n",
      "popular_3 : float32 ; uinque values: 996\n",
      "popular_4 : float32 ; uinque values: 1554\n",
      "active_0 : float32 ; uinque values: 1814\n",
      "num_song_0 : float32 ; uinque values: 1772\n",
      "active_1 : float32 ; uinque values: 346\n",
      "active_2 : float32 ; uinque values: 707\n",
      "active_3 : float32 ; uinque values: 620\n",
      "active_4 : float32 ; uinque values: 1059\n",
      "song_id_by_city : float32 ; uinque values: 21\n",
      "msno_by_country : float32 ; uinque values: 45\n",
      "msno_by_language : float32 ; uinque values: 10\n",
      "genre_ids_score : float32 ; uinque values: 132\n",
      "genre_ids_popular : int64 ; uinque values: 8\n",
      "msno_is_in_topK_of_artist_name : float32 ; uinque values: 3\n",
      "msno_is_in_topK_of_genre_ids : float32 ; uinque values: 3\n",
      "artist_name_is_in_topK_of_genre_ids : float32 ; uinque values: 3\n",
      "artist_name_is_in_topK_of_msno : float32 ; uinque values: 3\n",
      "source_screen_name_count : float32 ; uinque values: 21\n",
      "source_type_count : float32 ; uinque values: 13\n",
      "source_system_tab_count : float32 ; uinque values: 10\n",
      "source_screen_name_avg_score : float32 ; uinque values: 21\n",
      "source_type_avg_score : float32 ; uinque values: 13\n",
      "source_system_tab_avg_score : float32 ; uinque values: 10\n",
      "composer_by_city_country_language : float32 ; uinque values: 458\n",
      "lyricist_by_city_country_language : float32 ; uinque values: 376\n",
      "artist_name_by_city_country_language : float32 ; uinque values: 408\n",
      "city_hot : float32 ; uinque values: 21\n",
      "language_hot : float32 ; uinque values: 11\n"
     ]
    }
   ],
   "source": [
    "for col in train_use.columns: print(col, ':', train_use[col].dtype, '; uinque values:', len(train_use[col].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : int64 ; uinque values: 2556790\n",
      "msno : category ; uinque values: 25131\n",
      "song_id : category ; uinque values: 224753\n",
      "source_system_tab : category ; uinque values: 9\n",
      "source_screen_name : category ; uinque values: 22\n",
      "source_type : category ; uinque values: 12\n",
      "city : int32 ; uinque values: 21\n",
      "bd : int32 ; uinque values: 89\n",
      "gender : category ; uinque values: 2\n",
      "registered_via : int32 ; uinque values: 6\n",
      "song_length : float64 ; uinque values: 45659\n",
      "genre_ids : float32 ; uinque values: 148\n",
      "language : float32 ; uinque values: 10\n",
      "name : category ; uinque values: 154715\n",
      "country : category ; uinque values: 94\n",
      "song_year : float32 ; uinque values: 100\n",
      "registration_year : int32 ; uinque values: 14\n",
      "registration_month : int32 ; uinque values: 12\n",
      "registration_day : int32 ; uinque values: 31\n",
      "expiration_year : int32 ; uinque values: 16\n",
      "expiration_month : int64 ; uinque values: 12\n",
      "expiration_day : int32 ; uinque values: 31\n",
      "days : int64 ; uinque values: 4240\n",
      "composer_score : float32 ; uinque values: 2207\n",
      "composer : category ; uinque values: 35087\n",
      "lyricist_score : float32 ; uinque values: 1654\n",
      "lyricist : category ; uinque values: 18136\n",
      "artist_name_score : float32 ; uinque values: 1848\n",
      "artist_name : category ; uinque values: 26901\n",
      "popular_0 : float32 ; uinque values: 2083\n",
      "num_people_0 : float32 ; uinque values: 2045\n",
      "popular_1 : float32 ; uinque values: 457\n",
      "popular_2 : float32 ; uinque values: 1018\n",
      "popular_3 : float32 ; uinque values: 996\n",
      "popular_4 : float32 ; uinque values: 1616\n",
      "active_0 : float32 ; uinque values: 1811\n",
      "num_song_0 : float32 ; uinque values: 1767\n",
      "active_1 : float32 ; uinque values: 346\n",
      "active_2 : float32 ; uinque values: 704\n",
      "active_3 : float32 ; uinque values: 618\n",
      "active_4 : float32 ; uinque values: 1058\n",
      "song_id_by_city : float32 ; uinque values: 21\n",
      "msno_by_country : float32 ; uinque values: 45\n",
      "msno_by_language : float32 ; uinque values: 10\n",
      "genre_ids_score : float32 ; uinque values: 132\n",
      "genre_ids_popular : int64 ; uinque values: 8\n",
      "msno_is_in_topK_of_artist_name : float32 ; uinque values: 3\n",
      "msno_is_in_topK_of_genre_ids : float32 ; uinque values: 3\n",
      "artist_name_is_in_topK_of_genre_ids : float32 ; uinque values: 3\n",
      "artist_name_is_in_topK_of_msno : float32 ; uinque values: 3\n",
      "source_screen_name_count : float32 ; uinque values: 23\n",
      "source_type_count : float32 ; uinque values: 13\n",
      "source_system_tab_count : float32 ; uinque values: 10\n",
      "source_screen_name_avg_score : float32 ; uinque values: 23\n",
      "source_type_avg_score : float32 ; uinque values: 13\n",
      "source_system_tab_avg_score : float32 ; uinque values: 10\n",
      "composer_by_city_country_language : float32 ; uinque values: 457\n",
      "lyricist_by_city_country_language : float32 ; uinque values: 374\n",
      "artist_name_by_city_country_language : float32 ; uinque values: 404\n",
      "city_hot : float32 ; uinque values: 21\n",
      "language_hot : float32 ; uinque values: 11\n"
     ]
    }
   ],
   "source": [
    "for col in test.columns: print(col, ':', test[col].dtype, '; uinque values:', len(test[col].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msno : category ; uinque values: 30571\n",
      "song_id : category ; uinque values: 357496\n",
      "source_system_tab : category ; uinque values: 9\n",
      "source_screen_name : category ; uinque values: 20\n",
      "source_type : category ; uinque values: 12\n",
      "target : int64 ; uinque values: 2\n",
      "city : int32 ; uinque values: 21\n",
      "bd : int32 ; uinque values: 91\n",
      "gender : category ; uinque values: 2\n",
      "registered_via : int32 ; uinque values: 5\n",
      "song_length : float64 ; uinque values: 60028\n",
      "genre_ids : float32 ; uinque values: 153\n",
      "language : float32 ; uinque values: 10\n",
      "name : category ; uinque values: 232729\n",
      "country : category ; uinque values: 107\n",
      "song_year : float32 ; uinque values: 100\n",
      "registration_year : int32 ; uinque values: 14\n",
      "registration_month : int32 ; uinque values: 12\n",
      "registration_day : int32 ; uinque values: 31\n",
      "expiration_year : int32 ; uinque values: 18\n",
      "expiration_month : int64 ; uinque values: 12\n",
      "expiration_day : int32 ; uinque values: 31\n",
      "days : int64 ; uinque values: 4319\n",
      "composer_score : float32 ; uinque values: 2218\n",
      "composer : category ; uinque values: 49086\n",
      "lyricist_score : float32 ; uinque values: 1652\n",
      "lyricist : category ; uinque values: 24205\n",
      "artist_name_score : float32 ; uinque values: 1842\n",
      "artist_name : category ; uinque values: 39234\n",
      "popular_0 : float32 ; uinque values: 2041\n",
      "num_people_0 : float32 ; uinque values: 2003\n",
      "popular_1 : float32 ; uinque values: 457\n",
      "popular_2 : float32 ; uinque values: 1018\n",
      "popular_3 : float32 ; uinque values: 996\n",
      "popular_4 : float32 ; uinque values: 1554\n",
      "active_0 : float32 ; uinque values: 1814\n",
      "num_song_0 : float32 ; uinque values: 1772\n",
      "active_1 : float32 ; uinque values: 346\n",
      "active_2 : float32 ; uinque values: 707\n",
      "active_3 : float32 ; uinque values: 620\n",
      "active_4 : float32 ; uinque values: 1059\n",
      "song_id_by_city : float32 ; uinque values: 21\n",
      "msno_by_country : float32 ; uinque values: 45\n",
      "msno_by_language : float32 ; uinque values: 10\n",
      "genre_ids_score : float32 ; uinque values: 132\n",
      "genre_ids_popular : int64 ; uinque values: 8\n",
      "msno_is_in_topK_of_artist_name : float32 ; uinque values: 3\n",
      "msno_is_in_topK_of_genre_ids : float32 ; uinque values: 3\n",
      "artist_name_is_in_topK_of_genre_ids : float32 ; uinque values: 3\n",
      "artist_name_is_in_topK_of_msno : float32 ; uinque values: 3\n",
      "source_screen_name_count : float32 ; uinque values: 21\n",
      "source_type_count : float32 ; uinque values: 13\n",
      "source_system_tab_count : float32 ; uinque values: 10\n",
      "source_screen_name_avg_score : float32 ; uinque values: 21\n",
      "source_type_avg_score : float32 ; uinque values: 13\n",
      "source_system_tab_avg_score : float32 ; uinque values: 10\n",
      "composer_by_city_country_language : float32 ; uinque values: 458\n",
      "lyricist_by_city_country_language : float32 ; uinque values: 376\n",
      "artist_name_by_city_country_language : float32 ; uinque values: 408\n",
      "city_hot : float32 ; uinque values: 21\n",
      "language_hot : float32 ; uinque values: 11\n"
     ]
    }
   ],
   "source": [
    "for col in train_use.columns: print(col, ':', train_use[col].dtype, '; uinque values:', len(train_use[col].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2556790 2556790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test_id), len(test))\n",
    "#del train_use_org, test_org, validation_use_org\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['msno', 'song_id', 'source_system_tab', 'source_screen_name', 'source_type', 'city', 'bd', 'gender', 'registered_via', 'song_length', 'genre_ids', 'language', 'name', 'country', 'song_year', 'registration_year', 'registration_month', 'registration_day', 'expiration_year', 'expiration_month', 'expiration_day', 'days', 'composer_score', 'composer', 'lyricist_score', 'lyricist', 'artist_name_score', 'artist_name', 'popular_0', 'num_people_0', 'popular_1', 'popular_2', 'popular_3', 'popular_4', 'active_0', 'num_song_0', 'active_1', 'active_2', 'active_3', 'active_4', 'song_id_by_city', 'msno_by_country', 'msno_by_language', 'genre_ids_score', 'genre_ids_popular', 'msno_is_in_topK_of_artist_name', 'msno_is_in_topK_of_genre_ids', 'artist_name_is_in_topK_of_genre_ids', 'artist_name_is_in_topK_of_msno', 'source_screen_name_count', 'source_type_count', 'source_system_tab_count', 'source_screen_name_avg_score', 'source_type_avg_score', 'source_system_tab_avg_score', 'composer_by_city_country_language', 'lyricist_by_city_country_language', 'artist_name_by_city_country_language', 'city_hot', 'language_hot']\n"
     ]
    }
   ],
   "source": [
    "feature_list = list()\n",
    "for col in test.columns:\n",
    "    if col not in ['id']:\n",
    "        feature_list.append(col)\n",
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catogory_list = list()\n",
    "for col in test.columns:\n",
    "    if col not in ['song_length', 'id']:\n",
    "        if test[col].dtype.name == 'category':\n",
    "            catogory_list.append(col)\n",
    "print(catogory_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#用temp_train_all_comp_2 然后sum_merge_and_drop 和 drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kapok/pyenv35/lib/python3.5/site-packages/lightgbm/engine.py:98: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.641106\n",
      "[2]\tvalid_0's auc: 0.644627\n",
      "[3]\tvalid_0's auc: 0.648023\n",
      "[4]\tvalid_0's auc: 0.650209\n",
      "[5]\tvalid_0's auc: 0.651863\n",
      "[6]\tvalid_0's auc: 0.653013\n",
      "[7]\tvalid_0's auc: 0.653978\n",
      "[8]\tvalid_0's auc: 0.65505\n",
      "[9]\tvalid_0's auc: 0.655622\n",
      "[10]\tvalid_0's auc: 0.656833\n",
      "[11]\tvalid_0's auc: 0.657032\n",
      "[12]\tvalid_0's auc: 0.658177\n",
      "[13]\tvalid_0's auc: 0.658772\n",
      "[14]\tvalid_0's auc: 0.660138\n",
      "[15]\tvalid_0's auc: 0.660876\n",
      "[16]\tvalid_0's auc: 0.661929\n",
      "[17]\tvalid_0's auc: 0.662651\n",
      "[18]\tvalid_0's auc: 0.663747\n",
      "[19]\tvalid_0's auc: 0.6649\n",
      "[20]\tvalid_0's auc: 0.665395\n",
      "[21]\tvalid_0's auc: 0.66624\n",
      "[22]\tvalid_0's auc: 0.66695\n",
      "[23]\tvalid_0's auc: 0.667416\n",
      "[24]\tvalid_0's auc: 0.667868\n",
      "[25]\tvalid_0's auc: 0.668406\n",
      "[26]\tvalid_0's auc: 0.669488\n",
      "[27]\tvalid_0's auc: 0.670309\n",
      "[28]\tvalid_0's auc: 0.670745\n",
      "[29]\tvalid_0's auc: 0.671238\n",
      "[30]\tvalid_0's auc: 0.671472\n",
      "[31]\tvalid_0's auc: 0.672159\n",
      "[32]\tvalid_0's auc: 0.672501\n",
      "[33]\tvalid_0's auc: 0.672872\n",
      "[34]\tvalid_0's auc: 0.673317\n",
      "[35]\tvalid_0's auc: 0.673663\n",
      "[36]\tvalid_0's auc: 0.674421\n",
      "[37]\tvalid_0's auc: 0.675167\n",
      "[38]\tvalid_0's auc: 0.675459\n",
      "[39]\tvalid_0's auc: 0.675736\n",
      "[40]\tvalid_0's auc: 0.6759\n",
      "[41]\tvalid_0's auc: 0.675963\n",
      "[42]\tvalid_0's auc: 0.676321\n",
      "[43]\tvalid_0's auc: 0.676938\n",
      "[44]\tvalid_0's auc: 0.677202\n",
      "[45]\tvalid_0's auc: 0.67752\n",
      "[46]\tvalid_0's auc: 0.677699\n",
      "[47]\tvalid_0's auc: 0.677925\n",
      "[48]\tvalid_0's auc: 0.678126\n",
      "[49]\tvalid_0's auc: 0.678662\n",
      "[50]\tvalid_0's auc: 0.678892\n",
      "[51]\tvalid_0's auc: 0.679135\n",
      "[52]\tvalid_0's auc: 0.679234\n",
      "[53]\tvalid_0's auc: 0.679392\n",
      "[54]\tvalid_0's auc: 0.679437\n",
      "[55]\tvalid_0's auc: 0.679609\n",
      "[56]\tvalid_0's auc: 0.679818\n",
      "[57]\tvalid_0's auc: 0.679942\n",
      "[58]\tvalid_0's auc: 0.680117\n",
      "[59]\tvalid_0's auc: 0.680303\n",
      "[60]\tvalid_0's auc: 0.680563\n",
      "[61]\tvalid_0's auc: 0.680986\n",
      "[62]\tvalid_0's auc: 0.681365\n",
      "[63]\tvalid_0's auc: 0.681582\n",
      "[64]\tvalid_0's auc: 0.681744\n",
      "[65]\tvalid_0's auc: 0.682014\n",
      "[66]\tvalid_0's auc: 0.682191\n",
      "[67]\tvalid_0's auc: 0.682671\n",
      "[68]\tvalid_0's auc: 0.682689\n",
      "[69]\tvalid_0's auc: 0.682777\n",
      "[70]\tvalid_0's auc: 0.682903\n",
      "[71]\tvalid_0's auc: 0.682976\n",
      "[72]\tvalid_0's auc: 0.683111\n",
      "[73]\tvalid_0's auc: 0.683179\n",
      "[74]\tvalid_0's auc: 0.683201\n",
      "[75]\tvalid_0's auc: 0.683293\n",
      "[76]\tvalid_0's auc: 0.683506\n",
      "[77]\tvalid_0's auc: 0.683585\n",
      "[78]\tvalid_0's auc: 0.683685\n",
      "[79]\tvalid_0's auc: 0.683914\n",
      "[80]\tvalid_0's auc: 0.684001\n",
      "[81]\tvalid_0's auc: 0.684095\n",
      "[82]\tvalid_0's auc: 0.684172\n",
      "[83]\tvalid_0's auc: 0.684102\n",
      "[84]\tvalid_0's auc: 0.684339\n",
      "[85]\tvalid_0's auc: 0.68459\n",
      "[86]\tvalid_0's auc: 0.684698\n",
      "[87]\tvalid_0's auc: 0.684883\n",
      "[88]\tvalid_0's auc: 0.684984\n",
      "[89]\tvalid_0's auc: 0.685119\n",
      "[90]\tvalid_0's auc: 0.685232\n",
      "[91]\tvalid_0's auc: 0.685272\n",
      "[92]\tvalid_0's auc: 0.685351\n",
      "[93]\tvalid_0's auc: 0.68544\n",
      "[94]\tvalid_0's auc: 0.685537\n",
      "[95]\tvalid_0's auc: 0.685837\n",
      "[96]\tvalid_0's auc: 0.68593\n",
      "[97]\tvalid_0's auc: 0.686045\n",
      "[98]\tvalid_0's auc: 0.686062\n",
      "[99]\tvalid_0's auc: 0.686167\n",
      "[100]\tvalid_0's auc: 0.686308\n",
      "[101]\tvalid_0's auc: 0.686438\n",
      "[102]\tvalid_0's auc: 0.686461\n",
      "[103]\tvalid_0's auc: 0.68693\n",
      "[104]\tvalid_0's auc: 0.687308\n",
      "[105]\tvalid_0's auc: 0.687382\n",
      "[106]\tvalid_0's auc: 0.687502\n",
      "[107]\tvalid_0's auc: 0.687616\n",
      "[108]\tvalid_0's auc: 0.687729\n",
      "[109]\tvalid_0's auc: 0.687811\n",
      "[110]\tvalid_0's auc: 0.687938\n",
      "[111]\tvalid_0's auc: 0.688121\n",
      "[112]\tvalid_0's auc: 0.688211\n",
      "[113]\tvalid_0's auc: 0.688287\n",
      "[114]\tvalid_0's auc: 0.688361\n",
      "[115]\tvalid_0's auc: 0.688416\n",
      "[116]\tvalid_0's auc: 0.688408\n",
      "[117]\tvalid_0's auc: 0.688557\n",
      "[118]\tvalid_0's auc: 0.688599\n",
      "[119]\tvalid_0's auc: 0.688742\n",
      "[120]\tvalid_0's auc: 0.689028\n",
      "[121]\tvalid_0's auc: 0.689075\n",
      "[122]\tvalid_0's auc: 0.689183\n",
      "[123]\tvalid_0's auc: 0.68921\n",
      "[124]\tvalid_0's auc: 0.689229\n",
      "[125]\tvalid_0's auc: 0.689345\n",
      "[126]\tvalid_0's auc: 0.689479\n",
      "[127]\tvalid_0's auc: 0.689517\n",
      "[128]\tvalid_0's auc: 0.689519\n",
      "[129]\tvalid_0's auc: 0.689644\n",
      "[130]\tvalid_0's auc: 0.689959\n",
      "[131]\tvalid_0's auc: 0.689981\n",
      "[132]\tvalid_0's auc: 0.690014\n",
      "[133]\tvalid_0's auc: 0.690066\n",
      "[134]\tvalid_0's auc: 0.690124\n",
      "[135]\tvalid_0's auc: 0.690396\n",
      "[136]\tvalid_0's auc: 0.690562\n",
      "[137]\tvalid_0's auc: 0.690597\n",
      "[138]\tvalid_0's auc: 0.690665\n",
      "[139]\tvalid_0's auc: 0.690812\n",
      "[140]\tvalid_0's auc: 0.690915\n",
      "[141]\tvalid_0's auc: 0.691035\n",
      "[142]\tvalid_0's auc: 0.691085\n",
      "[143]\tvalid_0's auc: 0.691139\n",
      "[144]\tvalid_0's auc: 0.691286\n",
      "[145]\tvalid_0's auc: 0.69136\n",
      "[146]\tvalid_0's auc: 0.691391\n",
      "[147]\tvalid_0's auc: 0.691401\n",
      "[148]\tvalid_0's auc: 0.691544\n",
      "[149]\tvalid_0's auc: 0.691631\n",
      "[150]\tvalid_0's auc: 0.691698\n",
      "[151]\tvalid_0's auc: 0.691741\n",
      "[152]\tvalid_0's auc: 0.691759\n",
      "[153]\tvalid_0's auc: 0.69185\n",
      "[154]\tvalid_0's auc: 0.691887\n",
      "[155]\tvalid_0's auc: 0.691977\n",
      "[156]\tvalid_0's auc: 0.69201\n",
      "[157]\tvalid_0's auc: 0.692172\n",
      "[158]\tvalid_0's auc: 0.692202\n",
      "[159]\tvalid_0's auc: 0.692431\n",
      "[160]\tvalid_0's auc: 0.692655\n",
      "[161]\tvalid_0's auc: 0.692714\n",
      "[162]\tvalid_0's auc: 0.692758\n",
      "[163]\tvalid_0's auc: 0.692963\n",
      "[164]\tvalid_0's auc: 0.693062\n",
      "[165]\tvalid_0's auc: 0.693191\n",
      "[166]\tvalid_0's auc: 0.693218\n",
      "[167]\tvalid_0's auc: 0.69328\n",
      "[168]\tvalid_0's auc: 0.693291\n",
      "[169]\tvalid_0's auc: 0.693315\n",
      "[170]\tvalid_0's auc: 0.693433\n",
      "[171]\tvalid_0's auc: 0.693408\n",
      "[172]\tvalid_0's auc: 0.693399\n",
      "[173]\tvalid_0's auc: 0.693561\n",
      "[174]\tvalid_0's auc: 0.6936\n",
      "[175]\tvalid_0's auc: 0.693763\n",
      "[176]\tvalid_0's auc: 0.693837\n",
      "[177]\tvalid_0's auc: 0.693976\n",
      "[178]\tvalid_0's auc: 0.694157\n",
      "[179]\tvalid_0's auc: 0.694208\n",
      "[180]\tvalid_0's auc: 0.694252\n",
      "[181]\tvalid_0's auc: 0.694361\n",
      "[182]\tvalid_0's auc: 0.694357\n",
      "[183]\tvalid_0's auc: 0.694406\n",
      "[184]\tvalid_0's auc: 0.694424\n",
      "[185]\tvalid_0's auc: 0.694497\n",
      "[186]\tvalid_0's auc: 0.694573\n",
      "[187]\tvalid_0's auc: 0.694617\n",
      "[188]\tvalid_0's auc: 0.694621\n",
      "[189]\tvalid_0's auc: 0.694639\n",
      "[190]\tvalid_0's auc: 0.694634\n",
      "[191]\tvalid_0's auc: 0.694656\n",
      "[192]\tvalid_0's auc: 0.694649\n",
      "[193]\tvalid_0's auc: 0.694741\n",
      "[194]\tvalid_0's auc: 0.694772\n",
      "[195]\tvalid_0's auc: 0.694774\n",
      "[196]\tvalid_0's auc: 0.694866\n",
      "[197]\tvalid_0's auc: 0.69492\n",
      "[198]\tvalid_0's auc: 0.695119\n",
      "[199]\tvalid_0's auc: 0.695127\n",
      "[200]\tvalid_0's auc: 0.695142\n",
      "[201]\tvalid_0's auc: 0.69512\n",
      "[202]\tvalid_0's auc: 0.69517\n",
      "[203]\tvalid_0's auc: 0.695264\n",
      "[204]\tvalid_0's auc: 0.695311\n",
      "[205]\tvalid_0's auc: 0.695407\n",
      "[206]\tvalid_0's auc: 0.695401\n",
      "[207]\tvalid_0's auc: 0.69543\n",
      "[208]\tvalid_0's auc: 0.695508\n",
      "[209]\tvalid_0's auc: 0.695561\n",
      "[210]\tvalid_0's auc: 0.695637\n",
      "[211]\tvalid_0's auc: 0.695738\n",
      "[212]\tvalid_0's auc: 0.695768\n",
      "[213]\tvalid_0's auc: 0.695785\n",
      "[214]\tvalid_0's auc: 0.695813\n",
      "[215]\tvalid_0's auc: 0.695908\n",
      "[216]\tvalid_0's auc: 0.695876\n",
      "[217]\tvalid_0's auc: 0.696054\n",
      "[218]\tvalid_0's auc: 0.69613\n",
      "[219]\tvalid_0's auc: 0.696205\n",
      "[220]\tvalid_0's auc: 0.696319\n",
      "[221]\tvalid_0's auc: 0.696333\n",
      "[222]\tvalid_0's auc: 0.696321\n",
      "[223]\tvalid_0's auc: 0.696358\n",
      "[224]\tvalid_0's auc: 0.696355\n",
      "[225]\tvalid_0's auc: 0.696527\n",
      "[226]\tvalid_0's auc: 0.696624\n",
      "[227]\tvalid_0's auc: 0.69665\n",
      "[228]\tvalid_0's auc: 0.696718\n",
      "[229]\tvalid_0's auc: 0.696725\n",
      "[230]\tvalid_0's auc: 0.696668\n",
      "[231]\tvalid_0's auc: 0.696936\n",
      "[232]\tvalid_0's auc: 0.696937\n",
      "[233]\tvalid_0's auc: 0.696944\n",
      "[234]\tvalid_0's auc: 0.697027\n",
      "[235]\tvalid_0's auc: 0.697075\n",
      "[236]\tvalid_0's auc: 0.697118\n",
      "[237]\tvalid_0's auc: 0.697173\n",
      "[238]\tvalid_0's auc: 0.697207\n",
      "[239]\tvalid_0's auc: 0.697252\n",
      "[240]\tvalid_0's auc: 0.697297\n",
      "[241]\tvalid_0's auc: 0.697333\n",
      "[242]\tvalid_0's auc: 0.69739\n",
      "[243]\tvalid_0's auc: 0.697403\n",
      "[244]\tvalid_0's auc: 0.697388\n",
      "[245]\tvalid_0's auc: 0.697465\n",
      "[246]\tvalid_0's auc: 0.697553\n",
      "[247]\tvalid_0's auc: 0.69761\n",
      "[248]\tvalid_0's auc: 0.697587\n",
      "[249]\tvalid_0's auc: 0.697662\n",
      "[250]\tvalid_0's auc: 0.6978\n",
      "[251]\tvalid_0's auc: 0.697836\n",
      "[252]\tvalid_0's auc: 0.697969\n",
      "[253]\tvalid_0's auc: 0.698009\n",
      "[254]\tvalid_0's auc: 0.698036\n",
      "[255]\tvalid_0's auc: 0.698064\n",
      "[256]\tvalid_0's auc: 0.698115\n",
      "[257]\tvalid_0's auc: 0.698149\n",
      "[258]\tvalid_0's auc: 0.698328\n",
      "[259]\tvalid_0's auc: 0.698313\n",
      "[260]\tvalid_0's auc: 0.698385\n",
      "[261]\tvalid_0's auc: 0.698365\n",
      "[262]\tvalid_0's auc: 0.698402\n",
      "[263]\tvalid_0's auc: 0.698489\n",
      "[264]\tvalid_0's auc: 0.698562\n",
      "[265]\tvalid_0's auc: 0.698682\n",
      "[266]\tvalid_0's auc: 0.69872\n",
      "[267]\tvalid_0's auc: 0.698784\n",
      "[268]\tvalid_0's auc: 0.698767\n",
      "[269]\tvalid_0's auc: 0.698833\n",
      "[270]\tvalid_0's auc: 0.698833\n",
      "[271]\tvalid_0's auc: 0.698892\n",
      "[272]\tvalid_0's auc: 0.698922\n",
      "[273]\tvalid_0's auc: 0.698966\n",
      "[274]\tvalid_0's auc: 0.69901\n",
      "[275]\tvalid_0's auc: 0.699068\n",
      "[276]\tvalid_0's auc: 0.699061\n",
      "[277]\tvalid_0's auc: 0.699082\n",
      "[278]\tvalid_0's auc: 0.699082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[279]\tvalid_0's auc: 0.699116\n",
      "[280]\tvalid_0's auc: 0.699126\n",
      "[281]\tvalid_0's auc: 0.699239\n",
      "[282]\tvalid_0's auc: 0.699302\n",
      "[283]\tvalid_0's auc: 0.699298\n",
      "[284]\tvalid_0's auc: 0.699283\n",
      "[285]\tvalid_0's auc: 0.699295\n",
      "[286]\tvalid_0's auc: 0.699403\n",
      "[287]\tvalid_0's auc: 0.699466\n",
      "[288]\tvalid_0's auc: 0.699474\n",
      "[289]\tvalid_0's auc: 0.69953\n",
      "[290]\tvalid_0's auc: 0.699542\n",
      "[291]\tvalid_0's auc: 0.699565\n",
      "[292]\tvalid_0's auc: 0.699581\n",
      "[293]\tvalid_0's auc: 0.69961\n",
      "[294]\tvalid_0's auc: 0.69962\n",
      "[295]\tvalid_0's auc: 0.69967\n",
      "[296]\tvalid_0's auc: 0.69966\n",
      "[297]\tvalid_0's auc: 0.699647\n",
      "[298]\tvalid_0's auc: 0.699658\n",
      "[299]\tvalid_0's auc: 0.699689\n",
      "[300]\tvalid_0's auc: 0.69979\n",
      "[301]\tvalid_0's auc: 0.699851\n",
      "[302]\tvalid_0's auc: 0.699847\n",
      "[303]\tvalid_0's auc: 0.699913\n",
      "[304]\tvalid_0's auc: 0.699918\n",
      "[305]\tvalid_0's auc: 0.699929\n",
      "[306]\tvalid_0's auc: 0.699963\n",
      "[307]\tvalid_0's auc: 0.700014\n",
      "[308]\tvalid_0's auc: 0.700058\n",
      "[309]\tvalid_0's auc: 0.700052\n",
      "[310]\tvalid_0's auc: 0.700172\n",
      "[311]\tvalid_0's auc: 0.700204\n",
      "[312]\tvalid_0's auc: 0.700197\n",
      "[313]\tvalid_0's auc: 0.700263\n",
      "[314]\tvalid_0's auc: 0.700285\n",
      "[315]\tvalid_0's auc: 0.700328\n",
      "[316]\tvalid_0's auc: 0.700389\n",
      "[317]\tvalid_0's auc: 0.700407\n",
      "[318]\tvalid_0's auc: 0.700419\n",
      "[319]\tvalid_0's auc: 0.700473\n",
      "[320]\tvalid_0's auc: 0.700519\n",
      "[321]\tvalid_0's auc: 0.70049\n",
      "[322]\tvalid_0's auc: 0.700474\n",
      "[323]\tvalid_0's auc: 0.700488\n",
      "[324]\tvalid_0's auc: 0.700521\n",
      "[325]\tvalid_0's auc: 0.700589\n",
      "[326]\tvalid_0's auc: 0.700591\n",
      "[327]\tvalid_0's auc: 0.700629\n",
      "[328]\tvalid_0's auc: 0.70063\n",
      "[329]\tvalid_0's auc: 0.700714\n",
      "[330]\tvalid_0's auc: 0.700733\n",
      "[331]\tvalid_0's auc: 0.700749\n",
      "[332]\tvalid_0's auc: 0.700757\n",
      "[333]\tvalid_0's auc: 0.700843\n",
      "[334]\tvalid_0's auc: 0.700855\n",
      "[335]\tvalid_0's auc: 0.700872\n",
      "[336]\tvalid_0's auc: 0.700909\n",
      "[337]\tvalid_0's auc: 0.70093\n",
      "[338]\tvalid_0's auc: 0.700967\n",
      "[339]\tvalid_0's auc: 0.70097\n",
      "[340]\tvalid_0's auc: 0.700982\n",
      "[341]\tvalid_0's auc: 0.700997\n",
      "[342]\tvalid_0's auc: 0.700989\n",
      "[343]\tvalid_0's auc: 0.700967\n",
      "[344]\tvalid_0's auc: 0.700994\n",
      "[345]\tvalid_0's auc: 0.701066\n",
      "[346]\tvalid_0's auc: 0.70128\n",
      "[347]\tvalid_0's auc: 0.701268\n",
      "[348]\tvalid_0's auc: 0.70128\n",
      "[349]\tvalid_0's auc: 0.701333\n",
      "[350]\tvalid_0's auc: 0.701329\n",
      "[351]\tvalid_0's auc: 0.701334\n",
      "[352]\tvalid_0's auc: 0.701364\n",
      "[353]\tvalid_0's auc: 0.7014\n",
      "[354]\tvalid_0's auc: 0.701452\n",
      "[355]\tvalid_0's auc: 0.701474\n",
      "[356]\tvalid_0's auc: 0.701554\n",
      "[357]\tvalid_0's auc: 0.701596\n",
      "[358]\tvalid_0's auc: 0.701641\n",
      "[359]\tvalid_0's auc: 0.70168\n",
      "[360]\tvalid_0's auc: 0.70179\n",
      "[361]\tvalid_0's auc: 0.701806\n",
      "[362]\tvalid_0's auc: 0.701823\n",
      "[363]\tvalid_0's auc: 0.70183\n",
      "[364]\tvalid_0's auc: 0.701865\n",
      "[365]\tvalid_0's auc: 0.70185\n",
      "[366]\tvalid_0's auc: 0.701903\n",
      "[367]\tvalid_0's auc: 0.701907\n",
      "[368]\tvalid_0's auc: 0.701955\n",
      "[369]\tvalid_0's auc: 0.702017\n",
      "[370]\tvalid_0's auc: 0.702107\n",
      "[371]\tvalid_0's auc: 0.702127\n",
      "[372]\tvalid_0's auc: 0.702148\n",
      "[373]\tvalid_0's auc: 0.702195\n",
      "[374]\tvalid_0's auc: 0.702212\n",
      "[375]\tvalid_0's auc: 0.70234\n",
      "[376]\tvalid_0's auc: 0.702342\n",
      "[377]\tvalid_0's auc: 0.702351\n",
      "[378]\tvalid_0's auc: 0.702353\n",
      "[379]\tvalid_0's auc: 0.702374\n",
      "[380]\tvalid_0's auc: 0.702436\n",
      "[381]\tvalid_0's auc: 0.702454\n",
      "[382]\tvalid_0's auc: 0.70245\n",
      "[383]\tvalid_0's auc: 0.702545\n",
      "[384]\tvalid_0's auc: 0.702575\n",
      "[385]\tvalid_0's auc: 0.702654\n",
      "[386]\tvalid_0's auc: 0.702651\n",
      "[387]\tvalid_0's auc: 0.702669\n",
      "[388]\tvalid_0's auc: 0.702661\n",
      "[389]\tvalid_0's auc: 0.702679\n",
      "[390]\tvalid_0's auc: 0.702731\n",
      "[391]\tvalid_0's auc: 0.702771\n",
      "[392]\tvalid_0's auc: 0.702835\n",
      "[393]\tvalid_0's auc: 0.702883\n",
      "[394]\tvalid_0's auc: 0.702868\n",
      "[395]\tvalid_0's auc: 0.702827\n",
      "[396]\tvalid_0's auc: 0.702847\n",
      "[397]\tvalid_0's auc: 0.702869\n",
      "[398]\tvalid_0's auc: 0.702867\n",
      "[399]\tvalid_0's auc: 0.702879\n",
      "[400]\tvalid_0's auc: 0.702906\n",
      "[401]\tvalid_0's auc: 0.702909\n",
      "[402]\tvalid_0's auc: 0.702933\n",
      "[403]\tvalid_0's auc: 0.702951\n",
      "[404]\tvalid_0's auc: 0.702983\n",
      "[405]\tvalid_0's auc: 0.702993\n",
      "[406]\tvalid_0's auc: 0.702987\n",
      "[407]\tvalid_0's auc: 0.703026\n",
      "[408]\tvalid_0's auc: 0.70302\n",
      "[409]\tvalid_0's auc: 0.703055\n",
      "[410]\tvalid_0's auc: 0.703079\n",
      "[411]\tvalid_0's auc: 0.703081\n",
      "[412]\tvalid_0's auc: 0.703126\n",
      "[413]\tvalid_0's auc: 0.703152\n",
      "[414]\tvalid_0's auc: 0.703194\n",
      "[415]\tvalid_0's auc: 0.703216\n",
      "[416]\tvalid_0's auc: 0.703205\n",
      "[417]\tvalid_0's auc: 0.70321\n",
      "[418]\tvalid_0's auc: 0.703227\n",
      "[419]\tvalid_0's auc: 0.703252\n",
      "[420]\tvalid_0's auc: 0.70323\n",
      "[421]\tvalid_0's auc: 0.703297\n",
      "[422]\tvalid_0's auc: 0.703313\n",
      "[423]\tvalid_0's auc: 0.703315\n",
      "[424]\tvalid_0's auc: 0.703307\n",
      "[425]\tvalid_0's auc: 0.703299\n",
      "[426]\tvalid_0's auc: 0.703357\n",
      "[427]\tvalid_0's auc: 0.703439\n",
      "[428]\tvalid_0's auc: 0.703496\n",
      "[429]\tvalid_0's auc: 0.703507\n",
      "[430]\tvalid_0's auc: 0.703505\n",
      "[431]\tvalid_0's auc: 0.703543\n",
      "[432]\tvalid_0's auc: 0.703566\n",
      "[433]\tvalid_0's auc: 0.703563\n",
      "[434]\tvalid_0's auc: 0.703598\n",
      "[435]\tvalid_0's auc: 0.703651\n",
      "[436]\tvalid_0's auc: 0.703663\n",
      "[437]\tvalid_0's auc: 0.703657\n",
      "[438]\tvalid_0's auc: 0.703659\n",
      "[439]\tvalid_0's auc: 0.703681\n",
      "[440]\tvalid_0's auc: 0.70371\n",
      "[441]\tvalid_0's auc: 0.70371\n",
      "[442]\tvalid_0's auc: 0.703704\n",
      "[443]\tvalid_0's auc: 0.703723\n",
      "[444]\tvalid_0's auc: 0.703776\n",
      "[445]\tvalid_0's auc: 0.703791\n",
      "[446]\tvalid_0's auc: 0.703837\n",
      "[447]\tvalid_0's auc: 0.703863\n",
      "[448]\tvalid_0's auc: 0.703882\n",
      "[449]\tvalid_0's auc: 0.70388\n",
      "[450]\tvalid_0's auc: 0.703873\n",
      "[451]\tvalid_0's auc: 0.703909\n",
      "[452]\tvalid_0's auc: 0.703921\n",
      "[453]\tvalid_0's auc: 0.703921\n",
      "[454]\tvalid_0's auc: 0.703945\n",
      "[455]\tvalid_0's auc: 0.703963\n",
      "[456]\tvalid_0's auc: 0.704005\n",
      "[457]\tvalid_0's auc: 0.703983\n",
      "[458]\tvalid_0's auc: 0.704\n",
      "[459]\tvalid_0's auc: 0.704017\n",
      "[460]\tvalid_0's auc: 0.704\n",
      "[461]\tvalid_0's auc: 0.704015\n",
      "[462]\tvalid_0's auc: 0.704005\n",
      "[463]\tvalid_0's auc: 0.704026\n",
      "[464]\tvalid_0's auc: 0.704036\n",
      "[465]\tvalid_0's auc: 0.704035\n",
      "[466]\tvalid_0's auc: 0.704058\n",
      "[467]\tvalid_0's auc: 0.704063\n",
      "[468]\tvalid_0's auc: 0.704072\n",
      "[469]\tvalid_0's auc: 0.70405\n",
      "[470]\tvalid_0's auc: 0.704102\n",
      "[471]\tvalid_0's auc: 0.704123\n",
      "[472]\tvalid_0's auc: 0.704124\n",
      "[473]\tvalid_0's auc: 0.70418\n",
      "[474]\tvalid_0's auc: 0.704232\n",
      "[475]\tvalid_0's auc: 0.704225\n",
      "[476]\tvalid_0's auc: 0.704259\n",
      "[477]\tvalid_0's auc: 0.704371\n",
      "[478]\tvalid_0's auc: 0.704332\n",
      "[479]\tvalid_0's auc: 0.704374\n",
      "[480]\tvalid_0's auc: 0.704376\n",
      "[481]\tvalid_0's auc: 0.704389\n",
      "[482]\tvalid_0's auc: 0.704402\n",
      "[483]\tvalid_0's auc: 0.704387\n",
      "[484]\tvalid_0's auc: 0.704414\n",
      "[485]\tvalid_0's auc: 0.704437\n",
      "[486]\tvalid_0's auc: 0.704437\n",
      "[487]\tvalid_0's auc: 0.704447\n",
      "[488]\tvalid_0's auc: 0.704492\n",
      "[489]\tvalid_0's auc: 0.704523\n",
      "[490]\tvalid_0's auc: 0.704537\n",
      "[491]\tvalid_0's auc: 0.704567\n",
      "[492]\tvalid_0's auc: 0.704573\n",
      "[493]\tvalid_0's auc: 0.704583\n",
      "[494]\tvalid_0's auc: 0.704637\n",
      "[495]\tvalid_0's auc: 0.704645\n",
      "[496]\tvalid_0's auc: 0.704662\n",
      "[497]\tvalid_0's auc: 0.704663\n",
      "[498]\tvalid_0's auc: 0.704689\n",
      "[499]\tvalid_0's auc: 0.704712\n",
      "[500]\tvalid_0's auc: 0.704718\n",
      "[501]\tvalid_0's auc: 0.70473\n",
      "[502]\tvalid_0's auc: 0.704752\n",
      "[503]\tvalid_0's auc: 0.704777\n",
      "[504]\tvalid_0's auc: 0.704815\n",
      "[505]\tvalid_0's auc: 0.704845\n",
      "[506]\tvalid_0's auc: 0.70484\n",
      "[507]\tvalid_0's auc: 0.704834\n",
      "[508]\tvalid_0's auc: 0.704904\n",
      "[509]\tvalid_0's auc: 0.704926\n",
      "[510]\tvalid_0's auc: 0.704959\n",
      "[511]\tvalid_0's auc: 0.704959\n",
      "[512]\tvalid_0's auc: 0.704975\n",
      "[513]\tvalid_0's auc: 0.70496\n",
      "[514]\tvalid_0's auc: 0.704955\n",
      "[515]\tvalid_0's auc: 0.705002\n",
      "[516]\tvalid_0's auc: 0.704984\n",
      "[517]\tvalid_0's auc: 0.704991\n",
      "[518]\tvalid_0's auc: 0.704994\n",
      "[519]\tvalid_0's auc: 0.705104\n",
      "[520]\tvalid_0's auc: 0.705126\n",
      "[521]\tvalid_0's auc: 0.705176\n",
      "[522]\tvalid_0's auc: 0.705187\n",
      "[523]\tvalid_0's auc: 0.705242\n",
      "[524]\tvalid_0's auc: 0.70526\n",
      "[525]\tvalid_0's auc: 0.705252\n",
      "[526]\tvalid_0's auc: 0.705248\n",
      "[527]\tvalid_0's auc: 0.70526\n",
      "[528]\tvalid_0's auc: 0.705255\n",
      "[529]\tvalid_0's auc: 0.705293\n",
      "[530]\tvalid_0's auc: 0.705301\n",
      "[531]\tvalid_0's auc: 0.705285\n",
      "[532]\tvalid_0's auc: 0.705284\n",
      "[533]\tvalid_0's auc: 0.70532\n",
      "[534]\tvalid_0's auc: 0.70531\n",
      "[535]\tvalid_0's auc: 0.705319\n",
      "[536]\tvalid_0's auc: 0.705294\n",
      "[537]\tvalid_0's auc: 0.705302\n",
      "[538]\tvalid_0's auc: 0.705297\n",
      "[539]\tvalid_0's auc: 0.705316\n",
      "[540]\tvalid_0's auc: 0.705348\n",
      "[541]\tvalid_0's auc: 0.705343\n",
      "[542]\tvalid_0's auc: 0.705357\n",
      "[543]\tvalid_0's auc: 0.705368\n",
      "[544]\tvalid_0's auc: 0.70537\n",
      "[545]\tvalid_0's auc: 0.70539\n",
      "[546]\tvalid_0's auc: 0.705411\n",
      "[547]\tvalid_0's auc: 0.705433\n",
      "[548]\tvalid_0's auc: 0.705463\n",
      "[549]\tvalid_0's auc: 0.705465\n",
      "[550]\tvalid_0's auc: 0.70556\n",
      "[551]\tvalid_0's auc: 0.705559\n",
      "[552]\tvalid_0's auc: 0.70555\n",
      "[553]\tvalid_0's auc: 0.705545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[554]\tvalid_0's auc: 0.705583\n",
      "[555]\tvalid_0's auc: 0.705553\n",
      "[556]\tvalid_0's auc: 0.705537\n",
      "[557]\tvalid_0's auc: 0.705599\n",
      "[558]\tvalid_0's auc: 0.705607\n",
      "[559]\tvalid_0's auc: 0.705587\n",
      "[560]\tvalid_0's auc: 0.705582\n",
      "[561]\tvalid_0's auc: 0.705681\n",
      "[562]\tvalid_0's auc: 0.705671\n",
      "[563]\tvalid_0's auc: 0.705689\n",
      "[564]\tvalid_0's auc: 0.705723\n",
      "[565]\tvalid_0's auc: 0.705739\n",
      "[566]\tvalid_0's auc: 0.705755\n",
      "[567]\tvalid_0's auc: 0.705893\n",
      "[568]\tvalid_0's auc: 0.705895\n",
      "[569]\tvalid_0's auc: 0.70592\n",
      "[570]\tvalid_0's auc: 0.705941\n",
      "[571]\tvalid_0's auc: 0.70592\n",
      "[572]\tvalid_0's auc: 0.705962\n",
      "[573]\tvalid_0's auc: 0.705947\n",
      "[574]\tvalid_0's auc: 0.705961\n",
      "[575]\tvalid_0's auc: 0.705975\n",
      "[576]\tvalid_0's auc: 0.705958\n",
      "[577]\tvalid_0's auc: 0.705963\n",
      "[578]\tvalid_0's auc: 0.705969\n",
      "[579]\tvalid_0's auc: 0.705959\n",
      "[580]\tvalid_0's auc: 0.705929\n",
      "[581]\tvalid_0's auc: 0.705947\n",
      "[582]\tvalid_0's auc: 0.705964\n",
      "[583]\tvalid_0's auc: 0.705963\n",
      "[584]\tvalid_0's auc: 0.705999\n",
      "[585]\tvalid_0's auc: 0.706018\n",
      "[586]\tvalid_0's auc: 0.70604\n",
      "[587]\tvalid_0's auc: 0.706171\n",
      "[588]\tvalid_0's auc: 0.706183\n",
      "[589]\tvalid_0's auc: 0.706206\n",
      "[590]\tvalid_0's auc: 0.706191\n",
      "[591]\tvalid_0's auc: 0.706226\n",
      "[592]\tvalid_0's auc: 0.706254\n",
      "[593]\tvalid_0's auc: 0.706287\n",
      "[594]\tvalid_0's auc: 0.706269\n",
      "[595]\tvalid_0's auc: 0.706307\n",
      "[596]\tvalid_0's auc: 0.706297\n",
      "[597]\tvalid_0's auc: 0.706351\n",
      "[598]\tvalid_0's auc: 0.706364\n",
      "[599]\tvalid_0's auc: 0.706375\n",
      "[600]\tvalid_0's auc: 0.706332\n",
      "[601]\tvalid_0's auc: 0.70633\n",
      "[602]\tvalid_0's auc: 0.706307\n",
      "[603]\tvalid_0's auc: 0.706325\n",
      "[604]\tvalid_0's auc: 0.70633\n",
      "[605]\tvalid_0's auc: 0.70637\n",
      "[606]\tvalid_0's auc: 0.706395\n",
      "[607]\tvalid_0's auc: 0.706398\n",
      "[608]\tvalid_0's auc: 0.706405\n",
      "[609]\tvalid_0's auc: 0.706417\n",
      "[610]\tvalid_0's auc: 0.706417\n",
      "[611]\tvalid_0's auc: 0.706487\n",
      "[612]\tvalid_0's auc: 0.706517\n",
      "[613]\tvalid_0's auc: 0.706524\n",
      "[614]\tvalid_0's auc: 0.706524\n",
      "[615]\tvalid_0's auc: 0.706517\n",
      "[616]\tvalid_0's auc: 0.706517\n",
      "[617]\tvalid_0's auc: 0.706508\n",
      "[618]\tvalid_0's auc: 0.706513\n",
      "[619]\tvalid_0's auc: 0.706497\n",
      "[620]\tvalid_0's auc: 0.706491\n",
      "[621]\tvalid_0's auc: 0.706513\n",
      "[622]\tvalid_0's auc: 0.706531\n",
      "[623]\tvalid_0's auc: 0.706537\n",
      "[624]\tvalid_0's auc: 0.706556\n",
      "[625]\tvalid_0's auc: 0.706598\n",
      "[626]\tvalid_0's auc: 0.706601\n",
      "[627]\tvalid_0's auc: 0.706635\n",
      "[628]\tvalid_0's auc: 0.706623\n",
      "[629]\tvalid_0's auc: 0.70665\n",
      "[630]\tvalid_0's auc: 0.706672\n",
      "[631]\tvalid_0's auc: 0.706673\n",
      "[632]\tvalid_0's auc: 0.706668\n",
      "[633]\tvalid_0's auc: 0.706657\n",
      "[634]\tvalid_0's auc: 0.70665\n",
      "[635]\tvalid_0's auc: 0.706679\n",
      "[636]\tvalid_0's auc: 0.70677\n",
      "[637]\tvalid_0's auc: 0.706832\n",
      "[638]\tvalid_0's auc: 0.706834\n",
      "[639]\tvalid_0's auc: 0.706838\n",
      "[640]\tvalid_0's auc: 0.706832\n",
      "[641]\tvalid_0's auc: 0.706826\n",
      "[642]\tvalid_0's auc: 0.706842\n",
      "[643]\tvalid_0's auc: 0.706841\n",
      "[644]\tvalid_0's auc: 0.70685\n",
      "[645]\tvalid_0's auc: 0.706832\n",
      "[646]\tvalid_0's auc: 0.706852\n",
      "[647]\tvalid_0's auc: 0.70688\n",
      "[648]\tvalid_0's auc: 0.706891\n",
      "[649]\tvalid_0's auc: 0.706883\n",
      "[650]\tvalid_0's auc: 0.706876\n",
      "[651]\tvalid_0's auc: 0.706881\n",
      "[652]\tvalid_0's auc: 0.706891\n",
      "[653]\tvalid_0's auc: 0.706973\n",
      "[654]\tvalid_0's auc: 0.706957\n",
      "[655]\tvalid_0's auc: 0.706939\n",
      "[656]\tvalid_0's auc: 0.706949\n",
      "[657]\tvalid_0's auc: 0.706964\n",
      "[658]\tvalid_0's auc: 0.706971\n",
      "[659]\tvalid_0's auc: 0.706976\n",
      "[660]\tvalid_0's auc: 0.707016\n",
      "[661]\tvalid_0's auc: 0.706977\n",
      "[662]\tvalid_0's auc: 0.707054\n",
      "[663]\tvalid_0's auc: 0.707036\n",
      "[664]\tvalid_0's auc: 0.70703\n",
      "[665]\tvalid_0's auc: 0.707023\n",
      "[666]\tvalid_0's auc: 0.707006\n",
      "[667]\tvalid_0's auc: 0.707032\n",
      "[668]\tvalid_0's auc: 0.707006\n",
      "[669]\tvalid_0's auc: 0.70699\n",
      "[670]\tvalid_0's auc: 0.706961\n",
      "[671]\tvalid_0's auc: 0.706956\n",
      "[672]\tvalid_0's auc: 0.706981\n",
      "[673]\tvalid_0's auc: 0.706991\n",
      "[674]\tvalid_0's auc: 0.706975\n",
      "[675]\tvalid_0's auc: 0.706981\n",
      "[676]\tvalid_0's auc: 0.707004\n",
      "[677]\tvalid_0's auc: 0.707025\n",
      "[678]\tvalid_0's auc: 0.707061\n",
      "[679]\tvalid_0's auc: 0.707061\n",
      "[680]\tvalid_0's auc: 0.707104\n",
      "[681]\tvalid_0's auc: 0.707155\n",
      "[682]\tvalid_0's auc: 0.707148\n",
      "[683]\tvalid_0's auc: 0.707139\n",
      "[684]\tvalid_0's auc: 0.707142\n",
      "[685]\tvalid_0's auc: 0.707157\n",
      "[686]\tvalid_0's auc: 0.70721\n",
      "[687]\tvalid_0's auc: 0.707229\n",
      "[688]\tvalid_0's auc: 0.707245\n",
      "[689]\tvalid_0's auc: 0.707232\n",
      "[690]\tvalid_0's auc: 0.707285\n",
      "[691]\tvalid_0's auc: 0.707281\n",
      "[692]\tvalid_0's auc: 0.707289\n",
      "[693]\tvalid_0's auc: 0.707255\n",
      "[694]\tvalid_0's auc: 0.707241\n",
      "[695]\tvalid_0's auc: 0.707243\n",
      "[696]\tvalid_0's auc: 0.707248\n",
      "[697]\tvalid_0's auc: 0.707245\n",
      "[698]\tvalid_0's auc: 0.707232\n",
      "[699]\tvalid_0's auc: 0.70721\n",
      "[700]\tvalid_0's auc: 0.707189\n",
      "[701]\tvalid_0's auc: 0.707154\n",
      "[702]\tvalid_0's auc: 0.707131\n",
      "[703]\tvalid_0's auc: 0.707119\n",
      "[704]\tvalid_0's auc: 0.707134\n",
      "[705]\tvalid_0's auc: 0.707184\n",
      "[706]\tvalid_0's auc: 0.707187\n",
      "[707]\tvalid_0's auc: 0.707203\n",
      "[708]\tvalid_0's auc: 0.70716\n",
      "[709]\tvalid_0's auc: 0.707156\n",
      "[710]\tvalid_0's auc: 0.707172\n",
      "[711]\tvalid_0's auc: 0.707191\n",
      "[712]\tvalid_0's auc: 0.707213\n",
      "[713]\tvalid_0's auc: 0.707203\n",
      "[714]\tvalid_0's auc: 0.707264\n",
      "[715]\tvalid_0's auc: 0.707267\n",
      "[716]\tvalid_0's auc: 0.70727\n",
      "[717]\tvalid_0's auc: 0.707289\n",
      "[718]\tvalid_0's auc: 0.707297\n",
      "[719]\tvalid_0's auc: 0.707275\n",
      "[720]\tvalid_0's auc: 0.70727\n",
      "[721]\tvalid_0's auc: 0.707282\n",
      "[722]\tvalid_0's auc: 0.707283\n",
      "[723]\tvalid_0's auc: 0.707296\n",
      "[724]\tvalid_0's auc: 0.707271\n",
      "[725]\tvalid_0's auc: 0.707285\n",
      "[726]\tvalid_0's auc: 0.707331\n",
      "[727]\tvalid_0's auc: 0.707339\n",
      "[728]\tvalid_0's auc: 0.707328\n",
      "[729]\tvalid_0's auc: 0.707308\n",
      "[730]\tvalid_0's auc: 0.707332\n",
      "[731]\tvalid_0's auc: 0.707333\n",
      "[732]\tvalid_0's auc: 0.707337\n",
      "[733]\tvalid_0's auc: 0.707357\n",
      "[734]\tvalid_0's auc: 0.707362\n",
      "[735]\tvalid_0's auc: 0.707351\n",
      "[736]\tvalid_0's auc: 0.707349\n",
      "[737]\tvalid_0's auc: 0.707334\n",
      "[738]\tvalid_0's auc: 0.707317\n",
      "[739]\tvalid_0's auc: 0.707328\n",
      "[740]\tvalid_0's auc: 0.707337\n",
      "[741]\tvalid_0's auc: 0.707338\n",
      "[742]\tvalid_0's auc: 0.707343\n",
      "[743]\tvalid_0's auc: 0.707306\n",
      "[744]\tvalid_0's auc: 0.707306\n",
      "[745]\tvalid_0's auc: 0.707303\n",
      "[746]\tvalid_0's auc: 0.70732\n",
      "[747]\tvalid_0's auc: 0.707353\n",
      "[748]\tvalid_0's auc: 0.707345\n",
      "[749]\tvalid_0's auc: 0.707313\n",
      "[750]\tvalid_0's auc: 0.707365\n",
      "[751]\tvalid_0's auc: 0.707373\n",
      "[752]\tvalid_0's auc: 0.707349\n",
      "[753]\tvalid_0's auc: 0.70735\n",
      "[754]\tvalid_0's auc: 0.70736\n",
      "[755]\tvalid_0's auc: 0.707411\n",
      "[756]\tvalid_0's auc: 0.70739\n",
      "[757]\tvalid_0's auc: 0.707401\n",
      "[758]\tvalid_0's auc: 0.707406\n",
      "[759]\tvalid_0's auc: 0.707466\n",
      "[760]\tvalid_0's auc: 0.707466\n",
      "[761]\tvalid_0's auc: 0.707491\n",
      "[762]\tvalid_0's auc: 0.707505\n",
      "[763]\tvalid_0's auc: 0.707493\n",
      "[764]\tvalid_0's auc: 0.707498\n",
      "[765]\tvalid_0's auc: 0.707494\n",
      "[766]\tvalid_0's auc: 0.70749\n",
      "[767]\tvalid_0's auc: 0.707467\n",
      "[768]\tvalid_0's auc: 0.707484\n",
      "[769]\tvalid_0's auc: 0.707461\n",
      "[770]\tvalid_0's auc: 0.707466\n",
      "[771]\tvalid_0's auc: 0.707458\n",
      "[772]\tvalid_0's auc: 0.707477\n",
      "[773]\tvalid_0's auc: 0.707451\n",
      "[774]\tvalid_0's auc: 0.707442\n",
      "[775]\tvalid_0's auc: 0.707435\n",
      "[776]\tvalid_0's auc: 0.70746\n",
      "[777]\tvalid_0's auc: 0.707435\n",
      "[778]\tvalid_0's auc: 0.707443\n",
      "[779]\tvalid_0's auc: 0.707471\n",
      "[780]\tvalid_0's auc: 0.707465\n",
      "[781]\tvalid_0's auc: 0.707439\n",
      "[782]\tvalid_0's auc: 0.707462\n",
      "[783]\tvalid_0's auc: 0.707505\n",
      "[784]\tvalid_0's auc: 0.707491\n",
      "[785]\tvalid_0's auc: 0.707484\n",
      "[786]\tvalid_0's auc: 0.707488\n",
      "[787]\tvalid_0's auc: 0.707498\n",
      "[788]\tvalid_0's auc: 0.707489\n",
      "[789]\tvalid_0's auc: 0.707496\n",
      "[790]\tvalid_0's auc: 0.70751\n",
      "[791]\tvalid_0's auc: 0.707483\n",
      "[792]\tvalid_0's auc: 0.707475\n",
      "[793]\tvalid_0's auc: 0.707468\n",
      "[794]\tvalid_0's auc: 0.707525\n",
      "[795]\tvalid_0's auc: 0.707581\n",
      "[796]\tvalid_0's auc: 0.707598\n",
      "[797]\tvalid_0's auc: 0.707613\n",
      "[798]\tvalid_0's auc: 0.707593\n",
      "[799]\tvalid_0's auc: 0.707601\n",
      "[800]\tvalid_0's auc: 0.707621\n",
      "cur fold finished.\n"
     ]
    }
   ],
   "source": [
    "predictions = np.zeros(shape=[len(test)])\n",
    "\n",
    "# features = ['msno', 'song_id', 'source_system_tab', 'source_screen_name', 'source_type', 'city', 'bd', 'gender', 'registered_via', 'song_length', 'genre_ids', 'language', 'name', 'country', 'song_year', 'registration_year', 'registration_month', 'registration_day', 'expiration_year', 'expiration_month', 'expiration_day', 'days', 'composer_score', 'composer', 'lyricist_score', 'lyricist', 'artist_name_score', 'artist_name', 'popular_0', 'num_people_0', 'popular_1', 'num_people_1', 'popular_2', 'num_people_2', 'popular_3', 'num_people_3', 'popular_4', 'num_people_4', 'active_0', 'num_song_0', 'active_1', 'num_song_1', 'active_2', 'num_song_2', 'active_3', 'num_song_3', 'active_4', 'num_song_4', 'composer_by_city', 'composer_by_country', 'composer_by_language', 'lyricist_by_city', 'lyricist_by_country', 'lyricist_by_language', 'artist_name_by_city', 'artist_name_by_country', 'artist_name_by_language', 'song_id_by_city', 'msno_by_country', 'msno_by_language', 'genre_ids_score', 'genre_ids_popular', 'msno_is_in_topK_of_artist_name', 'msno_is_in_topK_of_genre_ids', 'artist_name_is_in_topK_of_genre_ids', 'artist_name_is_in_topK_of_msno', 'source_screen_name_count', 'source_screen_name_mean_popular_0', 'source_screen_name_mean_popular_1', 'source_screen_name_mean_active_0', 'source_screen_name_mean_active_1', 'source_type_count', 'source_type_mean_popular_0', 'source_type_mean_popular_1', 'source_type_mean_active_0', 'source_type_mean_active_1', 'city_by_song_id', 'city_by_msno', 'city_by_genre_ids', 'city_by_artist_name', 'language_by_song_id', 'language_by_msno', 'language_by_genre_ids', 'language_by_artist_name']\n",
    "\n",
    "# train_use_array = train_use[features].values\n",
    "# labels = train_use['target'].values.astype('int').flatten()\n",
    "# #del train_use  # delete dataframe to release memory \n",
    "# gc.collect()\n",
    "# train_data = lgb.Dataset(train_use_array, labels, feature_name = features, categorical_feature = ['msno', 'song_id', 'source_system_tab', 'source_screen_name', 'source_type', 'gender', 'name', 'country', 'composer', 'lyricist', 'artist_name'])\n",
    "\n",
    "train_data = lgb.Dataset(train_use.drop(['target'],axis=1),label=train_use['target'])\n",
    "val_data = lgb.Dataset(validation_use.drop(['target'],axis=1),label=validation_use['target'])\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.1 ,\n",
    "    'verbose': 0,\n",
    "    'num_leaves': 128,#108\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_seed': 1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'feature_fraction_seed': 1,\n",
    "    'max_bin': 128,\n",
    "    'max_depth': 12,\n",
    "    'num_rounds': 800,\n",
    "    'metric' : 'auc',\n",
    "    } \n",
    "\n",
    "bst = lgb.train(params, train_data, 100, valid_sets=[val_data])\n",
    "\n",
    "#del train_data, val_data\n",
    "gc.collect()\n",
    "\n",
    "predictions+=bst.predict(test.drop(['id'],axis=1))\n",
    "print('cur fold finished.')\n",
    "\n",
    "submission = pd.DataFrame({'id': test_id, 'target': predictions})\n",
    "submission.to_csv(SUBMISSION_FILENAME.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot feature importances...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxcAAAHwCAYAAADU/pIvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZkVhJMLMzMzMzMriP8HEge1A6Yuda8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f23eb8da080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Plot feature importances...')\n",
    "ax = lgb.plot_importance(bst, max_num_features=20)\n",
    "plt.show()\n",
    "# last 400 0.696958 800 0.703245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float32_list = list()\n",
    "for col in test.columns:\n",
    "    if col not in ['song_length', 'id']:\n",
    "        if test[col].dtype == np.float32:\n",
    "            float32_list.append(col)\n",
    "print(float32_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.read_csv(DATASET_PATH+'submission_2017-11-06 22:25:54.csv')#'submission_2017-11-07 17:29:32.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def param_tune_with_val(params, tune_param, param_list, data_list, val_data, less_prefered = False):\n",
    "    #data_list = {'train':{'x':train_d,'y':train_y}, 'validation':{'x':valid_d,'y':valid_y}}\n",
    "    best_metric = (less_prefered and sys.float_info.max or -sys.float_info.max)\n",
    "    best_param = param_list[0]\n",
    "\n",
    "    for par_value in param_list:\n",
    "        params[tune_param] = par_value\n",
    "        # , num_boost_round=params['num_boost_round'], early_stopping_rounds = params['early_stopping_rounds']\n",
    "        model = lgb.train(params, data_list['train']['x'], valid_sets=[data_list['validation']['x']], \\\n",
    "                feature_name='auto', #categorical_feature=['source_system_tab', 'source_screen_name', 'source_type', 'city', 'gender',\\\n",
    "                                     #                       'bd', 'name', 'artist_name', 'composer', 'lyricist', 'msno', 'song_id', 'genre_ids',\\\n",
    "                                     #                       'country', 'language', 'registered_via'],、\n",
    "                        )\n",
    "       \n",
    "        val_predprob = model.predict(val_data)\n",
    "        auroc_score = metrics.roc_auc_score(data_list['validation']['y'], val_predprob)\n",
    "\n",
    "        if (not less_prefered and auroc_score > best_metric) or (less_prefered and auroc_score < best_metric):\n",
    "            best_metric = auroc_score\n",
    "            best_param = par_value\n",
    "    log.info('best param for {}: {}, metric: {}'.format(tune_param, best_param, best_metric))\n",
    "    return best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#{'top_k': 20, 'feature_fraction': 0.8, 'bagging_freq': 1, 'min_data_in_bin': 3, 'min_sum_hessian_in_leaf': 0.001, 'bagging_fraction': 0.9, 'max_depth': 12, 'num_leaves': 100, 'learning_rate': 0.01, 'objective': 'binary', 'lambda_l2': 0.01, 'feature_fraction_seed': 1024, 'min_data_in_leaf': 15, 'max_bin': 100, 'verbose': 0, 'bagging_seed': 6666, 'max_cat_to_onehot': 4, 'metric': 'auc', 'lambda_l1': 1e-05, 'num_threads': 16, 'boosting': 'gbdt', 'min_split_gain': 0.3}\n",
    "\n",
    "#{'bagging_seed': 6666, 'lambda_l1': 1e-05, 'lambda_l2': 0.01, 'metric': 'auc', 'bagging_freq': 1, 'min_sum_hessian_in_leaf': 0.001, 'feature_fraction': 0.8, 'feature_fraction_seed': 1024, 'num_leaves': 90, 'boosting': 'gbdt', 'verbose': 0, 'min_data_in_leaf': 15, 'top_k': 20, 'objective': 'binary', 'min_data_in_bin': 3, 'num_threads': 16, 'max_cat_to_onehot': 4, 'max_depth': 10, 'bagging_fraction': 0.9, 'learning_rate': 0.01, 'max_bin': 80, 'min_split_gain': 0.3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_for_best_params(train, validation, test):\n",
    "    \n",
    "    X_train = lgb.Dataset(np.array(train.drop(['target'], axis=1)), label=train['target'].values)\n",
    "    X_valid = lgb.Dataset(np.array(validation.drop(['target'], axis=1)), label=validation['target'].values)\n",
    "    \n",
    "    y_train = train['target'].values\n",
    "    y_valid = validation['target'].values\n",
    "\n",
    "    X_test = np.array(test.drop(['id'], axis=1))\n",
    "\n",
    "    data_list = {'train':{'x':X_train,'y':y_train}, 'validation':{'x':X_valid,'y':y_valid}}\n",
    "######## for value rather than catogory ################\n",
    "#   params_to_eval = OrderedDict(\n",
    "#         ( \n",
    "#         ('num_boost_round', range(120,150,10)),\n",
    "#         ('num_leaves', range(80,100,10)), # number of leaves in one tree\n",
    "#         ('max_depth', range(8,12,1)),\n",
    "#         ('min_data_in_leaf', 15),\n",
    "#         ('min_sum_hessian_in_leaf', [0.001]),# too high will lead to under-fitting\n",
    "#         ('min_split_gain',[0.3]),# the minimum loss reduction required to make a split\n",
    "#         ('bagging_fraction',[0.9]),# [i/10.0 for i in range(6,10)]\n",
    "#         ('feature_fraction',[0.8]),# typical: 0.5-1\n",
    "#         ('max_bin', range(70,90,10)),\n",
    "#         ('lambda_l2',[0.01]),\n",
    "#         ('lambda_l1',[1e-5]),\n",
    "#         ('learning_rate',[0.01]), # typical: 0.01-0.2\n",
    "#         )\n",
    "#       )\n",
    "     \n",
    "#     initial_params = {\n",
    "#         'objective': 'binary',\n",
    "#         'boosting': 'gbdt',\n",
    "#         'num_boost_round': 140,\n",
    "#         'learning_rate': 0.01 ,\n",
    "#         'verbose': 0,\n",
    "#         'num_leaves': 90,\n",
    "#         'num_threads':16,\n",
    "#         'max_depth': 9,\n",
    "#         'min_data_in_leaf': 15, #minimal number of data in one leaf. Can be used to deal with over-fitting\n",
    "#         'min_sum_hessian_in_leaf': 1e-3, #minimal sum hessian in one leaf. Like min_data_in_leaf, it can be used to deal with over-fitting\n",
    "#         'feature_fraction': 0.8, #colsample_bytree\n",
    "#         'feature_fraction_seed': 1024,\n",
    "#         'bagging_fraction': 0.9, #subsample\n",
    "#         'bagging_freq': 1, #frequency for bagging, 0 means disable bagging. k means will perform bagging at every k iteration\n",
    "#         'bagging_seed': 6666,\n",
    "#         'early_stopping_rounds':10,   \n",
    "#         'lambda_l1': 1e-5, #L1 regularization\n",
    "#         'lambda_l2': 0.01, #L2 regularization\n",
    "#         'max_cat_to_onehot': 4, #when number of categories of one feature smaller than or equal to max_cat_to_onehot, one-vs-other split algorithm will be used\n",
    "#         'top_k': 20, #set this to larger value for more accurate result, but it will slow down the training speed\n",
    "#         'min_split_gain': 0.3, #the minimal gain to perform split\n",
    "#         'max_bin': 70, #max number of bins that feature values will be bucketed in. Small number of bins may reduce training accuracy but may increase general power (deal with over-fitting)\n",
    "#         'min_data_in_bin': 3, #min number of data inside one bin, use this to avoid one-data-one-bin (may over-fitting)       \n",
    "#         'metric' : 'auc',\n",
    "#     } \n",
    "    params_to_eval = OrderedDict(\n",
    "        ( \n",
    "        ('num_boost_round', range(100,400,50)),\n",
    "        ('num_leaves', range(80,160,10)), # number of leaves in one tree\n",
    "        ('max_depth', range(8,18,1)),\n",
    "        ('min_data_in_leaf', range(10,18,2)),\n",
    "        ('min_sum_hessian_in_leaf', [0.001]),# too high will lead to under-fitting\n",
    "        ('min_split_gain',[0.3]),# the minimum loss reduction required to make a split\n",
    "        ('bagging_fraction',[0.9]),# [i/10.0 for i in range(6,10)]\n",
    "        ('feature_fraction',[0.8]),# typical: 0.5-1\n",
    "        ('max_bin', range(80,200,10)),\n",
    "        ('lambda_l2',[0.01]),\n",
    "        ('lambda_l1',[1e-5]),\n",
    "        ('learning_rate',[0.01]), # typical: 0.01-0.2\n",
    "        )\n",
    "      )\n",
    "     \n",
    "    initial_params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'gbdt',\n",
    "        'num_boost_round': 200,\n",
    "        'learning_rate': 0.1 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 120,\n",
    "        'num_threads':16,\n",
    "        'max_depth': 14,\n",
    "        'min_data_in_leaf': 16, #minimal number of data in one leaf. Can be used to deal with over-fitting\n",
    "        'min_sum_hessian_in_leaf': 1e-3, #minimal sum hessian in one leaf. Like min_data_in_leaf, it can be used to deal with over-fitting\n",
    "        'feature_fraction': 0.8, #colsample_bytree\n",
    "        'feature_fraction_seed': 1024,\n",
    "        'bagging_fraction': 0.9, #subsample\n",
    "        'bagging_freq': 1, #frequency for bagging, 0 means disable bagging. k means will perform bagging at every k iteration\n",
    "        'bagging_seed': 6666,\n",
    "        'early_stopping_rounds':10,   \n",
    "        'lambda_l1': 1e-5, #L1 regularization\n",
    "        'lambda_l2': 0.01, #L2 regularization\n",
    "        'max_cat_to_onehot': 4, #when number of categories of one feature smaller than or equal to max_cat_to_onehot, one-vs-other split algorithm will be used\n",
    "        'top_k': 20, #set this to larger value for more accurate result, but it will slow down the training speed\n",
    "        'min_split_gain': 0.3, #the minimal gain to perform split\n",
    "        'max_bin': 140, #max number of bins that feature values will be bucketed in. Small number of bins may reduce training accuracy but may increase general power (deal with over-fitting)\n",
    "        'min_data_in_bin': 3, #min number of data inside one bin, use this to avoid one-data-one-bin (may over-fitting)       \n",
    "        'metric' : 'auc',\n",
    "    } \n",
    "    # only param nin this list are tuned, total list are ['n_estimators', 'reg_alpha', 'reg_lambda', 'subsample', 'colsample_bytree', 'min_child_weight', 'max_depth', 'learning_rate', 'gamma']\n",
    "    #tuned_param_name = ['num_boost_round', 'num_leaves', 'max_depth', 'max_bin']\n",
    "    tuned_param_name = ['num_boost_round', 'num_leaves', 'max_depth', 'min_data_in_leaf', 'min_sum_hessian_in_leaf',\\\n",
    "                        'min_split_gain', 'bagging_fraction', 'feature_fraction', 'max_bin', 'lambda_l2', 'lambda_l1', 'learning_rate']\n",
    "    for par_name, par_list in params_to_eval.items():\n",
    "        if par_name in tuned_param_name:\n",
    "            log.info('tunning {}...'.format(par_name))\n",
    "            if len(par_list) > 1:\n",
    "                initial_params[par_name] = param_tune_with_val(initial_params, par_name, par_list, data_list, np.array(validation.drop(['target'], axis=1)))\n",
    "            else:\n",
    "                initial_params[par_name] = par_list[0]\n",
    "    \n",
    "    return initial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "best_param = search_for_best_params(train_use, validation_use, test)\n",
    "log.info(best_param)\n",
    "time_elapsed = time.time() - start_time\n",
    "log.info('time used: {:.3f}sec'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'gbdt',\n",
    "        'num_boost_round': 140,\n",
    "        'learning_rate': 0.01 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 90,\n",
    "        'num_threads':16,\n",
    "        'max_depth': 9,\n",
    "        'min_data_in_leaf': 15, #minimal number of data in one leaf. Can be used to deal with over-fitting\n",
    "        'min_sum_hessian_in_leaf': 1e-3, #minimal sum hessian in one leaf. Like min_data_in_leaf, it can be used to deal with over-fitting\n",
    "        'feature_fraction': 0.8, #colsample_bytree\n",
    "        'feature_fraction_seed': 1024,\n",
    "        'bagging_fraction': 0.9, #subsample\n",
    "        'bagging_freq': 1, #frequency for bagging, 0 means disable bagging. k means will perform bagging at every k iteration\n",
    "        'bagging_seed': 6666,\n",
    "        'early_stopping_rounds':10,   \n",
    "        'lambda_l1': 1e-5, #L1 regularization\n",
    "        'lambda_l2': 0.01, #L2 regularization\n",
    "        'max_cat_to_onehot': 4, #when number of categories of one feature smaller than or equal to max_cat_to_onehot, one-vs-other split algorithm will be used\n",
    "        'top_k': 20, #set this to larger value for more accurate result, but it will slow down the training speed\n",
    "        'min_split_gain': 0.3, #the minimal gain to perform split\n",
    "        'max_bin': 70, #max number of bins that feature values will be bucketed in. Small number of bins may reduce training accuracy but may increase general power (deal with over-fitting)\n",
    "        'min_data_in_bin': 3, #min number of data inside one bin, use this to avoid one-data-one-bin (may over-fitting)       \n",
    "        'metric' : 'auc',\n",
    "    } \n",
    "X_train = lgb.Dataset(np.array(train_use.drop(['target'], axis=1)), label=train_use['target'].values)\n",
    "X_valid = lgb.Dataset(np.array(validation_use.drop(['target'], axis=1)), label=validation_use['target'].values)\n",
    "X_test = np.array(test.drop(['id'], axis=1))\n",
    "model = lgb.train(params, X_train, valid_sets=[X_valid])\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({'id': test_id, 'target': pred})\n",
    "submission.to_csv(SUBMISSION_FILENAME.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array(train_use.drop(['target'], axis=1))\n",
    "y_train = train_use['target'].values\n",
    "\n",
    "X_valid = np.array(validation_use.drop(['target'], axis=1))\n",
    "y_valid = validation_use['target'].values\n",
    "\n",
    "X_test = np.array(test.drop(['id'], axis=1))\n",
    "\n",
    "# d_train = xgb.DMatrix(X_train)\n",
    "# d_valid = xgb.DMatrix(X_valid) \n",
    "# d_test = xgb.DMatrix(X_test)\n",
    "\n",
    "data_list = {'train':{'x':X_train,'y':y_train}, 'validation':{'x':X_valid,'y':y_valid}}\n",
    "# Train model, evaluate and make predictions\n",
    "params={\n",
    "    'n_estimators':500,\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.75,\n",
    "    'gamma':0.1,\n",
    "    'subsample':0.8,\n",
    "    'colsample_bytree':0.3,\n",
    "    'min_child_weight':3,\n",
    "    'max_depth':16,\n",
    "    'seed':1024,\n",
    "    }\n",
    "\n",
    "param_tune_with_val(params, 'max_depth', [5,1,6], data_list, 'auc', 20)\n",
    "\n",
    "# model = xgb.train(params, d_train, 100, watchlist, early_stopping_rounds=20, \\\n",
    "#     maximize=True, verbose_eval=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array(train_use.drop(['target'], axis=1))\n",
    "y_train = train_use['target'].values\n",
    "\n",
    "X_valid = np.array(validation_use.drop(['target'], axis=1))\n",
    "y_valid = validation_use['target'].values\n",
    "\n",
    "X_test = np.array(test.drop(['id'], axis=1))\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "d_valid = xgb.DMatrix(X_valid, label=y_valid) \n",
    "d_test = xgb.DMatrix(X_test)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "# Train model, evaluate and make predictions\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eta'] = 0.75\n",
    "params['max_depth'] = 16\n",
    "params['silent'] = 1\n",
    "params['eval_metric'] = 'auc'\n",
    "\n",
    "model = xgb.train(params, d_train, 100, watchlist, early_stopping_rounds=20, \\\n",
    "    maximize=True, verbose_eval=5)\n",
    "\n",
    "#Predict training set:\n",
    "train_predictions = model.predict(X_train)\n",
    "train_predprob = model.predict_proba(X_train)[:,1]\n",
    "\n",
    "val_predictions = model.predict(X_valid)\n",
    "val_predprob = model.predict_proba(X_valid)[:,1]\n",
    "\n",
    "#Print model report:\n",
    "print(\"\\nModel Report\")\n",
    "print(\"Train Accuracy : %.4g\" % metrics.accuracy_score(y_train, train_predictions))\n",
    "print(\"Train AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, train_predprob))\n",
    "print(\"ValAccuracy : %.4g\" % metrics.accuracy_score(y_valid, val_predictions))\n",
    "print(\"Validation AUC Score (Train): %f\" % metrics.roc_auc_score(y_valid, val_predprob))\n",
    "\n",
    "feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')\n",
    "\n",
    "p_test = model.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27)\n",
    "modelfit(xgb1, train_use.drop(['target'],axis=1), train_use['target'], validation_use.drop(['target'],axis=1), validation_use['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['Disbursed'], eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Disbursed'].values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Disbursed'], dtrain_predprob))\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, train, label, validation, val_label, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(train.values, label=label.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds, metrics='auc', early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(train, label, eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    train_predictions = alg.predict(train)\n",
    "    train_predprob = alg.predict_proba(train)[:,1]\n",
    "    \n",
    "    val_predictions = alg.predict(validation)\n",
    "    val_predprob = alg.predict_proba(validation)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Train Accuracy : %.4g\" % metrics.accuracy_score(label.values, train_predictions))\n",
    "    print(\"Train AUC Score (Train): %f\" % metrics.roc_auc_score(label, train_predprob))\n",
    "    print(\"ValAccuracy : %.4g\" % metrics.accuracy_score(val_label.values, val_predictions))\n",
    "    print(\"Validation AUC Score (Train): %f\" % metrics.roc_auc_score(val_label, val_predprob))\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27)\n",
    "modelfit(xgb1, train_use.drop(['target'],axis=1), train_use['target'], validation_use.drop(['target'],axis=1), validation_use['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "predictions = np.zeros(shape=[len(test)])\n",
    "\n",
    "\n",
    "train_data = lgb.Dataset(train_use.drop(['target'],axis=1), label=train_use['target'])\n",
    "val_data = lgb.Dataset(validation_use.drop(['target'],axis=1), label=validation_use['target'])\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.1 ,\n",
    "    'verbose': 0,\n",
    "    'num_leaves': 108,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_seed': 1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'feature_fraction_seed': 1,\n",
    "    'max_bin': 128,\n",
    "    'max_depth': 10,\n",
    "    'num_rounds': 200,\n",
    "    'metric' : 'auc',\n",
    "    } \n",
    "\n",
    "bst = lgb.train(params, train_data, 100, valid_sets=[val_data])\n",
    "predictions=bst.predict(test.drop(['id'],axis=1))\n",
    "print('finished.')\n",
    "\n",
    "    \n",
    "predictions = predictions/3\n",
    "\n",
    "submission = pd.DataFrame({'id': test_id, 'target': predictions})\n",
    "submission.to_csv(SUBMISSION_FILENAME.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "predictions = np.zeros(shape=[len(test)])\n",
    "\n",
    "for train_indices,val_indices in kf.split(train) : \n",
    "    train_data = lgb.Dataset(train.drop(['target'],axis=1).loc[train_indices,:],label=train.loc[train_indices,'target'])\n",
    "    val_data = lgb.Dataset(train.drop(['target'],axis=1).loc[val_indices,:],label=train.loc[val_indices,'target'])\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'gbdt',\n",
    "        'learning_rate': 0.1 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 108,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 0.9,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_bin': 128,\n",
    "        'max_depth': 10,\n",
    "        'num_rounds': 200,\n",
    "        'metric' : 'auc',\n",
    "        } \n",
    "    \n",
    "    bst = lgb.train(params, train_data, 100, valid_sets=[val_data])\n",
    "    predictions+=bst.predict(test.drop(['id'],axis=1))\n",
    "    print('cur fold finished.')\n",
    "    del bst\n",
    "    \n",
    "predictions = predictions/3\n",
    "\n",
    "submission = pd.DataFrame({'id': test_id, 'target': predictions})\n",
    "submission.to_csv(SUBMISSION_FILENAME.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess songs data\n",
    "songs_genres = np.array(songs['genre_ids']\\\n",
    "    .apply(lambda x: [int(v) for v in str(x).split('|')]))\n",
    "genres_list = songs_genres.ravel().unique()\n",
    "print('Number of genres: ' + str(len(genres_list)))\n",
    "\n",
    "ohe_genres = np.zeros((len(songs_genres), len(genres_list)))\n",
    "for s_i, s_genres in enumerate(songs_genres):\n",
    "    for genre in s_genres:\n",
    "        g_i = genres_list.find(genre)\n",
    "        ohe_genres[s_i, g_i] = 1\n",
    "        \n",
    "for g_i, g in enumerate(genres_list):\n",
    "    songs['genre_' + str(g)] = ohe_genres[:, g_i]\n",
    "print(songs.head())\n",
    "songs = songs.drop(['genre_ids'], axis=1)\n",
    "\n",
    "song_cols = songs.columns\n",
    "\n",
    "# Preprocess dataset\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n",
    "\n",
    "cols = list(train.columns)\n",
    "cols.remove('target')\n",
    "\n",
    "for col in tqdm(cols):\n",
    "    if train[col].dtype == 'object':\n",
    "        train[col] = train[col].apply(str)\n",
    "        test[col] = test[col].apply(str)\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        train_vals = list(train[col].unique())\n",
    "        test_vals = list(test[col].unique())\n",
    "        le.fit(train_vals + test_vals)\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col] = le.transform(test[col])\n",
    "\n",
    "        print(col + ': ' + str(len(train_vals)) + ', ' + str(len(test_vals)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## import packages\n",
    "########################################\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Activation, Reshape\n",
    "from keras.layers.merge import concatenate, dot\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "\n",
    "########################################\n",
    "## load the data\n",
    "########################################\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "uid = train.msno\n",
    "sid = train.song_id\n",
    "target = train.target\n",
    "\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "id_test = test.id\n",
    "uid_test = test.msno\n",
    "sid_test = test.song_id\n",
    "\n",
    "########################################\n",
    "## encoding\n",
    "########################################\n",
    "\n",
    "usr_encoder = LabelEncoder()\n",
    "usr_encoder.fit(uid.append(uid_test))\n",
    "uid = usr_encoder.transform(uid)\n",
    "uid_test = usr_encoder.transform(uid_test)\n",
    "\n",
    "sid_encoder = LabelEncoder()\n",
    "sid_encoder.fit(sid.append(sid_test))\n",
    "sid = sid_encoder.transform(sid)\n",
    "sid_test = sid_encoder.transform(sid_test)\n",
    "\n",
    "u_cnt = int(max(uid.max(), uid_test.max()) + 1)\n",
    "s_cnt = int(max(sid.max(), sid_test.max()) + 1)\n",
    "\n",
    "########################################\n",
    "## train-validation split\n",
    "########################################\n",
    "\n",
    "perm = np.random.permutation(len(train))\n",
    "trn_cnt = int(len(train) * 0.85)\n",
    "uid_trn = uid[perm[:trn_cnt]]\n",
    "uid_val = uid[perm[trn_cnt:]]\n",
    "sid_trn = sid[perm[:trn_cnt]]\n",
    "sid_val = sid[perm[trn_cnt:]]\n",
    "target_trn = target[perm[:trn_cnt]]\n",
    "target_val = target[perm[trn_cnt:]]\n",
    "\n",
    "########################################\n",
    "## define the model\n",
    "########################################\n",
    "\n",
    "def get_model():\n",
    "    user_embeddings = Embedding(u_cnt,\n",
    "            64,\n",
    "            embeddings_initializer=RandomUniform(minval=-0.1, maxval=0.1),\n",
    "            embeddings_regularizer=l2(1e-4),\n",
    "            input_length=1,\n",
    "            trainable=True)\n",
    "    song_embeddings = Embedding(s_cnt,\n",
    "            64,\n",
    "            embeddings_initializer=RandomUniform(minval=-0.1, maxval=0.1),\n",
    "            embeddings_regularizer=l2(1e-4),\n",
    "            input_length=1,\n",
    "            trainable=True)\n",
    "\n",
    "    uid_input = Input(shape=(1,), dtype='int32')\n",
    "    embedded_usr = user_embeddings(uid_input)\n",
    "    embedded_usr = Reshape((64,))(embedded_usr)\n",
    "\n",
    "    sid_input = Input(shape=(1,), dtype='int32')\n",
    "    embedded_song = song_embeddings(sid_input)\n",
    "    embedded_song = Reshape((64,))(embedded_song)\n",
    "\n",
    "    preds = dot([embedded_usr, embedded_song], axes=1)\n",
    "    preds = concatenate([embedded_usr, embedded_song, preds])\n",
    "    \n",
    "    preds = Dense(128, activation='relu')(preds)\n",
    "    preds = Dropout(0.5)(preds)\n",
    "    \n",
    "    preds = Dense(1, activation='sigmoid')(preds)\n",
    "\n",
    "    model = Model(inputs=[uid_input, sid_input], outputs=preds)\n",
    "    \n",
    "    opt = RMSprop(lr=1e-3)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "\n",
    "    return model\n",
    "\n",
    "########################################\n",
    "## train the model\n",
    "########################################\n",
    "   \n",
    "model = get_model()\n",
    "early_stopping =EarlyStopping(monitor='val_acc', patience=5)\n",
    "model_path = 'bst_model.h5'\n",
    "model_checkpoint = ModelCheckpoint(model_path, save_best_only=True, \\\n",
    "        save_weights_only=True)\n",
    "\n",
    "hist = model.fit([uid_trn, sid_trn], target_trn, validation_data=([uid_val, sid_val], \\\n",
    "        target_val), epochs=100, batch_size=32768, shuffle=True, \\\n",
    "        callbacks=[early_stopping, model_checkpoint])\n",
    "model.load_weights(model_path)\n",
    "\n",
    "preds_val = model.predict([uid_val, sid_val], batch_size=32768)\n",
    "val_auc = roc_auc_score(target_val, preds_val)\n",
    "\n",
    "########################################\n",
    "## make the submission\n",
    "########################################\n",
    "\n",
    "preds_test = model.predict([uid_test, sid_test], batch_size=32768, verbose=1)\n",
    "sub = pd.DataFrame({'id': id_test, 'target': preds_test.ravel()})\n",
    "sub.to_csv('./sub_%.5f.csv'%(val_auc), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear algebra:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Graphics:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  \n",
    "# Frameworks:\n",
    "import lightgbm as lgb # LightGBM\n",
    "# Utils:\n",
    "import gc # garbage collector\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "IDIR = '../input/' # main path\n",
    "members = pd.read_csv(IDIR + 'members.csv')\n",
    "songs = pd.read_csv(IDIR + 'songs.csv')\n",
    "song_extra_info = pd.read_csv(IDIR + 'song_extra_info.csv')\n",
    "train = pd.read_csv(IDIR + 'train.csv')\n",
    "test = pd.read_csv(IDIR + 'test.csv')\n",
    "\n",
    "# Adding songs' info:\n",
    "train_aug1 = pd.merge(left=train, right=songs, on='song_id', how='left')\n",
    "test_aug1 = pd.merge(left=test, right=songs, on='song_id', how='left')\n",
    "# Adding extra info about songs:\n",
    "train_aug2 = pd.merge(left=train_aug1, right=song_extra_info, on='song_id', how='left')\n",
    "test_aug2 = pd.merge(left=test_aug1, right=song_extra_info, on='song_id', how='left')\n",
    "del train_aug1, test_aug1\n",
    "# Addind users' info:\n",
    "train_aug3 = pd.merge(left=train_aug2, right=members, on='msno', how='left')\n",
    "test_aug3 = pd.merge(left=test_aug2, right=members, on='msno', how='left')\n",
    "del train_aug2, test_aug2\n",
    "# Merging train and test data:\n",
    "train_aug3.drop(['song_id'], axis=1, inplace=True)\n",
    "train_aug3['set'] = 0\n",
    "test_aug3.drop(['song_id'], axis=1, inplace=True)\n",
    "test_aug3['set'] = 1\n",
    "test_aug3['target'] = -1\n",
    "all_aug = pd.concat([train_aug3, test_aug3], axis=0)\n",
    "del train_aug3, test_aug3\n",
    "gc.collect();\n",
    "\n",
    "\n",
    "\n",
    "# source_system_tab/source_screen_name/source_type/genre_ids/artist_name/composer/lyricist/name/isrc/gender 用'NA'填补并one-hot编码\n",
    "# genre_ids encoding:\n",
    "all_aug['genre_ids'] = all_aug.genre_ids.fillna('NA')\n",
    "all_aug['genre_ids'] = all_aug.genre_ids.astype(np.str)\n",
    "genre_ids_le = LabelEncoder()\n",
    "genre_ids_le.fit(all_aug.genre_ids)\n",
    "all_aug['genre_ids'] = genre_ids_le.transform(all_aug.genre_ids).astype(np.int16)\n",
    "\n",
    "# language encoding:\n",
    "all_aug['language'] = all_aug.language.fillna(-2)\n",
    "all_aug['language'] = all_aug.language.astype(np.int8)\n",
    "\n",
    "# city encoding:\n",
    "all_aug['city'] = all_aug.city.astype(np.int8)\n",
    "# bd encoding:\n",
    "all_aug['bd'] = all_aug.bd.astype(np.int16)\n",
    "\n",
    "# registered_via encoding:\n",
    "all_aug['registered_via'] = all_aug.registered_via.astype(np.int8)\n",
    "# registration_init_time encoding:\n",
    "all_aug['registration_init_time'] = all_aug.registration_init_time.astype(np.int32)\n",
    "# expiration_date encoding:\n",
    "all_aug['expiration_date'] = all_aug.expiration_date.astype(np.int32)\n",
    "# Info:\n",
    "all_aug.info(max_cols=0)\n",
    "all_aug.head(2)\n",
    "\n",
    "\n",
    "all_aug['exp_reg_time'] = all_aug.expiration_date - all_aug.registration_init_time\n",
    "\n",
    "\n",
    "\n",
    "gc.collect();\n",
    "d_train = lgb.Dataset(all_aug[all_aug.set == 0].drop(['target', 'msno', 'id', 'set'], axis=1), \n",
    "                      label=all_aug[all_aug.set == 0].pop('target'))\n",
    "ids_train = all_aug[all_aug.set == 0].pop('msno')\n",
    "\n",
    "lgb_params = {\n",
    "    'learning_rate': 1.0,\n",
    "    'max_depth': 15,\n",
    "    'num_leaves': 250, \n",
    "    'objective': 'binary',\n",
    "    'metric': {'auc'},\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 5,\n",
    "    'max_bin': 100}\n",
    "cv_result_lgb = lgb.cv(lgb_params, \n",
    "                       d_train, \n",
    "                       num_boost_round=5000, \n",
    "                       nfold=3, \n",
    "                       stratified=True, \n",
    "                       early_stopping_rounds=50, \n",
    "                       verbose_eval=100, \n",
    "                       show_stdv=True)\n",
    "\n",
    "num_boost_rounds_lgb = len(cv_result_lgb['auc-mean'])\n",
    "print('num_boost_rounds_lgb=' + str(num_boost_rounds_lgb))\n",
    "\n",
    "\n",
    "\n",
    "%%time\n",
    "ROUNDS = num_boost_rounds_lgb\n",
    "print('light GBM train :-)')\n",
    "bst = lgb.train(lgb_params, d_train, ROUNDS)\n",
    "# lgb.plot_importance(bst, figsize=(9,20))\n",
    "# del d_train\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "feature_imp = pd.Series(dict(zip(d_train.feature_name, \n",
    "                                 bst.feature_importance()))).sort_values(ascending=False)\n",
    "sns.barplot(x=feature_imp.values, y=feature_imp.index.values, orient='h', color='g')\n",
    "plt.subplot(1,2,2)\n",
    "train_scores = np.array(cv_result_lgb['auc-mean'])\n",
    "train_stds = np.array(cv_result_lgb['auc-stdv'])\n",
    "plt.plot(train_scores, color='green')\n",
    "plt.fill_between(range(len(cv_result_lgb['auc-mean'])), \n",
    "                 train_scores - train_stds, train_scores + train_stds, \n",
    "                 alpha=0.1, color='green')\n",
    "plt.title('LightGMB CV-results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
